{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "pkg_path = \"/nfs/homedirs/yuny/project-1/audio_classification\"\n",
    "if pkg_path not in sys.path:\n",
    "    sys.path.append(pkg_path)\n",
    "\n",
    "pkg_path = \"/nfs/homedirs/yuny/project-1/foolbox\"\n",
    "if pkg_path not in sys.path:\n",
    "    sys.path.append(pkg_path)\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "# from audio_classification.tools import attack_model, attack_model_for_randomize_smoothing\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cpu')\n",
    "# device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "project_dir = '/nfs/homedirs/yuny/project-1/'\n",
    "save_folder = '/nfs/homedirs/yuny/project-1/attack_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Any, Optional, Callable, Tuple\n",
    "from abc import ABC, abstractmethod\n",
    "import eagerpy as ep\n",
    "\n",
    "from foolbox.devutils import flatten\n",
    "from foolbox.devutils import atleast_kd\n",
    "from foolbox.types import Bounds\n",
    "from foolbox.models.base import Model\n",
    "from foolbox.criteria import Misclassification, TargetedMisclassification\n",
    "from foolbox.distances import l1, l2, linf\n",
    "from foolbox.attacks.base import FixedEpsilonAttack\n",
    "from foolbox.attacks.base import T\n",
    "from foolbox.attacks.base import get_criterion\n",
    "from foolbox.attacks.base import raise_if_kwargs\n",
    "\n",
    "import os\n",
    "import time\n",
    "import types\n",
    "import yaml\n",
    "import torch\n",
    "from audio_classification.tools import do_train, get_dataloader, get_model, get_transform\n",
    "from audio_classification.tools.train_net import collate\n",
    "from audio_classification.model import lit_m11, LitCRNN, SmoothClassifier\n",
    "from audio_classification.data import BMWDataset, UrbanSoundDataset\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "from foolbox.attacks import LinfPGD, L2PGD, FGM, FGSM\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "import IPython.display as ipd\n",
    "from scipy.io.wavfile import write\n",
    "from audio_classification.tools.foolbox_attack import _get_loss_fn, _value_and_grad, _run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'bmw_audio_rs_0.1'\n",
    "config_path = 'logs/bmw/default/crnn-bmw-audi-rs-0.1/hparams.yaml'\n",
    "pretrained_path = 'weights/bmw/crnn-bmw-audi-rs-0.1-epoch=112-val_acc=0.902.ckpt'\n",
    "# attack_model_randomized_smoothing(project_dir, config_path, pretrained_path, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CHECKPOINT': {'SAVE_NAME': 'crnn-bmw-audi-rs-0.1', 'SAVE_PATH': '../weights/bmw/', 'SAVE_TOP_K': 1}, 'DATALOADER': {'BATCH_SIZE': 8, 'NUM_WORKERS': 20}, 'DATASET': {'ANNOTATION_PATH': '/nfs/students/winter-term-2020/project-1/datasets/BMW/meta/bmw.csv', 'AUGMENTATION': 'none', 'FOLDER_PATH': '/nfs/students/winter-term-2020/project-1/datasets/Brake_Noise', 'NAME': 'BMW', 'NOISE_PATH': '../datasets/MUSAN/free-sound/', 'VAL_FOLD': 1, 'WEIGHT': 'NORMAL'}, 'LOSS': 'cross_entropy', 'MODEL': {'CRNN': {'INCLUDE_TOP': True, 'INCLUDE_TRANSFORM': True, 'RANDOMISED_SMOOTHING': True}, 'NAME': 'LitCRNN', 'NUM_CLASSES': 6}, 'SOLVER': {'GAMMA': 0.5, 'LEARNING_RATE': 0.001, 'LOG_PATH': '../logs/bmw/', 'MAX_EPOCH': 125, 'MIN_EPOCH': 1, 'NUM_GPUS': 1, 'SIGMA': 0.1, 'STEP_SIZE': 25, 'WEIGHT_DECAY': 0.001}, 'TRANSFORM': {'HOP_LENGTH': 256}, 'ATTACK': True}\n",
      "Data augmentation for BMW dataset: none\n",
      "Range of the input data is (-1.000000, 0.999969)\n"
     ]
    }
   ],
   "source": [
    "project=\"BMW\"\n",
    "with open(os.path.join(project_dir, config_path), \"r\") as config_file:\n",
    "    configs = yaml.load(config_file)\n",
    "configs[\"ATTACK\"]=True\n",
    "print(configs)\n",
    "\n",
    "# use test/validattion set\n",
    "if project==\"BMW\":\n",
    "    val_set = BMWDataset(configs, [11], transform=get_transform(configs)) # actually the test set\n",
    "elif project==\"UrbanSound8k\":\n",
    "    val_set = UrbanSoundDataset(configs, [10], transform=get_transform(configs))\n",
    "val_loader = DataLoader(val_set, batch_size=24, shuffle=False,\n",
    "                                num_workers=configs[\"DATALOADER\"][\"NUM_WORKERS\"],\n",
    "                                pin_memory=True, collate_fn = collate)\n",
    "\n",
    "# Get the upper bound and lower bound on the values of the data, to be used as constraint in PGD\n",
    "lower_bounds = []\n",
    "upper_bounds = []\n",
    "for step, (x, y, seq_lens) in enumerate(val_loader):    \n",
    "    upper_bounds.append(torch.max(x))\n",
    "    lower_bounds.append(torch.min(x))\n",
    "lower_bound = min(lower_bounds)\n",
    "upper_bound = max(upper_bounds)\n",
    "print(\"Range of the input data is (%f, %f)\" %(lower_bound, upper_bound))\n",
    "\n",
    "path_to_checkpoint = os.path.join(project_dir, pretrained_path)\n",
    "# Get the class weights, used in reloading the model\n",
    "if configs['DATASET']['WEIGHT']=='NORMAL':\n",
    "    weight = torch.tensor([28.9047, 14.8049,  4.5985,  2.4675,  4.4632, 19.5806]).to(device=device)\n",
    "elif configs['DATASET']['WEIGHT']=='SQUARED':\n",
    "    weight = torch.tensor([835.4845, 219.1843,  21.1461,   6.0885,  19.9205, 383.4014]).to(device=device)\n",
    "else:\n",
    "    weight = None\n",
    "\n",
    "if configs[\"MODEL\"][\"CRNN\"][\"RANDOMISED_SMOOTHING\"] == True:\n",
    "    base_classifier = LitCRNN.load_from_checkpoint(path_to_checkpoint, cfg=configs, class_weights=weight, strict=False, map_location=device).eval()\n",
    "    model = SmoothClassifier.load_from_checkpoint(checkpoint_path=path_to_checkpoint, cfg=configs, map_location=device, class_weights=weight, base_classifier = base_classifier.to(device=device)).eval()\n",
    "else:    \n",
    "    model = LitCRNN.load_from_checkpoint(path_to_checkpoint, cfg=configs, class_weights=weight, strict=False, map_location=device).eval()\n",
    "\n",
    "fmodel = PyTorchModel(model, bounds=(lower_bound, upper_bound), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate accuracy on clean data on a batch\n",
    "it = iter(val_loader)\n",
    "batch = next(it)\n",
    "clips = batch[0].to(device)\n",
    "labels = batch[1].to(device)\n",
    "lengths = batch[2].to(device)   # used only for CRNN\n",
    "\n",
    "# delete some variables to free up memory\n",
    "del it\n",
    "del val_loader\n",
    "del val_set\n",
    "\n",
    "# evaluate robustness with L-inf Fast Gradient Attack\n",
    "torch.cuda.empty_cache()\n",
    "attack = FGSM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward is called\n",
      "forward is called\n"
     ]
    }
   ],
   "source": [
    "epsilons = 0.001\n",
    "attack.run = types.MethodType(_run, attack)\n",
    "attack.get_loss_fn = types.MethodType(_get_loss_fn, attack)\n",
    "attack.value_and_grad = types.MethodType(_value_and_grad, attack)\n",
    "raw, clipped, is_adv = attack(fmodel, clips, labels, epsilons=epsilons, original_lengths=lengths)\n",
    "\n",
    "is_adv = is_adv.cpu()\n",
    "clipped = clipped.cpu() #\"Attacks samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward is called\n",
      "whether the attack is sucessul\n",
      "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True, False,  True,  True, False,\n",
      "        False, False, False, False])\n",
      "labels predicted using attack samples\n",
      "tensor([3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3])\n",
      "labels predicted using original samples\n",
      "tensor([0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "out = model(clipped.to(device), lengths)\n",
    "preds = torch.argmax(out, dim=1)\n",
    "print(\"whether the attack is sucessful\")\n",
    "print(is_adv)\n",
    "print(\"labels predicted using attack samples\")\n",
    "print(preds) # labels predicted using attack samples\n",
    "print(\"labels predicted using original samples\")\n",
    "print(batch[1]) # labels predicted using original samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
