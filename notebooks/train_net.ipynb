{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "pkg_path = \"/nfs/homedirs/yuny/project-1/audio_classification\"\n",
    "if pkg_path not in sys.path:\n",
    "    sys.path.append(pkg_path)\n",
    "    \n",
    "import yaml\n",
    "import torch\n",
    "from audio_classification.tools import do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/nfs/homedirs/yuny/project-1/audio_classification/configs/crnn_bmw.yaml\", \"r\") as config_file:\n",
    "    configs = yaml.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: noise\n",
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name        | Type        | Params\n",
      "---------------------------------------------\n",
      "0  | conv1       | Conv2d      | 640   \n",
      "1  | bn1         | BatchNorm2d | 128   \n",
      "2  | dropout1    | Dropout     | 0     \n",
      "3  | conv2       | Conv2d      | 73 K  \n",
      "4  | bn2         | BatchNorm2d | 256   \n",
      "5  | dropout2    | Dropout     | 0     \n",
      "6  | conv3       | Conv2d      | 147 K \n",
      "7  | bn3         | BatchNorm2d | 256   \n",
      "8  | dropout3    | Dropout     | 0     \n",
      "9  | conv4       | Conv2d      | 147 K \n",
      "10 | bn4         | BatchNorm2d | 256   \n",
      "11 | dropout4    | Dropout     | 0     \n",
      "12 | rnn         | GRU         | 21 K  \n",
      "13 | dropout_rnn | Dropout     | 0     \n",
      "14 | linear      | Linear      | 198   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.965, v_num=0, train_loss_step=0.497]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.985, v_num=0, train_loss_step=0.588, val_loss=1.03, val_acc=0.623]\n",
      "Epoch 1:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.786, v_num=0, train_loss_step=0.985, val_loss=1.03, val_acc=0.623, train_loss_epoch=1.21]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.819, v_num=0, train_loss_step=0.521, val_loss=1.04, val_acc=0.656, train_loss_epoch=1.21]\n",
      "Epoch 2:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=1.088, v_num=0, train_loss_step=1.13, val_loss=1.04, val_acc=0.656, train_loss_epoch=1.05] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.972, v_num=0, train_loss_step=0.453, val_loss=0.935, val_acc=0.656, train_loss_epoch=1.05]\n",
      "Epoch 3:  85%|████████▍ | 130/153 [00:24<00:04,  5.41it/s, loss=0.910, v_num=0, train_loss_step=1.08, val_loss=0.935, val_acc=0.656, train_loss_epoch=1.04] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.895, v_num=0, train_loss_step=1.28, val_loss=0.864, val_acc=0.672, train_loss_epoch=1.04]\n",
      "Epoch 4:  85%|████████▍ | 130/153 [00:24<00:04,  5.39it/s, loss=0.785, v_num=0, train_loss_step=2.12, val_loss=0.864, val_acc=0.672, train_loss_epoch=0.936]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 140/153 [00:27<00:02,  5.11it/s, loss=0.901, v_num=0, train_loss_step=0.796, val_loss=0.849, val_acc=0.738, train_loss_epoch=0.936]\n",
      "Epoch 5:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.657, v_num=0, train_loss_step=0.422, val_loss=0.849, val_acc=0.738, train_loss_epoch=0.909]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.711, v_num=0, train_loss_step=1.11, val_loss=0.748, val_acc=0.738, train_loss_epoch=0.909] \n",
      "Epoch 6:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.683, v_num=0, train_loss_step=1.34, val_loss=0.748, val_acc=0.738, train_loss_epoch=0.788]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.687, v_num=0, train_loss_step=0.138, val_loss=0.793, val_acc=0.721, train_loss_epoch=0.788]\n",
      "Epoch 7:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.661, v_num=0, train_loss_step=0.471, val_loss=0.793, val_acc=0.721, train_loss_epoch=0.732]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.697, v_num=0, train_loss_step=1.11, val_loss=0.726, val_acc=0.689, train_loss_epoch=0.732] \n",
      "Epoch 8:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.659, v_num=0, train_loss_step=0.562, val_loss=0.726, val_acc=0.689, train_loss_epoch=0.69]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.614, v_num=0, train_loss_step=0.225, val_loss=0.564, val_acc=0.787, train_loss_epoch=0.69]\n",
      "Epoch 9:  85%|████████▍ | 130/153 [00:24<00:04,  5.32it/s, loss=0.507, v_num=0, train_loss_step=0.473, val_loss=0.564, val_acc=0.787, train_loss_epoch=0.604]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.493, v_num=0, train_loss_step=0.0347, val_loss=0.628, val_acc=0.754, train_loss_epoch=0.604]\n",
      "Epoch 10:  85%|████████▍ | 130/153 [00:24<00:04,  5.31it/s, loss=0.667, v_num=0, train_loss_step=0.0328, val_loss=0.628, val_acc=0.754, train_loss_epoch=0.552]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 140/153 [00:27<00:02,  5.05it/s, loss=0.508, v_num=0, train_loss_step=1.7, val_loss=0.49, val_acc=0.82, train_loss_epoch=0.552]     \n",
      "Epoch 11:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.480, v_num=0, train_loss_step=0.473, val_loss=0.49, val_acc=0.82, train_loss_epoch=0.597]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.541, v_num=0, train_loss_step=0.504, val_loss=0.58, val_acc=0.787, train_loss_epoch=0.597]\n",
      "Epoch 12:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.469, v_num=0, train_loss_step=0.0979, val_loss=0.58, val_acc=0.787, train_loss_epoch=0.472]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 140/153 [00:27<00:02,  5.01it/s, loss=0.427, v_num=0, train_loss_step=1.4, val_loss=0.434, val_acc=0.852, train_loss_epoch=0.472]  \n",
      "Epoch 13:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.495, v_num=0, train_loss_step=0.182, val_loss=0.434, val_acc=0.852, train_loss_epoch=0.489] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.425, v_num=0, train_loss_step=0.333, val_loss=0.42, val_acc=0.902, train_loss_epoch=0.489] \n",
      "Epoch 14:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.510, v_num=0, train_loss_step=0.189, val_loss=0.42, val_acc=0.902, train_loss_epoch=0.484]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.427, v_num=0, train_loss_step=0.238, val_loss=0.593, val_acc=0.787, train_loss_epoch=0.484]\n",
      "Epoch 15:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.527, v_num=0, train_loss_step=0.0295, val_loss=0.593, val_acc=0.787, train_loss_epoch=0.513]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.465, v_num=0, train_loss_step=0.115, val_loss=0.375, val_acc=0.902, train_loss_epoch=0.513] \n",
      "Epoch 16:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.379, v_num=0, train_loss_step=0.717, val_loss=0.375, val_acc=0.902, train_loss_epoch=0.446]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.446, v_num=0, train_loss_step=0.144, val_loss=0.392, val_acc=0.869, train_loss_epoch=0.446]\n",
      "Epoch 17:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.353, v_num=0, train_loss_step=0.335, val_loss=0.392, val_acc=0.869, train_loss_epoch=0.462]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.360, v_num=0, train_loss_step=0.0797, val_loss=0.411, val_acc=0.869, train_loss_epoch=0.462]\n",
      "Epoch 18:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.350, v_num=0, train_loss_step=0.0548, val_loss=0.411, val_acc=0.869, train_loss_epoch=0.462]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.249, v_num=0, train_loss_step=1.07, val_loss=0.43, val_acc=0.852, train_loss_epoch=0.462]   \n",
      "Epoch 19:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.319, v_num=0, train_loss_step=0.149, val_loss=0.43, val_acc=0.852, train_loss_epoch=0.391] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.294, v_num=0, train_loss_step=0.0674, val_loss=0.36, val_acc=0.902, train_loss_epoch=0.391]\n",
      "Epoch 20:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.363, v_num=0, train_loss_step=0.751, val_loss=0.36, val_acc=0.902, train_loss_epoch=0.396]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.413, v_num=0, train_loss_step=1.28, val_loss=0.351, val_acc=0.885, train_loss_epoch=0.396]\n",
      "Epoch 21:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.293, v_num=0, train_loss_step=0.0695, val_loss=0.351, val_acc=0.885, train_loss_epoch=0.352]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.311, v_num=0, train_loss_step=0.502, val_loss=0.434, val_acc=0.869, train_loss_epoch=0.352] \n",
      "Epoch 22:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.370, v_num=0, train_loss_step=0.545, val_loss=0.434, val_acc=0.869, train_loss_epoch=0.428] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  92%|█████████▏| 140/153 [00:27<00:02,  5.11it/s, loss=0.461, v_num=0, train_loss_step=0.394, val_loss=0.514, val_acc=0.836, train_loss_epoch=0.428]\n",
      "Epoch 23:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.422, v_num=0, train_loss_step=0.0218, val_loss=0.514, val_acc=0.836, train_loss_epoch=0.342] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.458, v_num=0, train_loss_step=1.37, val_loss=0.564, val_acc=0.803, train_loss_epoch=0.342]  \n",
      "Epoch 24:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.404, v_num=0, train_loss_step=0.176, val_loss=0.564, val_acc=0.803, train_loss_epoch=0.384] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.424, v_num=0, train_loss_step=0.829, val_loss=0.506, val_acc=0.803, train_loss_epoch=0.384]\n",
      "Epoch 25:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.281, v_num=0, train_loss_step=0.0313, val_loss=0.506, val_acc=0.803, train_loss_epoch=0.424]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.268, v_num=0, train_loss_step=0.0031, val_loss=0.315, val_acc=0.902, train_loss_epoch=0.424]\n",
      "Epoch 26:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.221, v_num=0, train_loss_step=0.785, val_loss=0.315, val_acc=0.902, train_loss_epoch=0.301] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.178, v_num=0, train_loss_step=0.0506, val_loss=0.307, val_acc=0.902, train_loss_epoch=0.301]\n",
      "Epoch 27:  85%|████████▍ | 130/153 [00:24<00:04,  5.39it/s, loss=0.304, v_num=0, train_loss_step=0.0491, val_loss=0.307, val_acc=0.902, train_loss_epoch=0.277]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.303, v_num=0, train_loss_step=0.0988, val_loss=0.343, val_acc=0.885, train_loss_epoch=0.277]\n",
      "Epoch 28:  85%|████████▍ | 130/153 [00:23<00:04,  5.42it/s, loss=0.235, v_num=0, train_loss_step=0.431, val_loss=0.343, val_acc=0.885, train_loss_epoch=0.28]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28:  92%|█████████▏| 140/153 [00:27<00:02,  5.13it/s, loss=0.227, v_num=0, train_loss_step=0.0142, val_loss=0.333, val_acc=0.902, train_loss_epoch=0.28]\n",
      "Epoch 29:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.136, v_num=0, train_loss_step=0.15, val_loss=0.333, val_acc=0.902, train_loss_epoch=0.252]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.138, v_num=0, train_loss_step=0.0767, val_loss=0.323, val_acc=0.902, train_loss_epoch=0.252]\n",
      "Epoch 30:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.308, v_num=0, train_loss_step=0.0661, val_loss=0.323, val_acc=0.902, train_loss_epoch=0.209]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.242, v_num=0, train_loss_step=0.00398, val_loss=0.439, val_acc=0.869, train_loss_epoch=0.209]\n",
      "Epoch 31:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.260, v_num=0, train_loss_step=0.0127, val_loss=0.439, val_acc=0.869, train_loss_epoch=0.262] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.235, v_num=0, train_loss_step=0.00165, val_loss=0.297, val_acc=0.902, train_loss_epoch=0.262]\n",
      "Epoch 32:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.333, v_num=0, train_loss_step=0.0364, val_loss=0.297, val_acc=0.902, train_loss_epoch=0.235] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.371, v_num=0, train_loss_step=0.195, val_loss=0.27, val_acc=0.918, train_loss_epoch=0.235]  \n",
      "Epoch 33:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.211, v_num=0, train_loss_step=0.238, val_loss=0.27, val_acc=0.918, train_loss_epoch=0.253] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.238, v_num=0, train_loss_step=0.17, val_loss=0.488, val_acc=0.852, train_loss_epoch=0.253]\n",
      "Epoch 34:  85%|████████▍ | 130/153 [00:24<00:04,  5.30it/s, loss=0.214, v_num=0, train_loss_step=0.003, val_loss=0.488, val_acc=0.852, train_loss_epoch=0.253]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34:  92%|█████████▏| 140/153 [00:27<00:02,  5.02it/s, loss=0.191, v_num=0, train_loss_step=0.0022, val_loss=0.284, val_acc=0.902, train_loss_epoch=0.253]\n",
      "Epoch 35:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.287, v_num=0, train_loss_step=0.24, val_loss=0.284, val_acc=0.902, train_loss_epoch=0.219]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35:  92%|█████████▏| 140/153 [00:27<00:02,  5.02it/s, loss=0.110, v_num=0, train_loss_step=0.000708, val_loss=0.311, val_acc=0.918, train_loss_epoch=0.219]\n",
      "Epoch 36:  85%|████████▍ | 130/153 [00:23<00:04,  5.43it/s, loss=0.241, v_num=0, train_loss_step=0.0283, val_loss=0.311, val_acc=0.918, train_loss_epoch=0.215]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36:  92%|█████████▏| 140/153 [00:27<00:02,  5.15it/s, loss=0.224, v_num=0, train_loss_step=0.228, val_loss=0.88, val_acc=0.721, train_loss_epoch=0.215]  \n",
      "Epoch 37:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.174, v_num=0, train_loss_step=0.0255, val_loss=0.88, val_acc=0.721, train_loss_epoch=0.218]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.249, v_num=0, train_loss_step=0.434, val_loss=0.407, val_acc=0.885, train_loss_epoch=0.218]\n",
      "Epoch 38:  85%|████████▍ | 130/153 [00:24<00:04,  5.32it/s, loss=0.199, v_num=0, train_loss_step=0.0768, val_loss=0.407, val_acc=0.885, train_loss_epoch=0.237]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.162, v_num=0, train_loss_step=0.00457, val_loss=0.273, val_acc=0.918, train_loss_epoch=0.237]\n",
      "Epoch 39:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.272, v_num=0, train_loss_step=0.0543, val_loss=0.273, val_acc=0.918, train_loss_epoch=0.228] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.612, v_num=0, train_loss_step=0.67, val_loss=0.326, val_acc=0.902, train_loss_epoch=0.228]  \n",
      "Epoch 40:  85%|████████▍ | 130/153 [00:24<00:04,  5.31it/s, loss=0.176, v_num=0, train_loss_step=0.211, val_loss=0.326, val_acc=0.902, train_loss_epoch=0.24]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 40:  92%|█████████▏| 140/153 [00:27<00:02,  5.02it/s, loss=0.139, v_num=0, train_loss_step=0.00259, val_loss=0.246, val_acc=0.934, train_loss_epoch=0.24]\n",
      "Epoch 41:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.185, v_num=0, train_loss_step=0.104, val_loss=0.246, val_acc=0.934, train_loss_epoch=0.222] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 41:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.154, v_num=0, train_loss_step=0.126, val_loss=0.238, val_acc=0.918, train_loss_epoch=0.222]\n",
      "Epoch 42:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.220, v_num=0, train_loss_step=0.513, val_loss=0.238, val_acc=0.918, train_loss_epoch=0.2]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 42:  92%|█████████▏| 140/153 [00:27<00:02,  5.03it/s, loss=0.263, v_num=0, train_loss_step=0.0184, val_loss=0.258, val_acc=0.934, train_loss_epoch=0.2]\n",
      "Epoch 43:  85%|████████▍ | 130/153 [00:24<00:04,  5.39it/s, loss=0.452, v_num=0, train_loss_step=0.00181, val_loss=0.258, val_acc=0.934, train_loss_epoch=0.209]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 43:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.385, v_num=0, train_loss_step=0.097, val_loss=0.283, val_acc=0.918, train_loss_epoch=0.209]  \n",
      "Epoch 44:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.348, v_num=0, train_loss_step=0.187, val_loss=0.283, val_acc=0.918, train_loss_epoch=0.27]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 44:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.324, v_num=0, train_loss_step=0.053, val_loss=0.37, val_acc=0.902, train_loss_epoch=0.27] \n",
      "Epoch 45:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.110, v_num=0, train_loss_step=0.0375, val_loss=0.37, val_acc=0.902, train_loss_epoch=0.196] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 45:  92%|█████████▏| 140/153 [00:27<00:02,  5.13it/s, loss=0.131, v_num=0, train_loss_step=0.0773, val_loss=0.24, val_acc=0.934, train_loss_epoch=0.196]\n",
      "Epoch 46:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.309, v_num=0, train_loss_step=0.0304, val_loss=0.24, val_acc=0.934, train_loss_epoch=0.174] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.308, v_num=0, train_loss_step=0.0154, val_loss=0.281, val_acc=0.934, train_loss_epoch=0.174]\n",
      "Epoch 47:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.156, v_num=0, train_loss_step=0.0168, val_loss=0.281, val_acc=0.934, train_loss_epoch=0.236]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 47:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.116, v_num=0, train_loss_step=0.0539, val_loss=0.234, val_acc=0.934, train_loss_epoch=0.236]\n",
      "Epoch 48:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.141, v_num=0, train_loss_step=0.00315, val_loss=0.234, val_acc=0.934, train_loss_epoch=0.221]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 48:  92%|█████████▏| 140/153 [00:27<00:02,  5.11it/s, loss=0.098, v_num=0, train_loss_step=0.0198, val_loss=0.262, val_acc=0.918, train_loss_epoch=0.221] \n",
      "Epoch 49:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.098, v_num=0, train_loss_step=0.0274, val_loss=0.262, val_acc=0.918, train_loss_epoch=0.226] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 49:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.106, v_num=0, train_loss_step=0.00425, val_loss=0.284, val_acc=0.934, train_loss_epoch=0.226]\n",
      "Epoch 50:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.148, v_num=0, train_loss_step=0.0592, val_loss=0.284, val_acc=0.934, train_loss_epoch=0.218] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 50:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.230, v_num=0, train_loss_step=0.0161, val_loss=0.232, val_acc=0.934, train_loss_epoch=0.218]\n",
      "Epoch 51:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.173, v_num=0, train_loss_step=0.0729, val_loss=0.232, val_acc=0.934, train_loss_epoch=0.152] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 51:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.193, v_num=0, train_loss_step=1.15, val_loss=0.282, val_acc=0.934, train_loss_epoch=0.152]  \n",
      "Epoch 52:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.154, v_num=0, train_loss_step=0.163, val_loss=0.282, val_acc=0.934, train_loss_epoch=0.167]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 52:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.174, v_num=0, train_loss_step=0.922, val_loss=0.245, val_acc=0.934, train_loss_epoch=0.167]\n",
      "Epoch 53:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.263, v_num=0, train_loss_step=0.865, val_loss=0.245, val_acc=0.934, train_loss_epoch=0.171]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 53:  92%|█████████▏| 140/153 [00:27<00:02,  5.03it/s, loss=0.308, v_num=0, train_loss_step=0.0511, val_loss=0.204, val_acc=0.934, train_loss_epoch=0.171]\n",
      "Epoch 54:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.148, v_num=0, train_loss_step=0.0284, val_loss=0.204, val_acc=0.934, train_loss_epoch=0.162] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 54:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.096, v_num=0, train_loss_step=0.0556, val_loss=0.284, val_acc=0.918, train_loss_epoch=0.162]\n",
      "Epoch 55:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.088, v_num=0, train_loss_step=0.0406, val_loss=0.284, val_acc=0.918, train_loss_epoch=0.161] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 55:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.118, v_num=0, train_loss_step=0.0018, val_loss=0.214, val_acc=0.934, train_loss_epoch=0.161]\n",
      "Epoch 56:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.213, v_num=0, train_loss_step=0.522, val_loss=0.214, val_acc=0.934, train_loss_epoch=0.154] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 56:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.136, v_num=0, train_loss_step=0.00172, val_loss=0.324, val_acc=0.902, train_loss_epoch=0.154]\n",
      "Epoch 57:  85%|████████▍ | 130/153 [00:24<00:04,  5.30it/s, loss=0.096, v_num=0, train_loss_step=0.101, val_loss=0.324, val_acc=0.902, train_loss_epoch=0.177]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 57:  92%|█████████▏| 140/153 [00:27<00:02,  5.04it/s, loss=0.114, v_num=0, train_loss_step=0.00153, val_loss=0.243, val_acc=0.934, train_loss_epoch=0.177]\n",
      "Epoch 58:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.164, v_num=0, train_loss_step=0.0355, val_loss=0.243, val_acc=0.934, train_loss_epoch=0.134] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 58:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.134, v_num=0, train_loss_step=0.0412, val_loss=0.207, val_acc=0.934, train_loss_epoch=0.134]\n",
      "Epoch 59:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.183, v_num=0, train_loss_step=0.463, val_loss=0.207, val_acc=0.934, train_loss_epoch=0.149] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 59:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.127, v_num=0, train_loss_step=0.149, val_loss=0.224, val_acc=0.934, train_loss_epoch=0.149]\n",
      "Epoch 60:  85%|████████▍ | 130/153 [00:23<00:04,  5.44it/s, loss=0.119, v_num=0, train_loss_step=0.0184, val_loss=0.224, val_acc=0.934, train_loss_epoch=0.155]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 60:  92%|█████████▏| 140/153 [00:27<00:02,  5.14it/s, loss=0.084, v_num=0, train_loss_step=0.42, val_loss=0.227, val_acc=0.934, train_loss_epoch=0.155]  \n",
      "Epoch 61:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.139, v_num=0, train_loss_step=0.000579, val_loss=0.227, val_acc=0.934, train_loss_epoch=0.156]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 61:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.165, v_num=0, train_loss_step=0.00194, val_loss=0.255, val_acc=0.934, train_loss_epoch=0.156] \n",
      "Epoch 62:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.187, v_num=0, train_loss_step=0.113, val_loss=0.255, val_acc=0.934, train_loss_epoch=0.135]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 62:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.202, v_num=0, train_loss_step=0.000281, val_loss=0.235, val_acc=0.934, train_loss_epoch=0.135]\n",
      "Epoch 63:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.117, v_num=0, train_loss_step=0.0534, val_loss=0.235, val_acc=0.934, train_loss_epoch=0.144]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 63:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.242, v_num=0, train_loss_step=0.162, val_loss=0.255, val_acc=0.934, train_loss_epoch=0.144] \n",
      "Epoch 64:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.225, v_num=0, train_loss_step=0.127, val_loss=0.255, val_acc=0.934, train_loss_epoch=0.16] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 64:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.221, v_num=0, train_loss_step=0.00158, val_loss=0.231, val_acc=0.934, train_loss_epoch=0.16]\n",
      "Epoch 65:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.111, v_num=0, train_loss_step=0.0484, val_loss=0.231, val_acc=0.934, train_loss_epoch=0.139] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 65:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.165, v_num=0, train_loss_step=1.29, val_loss=0.222, val_acc=0.934, train_loss_epoch=0.139]  \n",
      "Epoch 66:  85%|████████▍ | 130/153 [00:24<00:04,  5.41it/s, loss=0.204, v_num=0, train_loss_step=0.105, val_loss=0.222, val_acc=0.934, train_loss_epoch=0.147]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 66:  92%|█████████▏| 140/153 [00:27<00:02,  5.13it/s, loss=0.232, v_num=0, train_loss_step=0.0328, val_loss=0.308, val_acc=0.918, train_loss_epoch=0.147]\n",
      "Epoch 67:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.200, v_num=0, train_loss_step=0.101, val_loss=0.308, val_acc=0.918, train_loss_epoch=0.146] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 67:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.237, v_num=0, train_loss_step=0.0598, val_loss=0.311, val_acc=0.918, train_loss_epoch=0.146]\n",
      "Epoch 68:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.180, v_num=0, train_loss_step=0.0238, val_loss=0.311, val_acc=0.918, train_loss_epoch=0.155] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 68:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.291, v_num=0, train_loss_step=1.53, val_loss=0.227, val_acc=0.934, train_loss_epoch=0.155]  \n",
      "Epoch 69:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.145, v_num=0, train_loss_step=0.0313, val_loss=0.227, val_acc=0.934, train_loss_epoch=0.182] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.155, v_num=0, train_loss_step=0.00451, val_loss=0.257, val_acc=0.918, train_loss_epoch=0.182]\n",
      "Epoch 70:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.155, v_num=0, train_loss_step=0.0715, val_loss=0.257, val_acc=0.918, train_loss_epoch=0.154] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 70:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.177, v_num=0, train_loss_step=0.00137, val_loss=0.202, val_acc=0.934, train_loss_epoch=0.154]\n",
      "Epoch 71:  85%|████████▍ | 130/153 [00:23<00:04,  5.42it/s, loss=0.309, v_num=0, train_loss_step=0.00215, val_loss=0.202, val_acc=0.934, train_loss_epoch=0.152]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 71:  92%|█████████▏| 140/153 [00:27<00:02,  5.13it/s, loss=0.256, v_num=0, train_loss_step=0.000422, val_loss=0.264, val_acc=0.934, train_loss_epoch=0.152]\n",
      "Epoch 72:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.074, v_num=0, train_loss_step=0.0122, val_loss=0.264, val_acc=0.934, train_loss_epoch=0.134]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 72:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.111, v_num=0, train_loss_step=0.000792, val_loss=0.256, val_acc=0.934, train_loss_epoch=0.134]\n",
      "Epoch 73:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.063, v_num=0, train_loss_step=0.0213, val_loss=0.256, val_acc=0.934, train_loss_epoch=0.171]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 73:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.069, v_num=0, train_loss_step=0.0655, val_loss=0.235, val_acc=0.934, train_loss_epoch=0.171]\n",
      "Epoch 74:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.118, v_num=0, train_loss_step=0.000978, val_loss=0.235, val_acc=0.934, train_loss_epoch=0.116]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 74:  92%|█████████▏| 140/153 [00:27<00:02,  5.02it/s, loss=0.141, v_num=0, train_loss_step=0.00363, val_loss=0.192, val_acc=0.934, train_loss_epoch=0.116] \n",
      "Epoch 75:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.137, v_num=0, train_loss_step=0.0386, val_loss=0.192, val_acc=0.934, train_loss_epoch=0.136] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 75:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.196, v_num=0, train_loss_step=0.131, val_loss=0.232, val_acc=0.934, train_loss_epoch=0.136] \n",
      "Epoch 76:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.045, v_num=0, train_loss_step=0.0163, val_loss=0.232, val_acc=0.934, train_loss_epoch=0.12]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 76:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.085, v_num=0, train_loss_step=0.137, val_loss=0.2, val_acc=0.934, train_loss_epoch=0.12]   \n",
      "Epoch 77:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.125, v_num=0, train_loss_step=0.656, val_loss=0.2, val_acc=0.934, train_loss_epoch=0.11]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 77:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.126, v_num=0, train_loss_step=0.104, val_loss=0.191, val_acc=0.934, train_loss_epoch=0.11]\n",
      "Epoch 78:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.209, v_num=0, train_loss_step=0.267, val_loss=0.191, val_acc=0.934, train_loss_epoch=0.103]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 78:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.208, v_num=0, train_loss_step=0.296, val_loss=0.216, val_acc=0.934, train_loss_epoch=0.103]\n",
      "Epoch 79:  85%|████████▍ | 130/153 [00:24<00:04,  5.32it/s, loss=0.098, v_num=0, train_loss_step=0.0667, val_loss=0.216, val_acc=0.934, train_loss_epoch=0.144] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 79:  92%|█████████▏| 140/153 [00:27<00:02,  5.05it/s, loss=0.097, v_num=0, train_loss_step=0.0772, val_loss=0.222, val_acc=0.934, train_loss_epoch=0.144]\n",
      "Epoch 80:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.122, v_num=0, train_loss_step=0.884, val_loss=0.222, val_acc=0.934, train_loss_epoch=0.131] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 80:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.108, v_num=0, train_loss_step=0.144, val_loss=0.21, val_acc=0.934, train_loss_epoch=0.131] \n",
      "Epoch 81:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.069, v_num=0, train_loss_step=0.00967, val_loss=0.21, val_acc=0.934, train_loss_epoch=0.0995]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 81:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.145, v_num=0, train_loss_step=0.00057, val_loss=0.204, val_acc=0.934, train_loss_epoch=0.0995]\n",
      "Epoch 82:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.165, v_num=0, train_loss_step=0.00273, val_loss=0.204, val_acc=0.934, train_loss_epoch=0.113] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 82:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.174, v_num=0, train_loss_step=0.000723, val_loss=0.159, val_acc=0.934, train_loss_epoch=0.113]\n",
      "Epoch 83:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.084, v_num=0, train_loss_step=0.0146, val_loss=0.159, val_acc=0.934, train_loss_epoch=0.108]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 83:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.052, v_num=0, train_loss_step=0.128, val_loss=0.177, val_acc=0.934, train_loss_epoch=0.108] \n",
      "Epoch 84:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.098, v_num=0, train_loss_step=0.461, val_loss=0.177, val_acc=0.934, train_loss_epoch=0.112] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 84:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.111, v_num=0, train_loss_step=0.23, val_loss=0.193, val_acc=0.934, train_loss_epoch=0.112] \n",
      "Epoch 85:  85%|████████▍ | 130/153 [00:24<00:04,  5.30it/s, loss=0.172, v_num=0, train_loss_step=0.255, val_loss=0.193, val_acc=0.934, train_loss_epoch=0.101] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 85:  92%|█████████▏| 140/153 [00:27<00:02,  5.01it/s, loss=0.243, v_num=0, train_loss_step=0.000417, val_loss=0.208, val_acc=0.951, train_loss_epoch=0.101]\n",
      "Epoch 86:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.104, v_num=0, train_loss_step=0.335, val_loss=0.208, val_acc=0.951, train_loss_epoch=0.0985]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 86:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.158, v_num=0, train_loss_step=1.16, val_loss=0.218, val_acc=0.934, train_loss_epoch=0.0985] \n",
      "Epoch 87:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.082, v_num=0, train_loss_step=0.0213, val_loss=0.218, val_acc=0.934, train_loss_epoch=0.119] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 87:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.096, v_num=0, train_loss_step=0.0718, val_loss=0.244, val_acc=0.934, train_loss_epoch=0.119]\n",
      "Epoch 88:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.059, v_num=0, train_loss_step=0.375, val_loss=0.244, val_acc=0.934, train_loss_epoch=0.107] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 88:  92%|█████████▏| 140/153 [00:27<00:02,  5.11it/s, loss=0.062, v_num=0, train_loss_step=0.214, val_loss=0.231, val_acc=0.934, train_loss_epoch=0.107]\n",
      "Epoch 89:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.117, v_num=0, train_loss_step=0.153, val_loss=0.231, val_acc=0.934, train_loss_epoch=0.107]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 89:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.110, v_num=0, train_loss_step=0.114, val_loss=0.223, val_acc=0.918, train_loss_epoch=0.107]\n",
      "Epoch 90:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.209, v_num=0, train_loss_step=0.536, val_loss=0.223, val_acc=0.918, train_loss_epoch=0.0972] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 90:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.176, v_num=0, train_loss_step=0.000556, val_loss=0.186, val_acc=0.934, train_loss_epoch=0.0972]\n",
      "Epoch 91:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.248, v_num=0, train_loss_step=1.56, val_loss=0.186, val_acc=0.934, train_loss_epoch=0.117]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 91:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.210, v_num=0, train_loss_step=0.00101, val_loss=0.19, val_acc=0.951, train_loss_epoch=0.117]\n",
      "Epoch 92:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.119, v_num=0, train_loss_step=0.342, val_loss=0.19, val_acc=0.951, train_loss_epoch=0.116]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.136, v_num=0, train_loss_step=0.0987, val_loss=0.343, val_acc=0.918, train_loss_epoch=0.116]\n",
      "Epoch 93:  85%|████████▍ | 130/153 [00:24<00:04,  5.41it/s, loss=0.136, v_num=0, train_loss_step=0.00909, val_loss=0.343, val_acc=0.918, train_loss_epoch=0.126]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 93:  92%|█████████▏| 140/153 [00:27<00:02,  5.14it/s, loss=0.122, v_num=0, train_loss_step=9.86e-5, val_loss=0.176, val_acc=0.934, train_loss_epoch=0.126]\n",
      "Epoch 94:  85%|████████▍ | 130/153 [00:24<00:04,  5.31it/s, loss=0.074, v_num=0, train_loss_step=0.00856, val_loss=0.176, val_acc=0.934, train_loss_epoch=0.117]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 94:  92%|█████████▏| 140/153 [00:27<00:02,  5.05it/s, loss=0.101, v_num=0, train_loss_step=0.187, val_loss=0.249, val_acc=0.951, train_loss_epoch=0.117]  \n",
      "Epoch 95:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.072, v_num=0, train_loss_step=0.0948, val_loss=0.249, val_acc=0.951, train_loss_epoch=0.0961] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 95:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.134, v_num=0, train_loss_step=1.8, val_loss=0.199, val_acc=0.934, train_loss_epoch=0.0961]   \n",
      "Epoch 96:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.096, v_num=0, train_loss_step=0.4, val_loss=0.199, val_acc=0.934, train_loss_epoch=0.104]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 96:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.114, v_num=0, train_loss_step=0.017, val_loss=0.234, val_acc=0.934, train_loss_epoch=0.104]\n",
      "Epoch 97:  85%|████████▍ | 130/153 [00:24<00:04,  5.41it/s, loss=0.161, v_num=0, train_loss_step=0.0108, val_loss=0.234, val_acc=0.934, train_loss_epoch=0.0969]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 97:  92%|█████████▏| 140/153 [00:27<00:02,  5.11it/s, loss=0.147, v_num=0, train_loss_step=0.0612, val_loss=0.247, val_acc=0.934, train_loss_epoch=0.0969]\n",
      "Epoch 98:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.121, v_num=0, train_loss_step=0.00646, val_loss=0.247, val_acc=0.934, train_loss_epoch=0.101]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 98:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.049, v_num=0, train_loss_step=0.000359, val_loss=0.23, val_acc=0.934, train_loss_epoch=0.101]\n",
      "Epoch 99:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.094, v_num=0, train_loss_step=0.607, val_loss=0.23, val_acc=0.934, train_loss_epoch=0.0913]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 99:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.094, v_num=0, train_loss_step=0.0261, val_loss=0.176, val_acc=0.934, train_loss_epoch=0.0913]\n",
      "Epoch 100:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.073, v_num=0, train_loss_step=0.00189, val_loss=0.176, val_acc=0.934, train_loss_epoch=0.0943]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 100:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.062, v_num=0, train_loss_step=0.0146, val_loss=0.158, val_acc=0.934, train_loss_epoch=0.0943] \n",
      "Epoch 101:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.076, v_num=0, train_loss_step=0.369, val_loss=0.158, val_acc=0.934, train_loss_epoch=0.0886]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 101:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.068, v_num=0, train_loss_step=0.0197, val_loss=0.17, val_acc=0.934, train_loss_epoch=0.0886]\n",
      "Epoch 102:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.098, v_num=0, train_loss_step=0.00947, val_loss=0.17, val_acc=0.934, train_loss_epoch=0.0886]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 102:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.091, v_num=0, train_loss_step=0.00198, val_loss=0.139, val_acc=0.934, train_loss_epoch=0.0886]\n",
      "Epoch 103:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.079, v_num=0, train_loss_step=0.0394, val_loss=0.139, val_acc=0.934, train_loss_epoch=0.0963] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 103:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.083, v_num=0, train_loss_step=0.115, val_loss=0.17, val_acc=0.951, train_loss_epoch=0.0963]  \n",
      "Epoch 104:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.097, v_num=0, train_loss_step=0.00129, val_loss=0.17, val_acc=0.951, train_loss_epoch=0.085]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 104:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.109, v_num=0, train_loss_step=0.00696, val_loss=0.201, val_acc=0.934, train_loss_epoch=0.085]\n",
      "Epoch 105:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.107, v_num=0, train_loss_step=0.00112, val_loss=0.201, val_acc=0.934, train_loss_epoch=0.0854]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 105:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.089, v_num=0, train_loss_step=0.0262, val_loss=0.181, val_acc=0.934, train_loss_epoch=0.0854] \n",
      "Epoch 106:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.056, v_num=0, train_loss_step=0.0495, val_loss=0.181, val_acc=0.934, train_loss_epoch=0.0788]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 106:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.060, v_num=0, train_loss_step=0.00579, val_loss=0.166, val_acc=0.934, train_loss_epoch=0.0788]\n",
      "Epoch 107:  85%|████████▍ | 130/153 [00:24<00:04,  5.25it/s, loss=0.093, v_num=0, train_loss_step=0.32, val_loss=0.166, val_acc=0.934, train_loss_epoch=0.0927]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 107:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.131, v_num=0, train_loss_step=0.00338, val_loss=0.165, val_acc=0.951, train_loss_epoch=0.0927]\n",
      "Epoch 108:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.077, v_num=0, train_loss_step=0.000641, val_loss=0.165, val_acc=0.951, train_loss_epoch=0.0749]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 108:  92%|█████████▏| 140/153 [00:27<00:02,  5.05it/s, loss=0.045, v_num=0, train_loss_step=0.00104, val_loss=0.171, val_acc=0.934, train_loss_epoch=0.0749] \n",
      "Epoch 109:  85%|████████▍ | 130/153 [00:25<00:04,  5.19it/s, loss=0.015, v_num=0, train_loss_step=0.00277, val_loss=0.171, val_acc=0.934, train_loss_epoch=0.079] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 109:  92%|█████████▏| 140/153 [00:28<00:02,  4.90it/s, loss=0.045, v_num=0, train_loss_step=0.00149, val_loss=0.163, val_acc=0.951, train_loss_epoch=0.079]\n",
      "Epoch 110:  85%|████████▍ | 130/153 [00:25<00:04,  5.04it/s, loss=0.080, v_num=0, train_loss_step=0.432, val_loss=0.163, val_acc=0.951, train_loss_epoch=0.0892]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 110:  92%|█████████▏| 140/153 [00:29<00:02,  4.81it/s, loss=0.154, v_num=0, train_loss_step=0.000182, val_loss=0.255, val_acc=0.934, train_loss_epoch=0.0892]\n",
      "Epoch 111:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.052, v_num=0, train_loss_step=0.00255, val_loss=0.255, val_acc=0.934, train_loss_epoch=0.107]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 111:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.056, v_num=0, train_loss_step=0.00644, val_loss=0.16, val_acc=0.934, train_loss_epoch=0.107] \n",
      "Epoch 112:  85%|████████▍ | 130/153 [00:25<00:04,  5.16it/s, loss=0.084, v_num=0, train_loss_step=0.00105, val_loss=0.16, val_acc=0.934, train_loss_epoch=0.0804]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 112:  92%|█████████▏| 140/153 [00:28<00:02,  4.91it/s, loss=0.072, v_num=0, train_loss_step=0.00179, val_loss=0.143, val_acc=0.951, train_loss_epoch=0.0804]\n",
      "Epoch 113:  85%|████████▍ | 130/153 [00:25<00:04,  5.08it/s, loss=0.045, v_num=0, train_loss_step=0.00159, val_loss=0.143, val_acc=0.951, train_loss_epoch=0.0628]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 113:  92%|█████████▏| 140/153 [00:29<00:02,  4.82it/s, loss=0.021, v_num=0, train_loss_step=0.0818, val_loss=0.131, val_acc=0.951, train_loss_epoch=0.0628] \n",
      "Epoch 114:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.089, v_num=0, train_loss_step=0.0224, val_loss=0.131, val_acc=0.951, train_loss_epoch=0.0721] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 114:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.077, v_num=0, train_loss_step=0.00447, val_loss=0.113, val_acc=0.934, train_loss_epoch=0.0721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115:  85%|████████▍ | 130/153 [00:26<00:04,  4.83it/s, loss=0.078, v_num=0, train_loss_step=0.348, val_loss=0.113, val_acc=0.934, train_loss_epoch=0.0825]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 115:  92%|█████████▏| 140/153 [00:30<00:02,  4.55it/s, loss=0.047, v_num=0, train_loss_step=0.000976, val_loss=0.198, val_acc=0.951, train_loss_epoch=0.0825]\n",
      "Epoch 116:  85%|████████▍ | 130/153 [00:28<00:05,  4.56it/s, loss=0.058, v_num=0, train_loss_step=0.0103, val_loss=0.198, val_acc=0.951, train_loss_epoch=0.0709]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 116:  92%|█████████▏| 140/153 [00:32<00:02,  4.34it/s, loss=0.087, v_num=0, train_loss_step=0.457, val_loss=0.168, val_acc=0.951, train_loss_epoch=0.0709] \n",
      "Epoch 117:  85%|████████▍ | 130/153 [00:26<00:04,  4.84it/s, loss=0.100, v_num=0, train_loss_step=0.34, val_loss=0.168, val_acc=0.951, train_loss_epoch=0.0687]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 117:  92%|█████████▏| 140/153 [00:30<00:02,  4.58it/s, loss=0.070, v_num=0, train_loss_step=0.00145, val_loss=0.164, val_acc=0.967, train_loss_epoch=0.0687]\n",
      "Epoch 118:  85%|████████▍ | 130/153 [00:26<00:04,  4.83it/s, loss=0.027, v_num=0, train_loss_step=0.08, val_loss=0.164, val_acc=0.967, train_loss_epoch=0.0705]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 118:  92%|█████████▏| 140/153 [00:30<00:02,  4.60it/s, loss=0.049, v_num=0, train_loss_step=0.0133, val_loss=0.176, val_acc=0.951, train_loss_epoch=0.0705]\n",
      "Epoch 119:  85%|████████▍ | 130/153 [00:25<00:04,  5.08it/s, loss=0.043, v_num=0, train_loss_step=0.00461, val_loss=0.176, val_acc=0.951, train_loss_epoch=0.0877]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 119:  92%|█████████▏| 140/153 [00:29<00:02,  4.79it/s, loss=0.046, v_num=0, train_loss_step=0.000945, val_loss=0.165, val_acc=0.934, train_loss_epoch=0.0877]\n",
      "Epoch 120:  52%|█████▏    | 80/153 [00:21<00:19,  3.67it/s, loss=0.120, v_num=0, train_loss_step=0.000362, val_loss=0.165, val_acc=0.934, train_loss_epoch=0.0746] "
     ]
    }
   ],
   "source": [
    "configs['DATASET']['AUGMENTATION'] = 'noise'\n",
    "configs['DATASET']['NOISE_PATH']= '../datasets/MUSAN/free-sound/'\n",
    "configs['LOSS'] = 'cross_entropy'\n",
    "configs['CHECKPOINT']['SAVE_NAME'] = 'crnn-bmw-noise'\n",
    "torch.cuda.empty_cache()\n",
    "do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs['DATASET']['AUGMENTATION'] = 'noise'\n",
    "configs['DATASET']['NOISE_PATH']= '../datasets/MUSAN/free-sound/'\n",
    "configs['LOSS'] = 'label_smoothing_cross_entropy'\n",
    "configs['CHECKPOINT']['SAVE_NAME'] = 'crnn-bmw-noise-ls0.1'\n",
    "torch.cuda.empty_cache()\n",
    "do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs['DATASET']['AUGMENTATION'] = 'uniform'\n",
    "configs['LOSS'] = 'cross_entropy'\n",
    "configs['CHECKPOINT']['SAVE_NAME'] = 'crnn-bmw-uniform'\n",
    "torch.cuda.empty_cache()\n",
    "do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs['DATASET']['AUGMENTATION'] = 'uniform'\n",
    "configs['LOSS'] = 'label_smoothing_cross_entropy'\n",
    "configs['CHECKPOINT']['SAVE_NAME'] = 'crnn-bmw-uniform-ls0.1'\n",
    "torch.cuda.empty_cache()\n",
    "do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs['DATASET']['AUGMENTATION'] = 'gaussian'\n",
    "configs['LOSS'] = 'cross_entropy'\n",
    "configs['CHECKPOINT']['SAVE_NAME'] = 'crnn-bmw-gaussian'\n",
    "torch.cuda.empty_cache()\n",
    "do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs['DATASET']['AUGMENTATION'] = 'gaussian'\n",
    "configs['LOSS'] = 'label_smoothing_cross_entropy'\n",
    "configs['CHECKPOINT']['SAVE_NAME'] = 'crnn-bmw-gaussian-ls0.1'\n",
    "torch.cuda.empty_cache()\n",
    "do_train(configs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
