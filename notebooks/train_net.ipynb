{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "pkg_path = \"/nfs/homedirs/yuny/project-1/audio_classification\"\n",
    "if pkg_path not in sys.path:\n",
    "    sys.path.append(pkg_path)\n",
    "    \n",
    "import yaml\n",
    "from audio_classification.tools import do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"/nfs/homedirs/yuny/project-1/audio_classification/configs/crnn_urbansound8k.yaml\", \"r\") as config_file:\n",
    "    configs = yaml.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name        | Type        | Params\n",
      "---------------------------------------------\n",
      "0  | conv1       | Conv2d      | 640   \n",
      "1  | bn1         | BatchNorm2d | 128   \n",
      "2  | dropout1    | Dropout     | 0     \n",
      "3  | conv2       | Conv2d      | 73 K  \n",
      "4  | bn2         | BatchNorm2d | 256   \n",
      "5  | dropout2    | Dropout     | 0     \n",
      "6  | conv3       | Conv2d      | 147 K \n",
      "7  | bn3         | BatchNorm2d | 256   \n",
      "8  | dropout3    | Dropout     | 0     \n",
      "9  | conv4       | Conv2d      | 147 K \n",
      "10 | bn4         | BatchNorm2d | 256   \n",
      "11 | dropout4    | Dropout     | 0     \n",
      "12 | rnn         | GRU         | 21 K  \n",
      "13 | dropout_rnn | Dropout     | 0     \n",
      "14 | linear      | Linear      | 330   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  89%|████████▉ | 650/728 [01:44<00:12,  6.19it/s, loss=2.056, v_num=10, train_loss_step=2.26]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 660/728 [01:50<00:11,  5.96it/s, loss=2.056, v_num=10, train_loss_step=2.26]\n",
      "Epoch 0:  92%|█████████▏| 670/728 [01:54<00:09,  5.86it/s, loss=2.056, v_num=10, train_loss_step=2.26]\n",
      "Epoch 0:  93%|█████████▎| 680/728 [01:55<00:08,  5.89it/s, loss=2.056, v_num=10, train_loss_step=2.26]\n",
      "Epoch 0:  95%|█████████▍| 690/728 [01:56<00:06,  5.94it/s, loss=2.056, v_num=10, train_loss_step=2.26]\n",
      "Epoch 0:  96%|█████████▌| 700/728 [01:56<00:04,  5.99it/s, loss=2.056, v_num=10, train_loss_step=2.26]\n",
      "Epoch 0:  98%|█████████▊| 710/728 [01:57<00:02,  6.06it/s, loss=2.056, v_num=10, train_loss_step=2.26]\n",
      "Epoch 0:  99%|█████████▉| 720/728 [01:57<00:01,  6.11it/s, loss=2.024, v_num=10, train_loss_step=1.76, val_loss=1.93, val_acc=0.278]\n",
      "Epoch 1:  89%|████████▉ | 650/728 [01:44<00:12,  6.22it/s, loss=1.777, v_num=10, train_loss_step=1.68, val_loss=1.93, val_acc=0.278, train_loss_epoch=2.04]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 660/728 [01:50<00:11,  6.00it/s, loss=1.777, v_num=10, train_loss_step=1.68, val_loss=1.93, val_acc=0.278, train_loss_epoch=2.04]\n",
      "Epoch 1:  92%|█████████▏| 670/728 [01:53<00:09,  5.90it/s, loss=1.777, v_num=10, train_loss_step=1.68, val_loss=1.93, val_acc=0.278, train_loss_epoch=2.04]\n",
      "Epoch 1:  93%|█████████▎| 680/728 [01:54<00:08,  5.93it/s, loss=1.777, v_num=10, train_loss_step=1.68, val_loss=1.93, val_acc=0.278, train_loss_epoch=2.04]\n",
      "Epoch 1:  95%|█████████▍| 690/728 [01:55<00:06,  5.98it/s, loss=1.777, v_num=10, train_loss_step=1.68, val_loss=1.93, val_acc=0.278, train_loss_epoch=2.04]\n",
      "Epoch 1:  96%|█████████▌| 700/728 [01:56<00:04,  6.02it/s, loss=1.777, v_num=10, train_loss_step=1.68, val_loss=1.93, val_acc=0.278, train_loss_epoch=2.04]\n",
      "Epoch 1:  98%|█████████▊| 710/728 [01:56<00:02,  6.10it/s, loss=1.777, v_num=10, train_loss_step=1.68, val_loss=1.93, val_acc=0.278, train_loss_epoch=2.04]\n",
      "Epoch 1:  99%|█████████▉| 720/728 [01:57<00:01,  6.15it/s, loss=1.830, v_num=10, train_loss_step=1.87, val_loss=1.62, val_acc=0.302, train_loss_epoch=2.04]\n",
      "Epoch 2:  29%|██▉       | 210/728 [00:37<01:33,  5.53it/s, loss=1.826, v_num=10, train_loss_step=1.78, val_loss=1.62, val_acc=0.302, train_loss_epoch=1.88]"
     ]
    }
   ],
   "source": [
    "test_loader = do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Temporary testing procedure, will move to do_train in the future\n",
    "\"\"\"\n",
    "from audio_classification.model import lit_m18\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "map_location = 'cuda'\n",
    "model = lit_m18.load_from_checkpoint(\n",
    "    checkpoint_path='/nfs/students/winter-term-2020/project-1/project-1/weights/m18-epoch=19-val_acc=0.803.ckpt',\n",
    "    cfg=configs,\n",
    "    map_location=map_location\n",
    ")\n",
    "trainer = pl.Trainer()\n",
    "\n",
    "trainer.test(model, test_dataloaders=test_loader)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
