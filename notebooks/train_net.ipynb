{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "pkg_path = \"/nfs/homedirs/yuny/project-1/audio_classification\"\n",
    "if pkg_path not in sys.path:\n",
    "    sys.path.append(pkg_path)\n",
    "    \n",
    "import yaml\n",
    "import torch\n",
    "from audio_classification.tools import do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/nfs/homedirs/yuny/project-1/audio_classification/configs/crnn_bmw.yaml\", \"r\") as config_file:\n",
    "    configs = yaml.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: noise\n",
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name        | Type        | Params\n",
      "---------------------------------------------\n",
      "0  | conv1       | Conv2d      | 640   \n",
      "1  | bn1         | BatchNorm2d | 128   \n",
      "2  | dropout1    | Dropout     | 0     \n",
      "3  | conv2       | Conv2d      | 73 K  \n",
      "4  | bn2         | BatchNorm2d | 256   \n",
      "5  | dropout2    | Dropout     | 0     \n",
      "6  | conv3       | Conv2d      | 147 K \n",
      "7  | bn3         | BatchNorm2d | 256   \n",
      "8  | dropout3    | Dropout     | 0     \n",
      "9  | conv4       | Conv2d      | 147 K \n",
      "10 | bn4         | BatchNorm2d | 256   \n",
      "11 | dropout4    | Dropout     | 0     \n",
      "12 | rnn         | GRU         | 21 K  \n",
      "13 | dropout_rnn | Dropout     | 0     \n",
      "14 | linear      | Linear      | 198   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.965, v_num=0, train_loss_step=0.497]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.985, v_num=0, train_loss_step=0.588, val_loss=1.03, val_acc=0.623]\n",
      "Epoch 1:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.786, v_num=0, train_loss_step=0.985, val_loss=1.03, val_acc=0.623, train_loss_epoch=1.21]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.819, v_num=0, train_loss_step=0.521, val_loss=1.04, val_acc=0.656, train_loss_epoch=1.21]\n",
      "Epoch 2:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=1.088, v_num=0, train_loss_step=1.13, val_loss=1.04, val_acc=0.656, train_loss_epoch=1.05] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.972, v_num=0, train_loss_step=0.453, val_loss=0.935, val_acc=0.656, train_loss_epoch=1.05]\n",
      "Epoch 3:  85%|████████▍ | 130/153 [00:24<00:04,  5.41it/s, loss=0.910, v_num=0, train_loss_step=1.08, val_loss=0.935, val_acc=0.656, train_loss_epoch=1.04] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.895, v_num=0, train_loss_step=1.28, val_loss=0.864, val_acc=0.672, train_loss_epoch=1.04]\n",
      "Epoch 4:  85%|████████▍ | 130/153 [00:24<00:04,  5.39it/s, loss=0.785, v_num=0, train_loss_step=2.12, val_loss=0.864, val_acc=0.672, train_loss_epoch=0.936]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 140/153 [00:27<00:02,  5.11it/s, loss=0.901, v_num=0, train_loss_step=0.796, val_loss=0.849, val_acc=0.738, train_loss_epoch=0.936]\n",
      "Epoch 5:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.657, v_num=0, train_loss_step=0.422, val_loss=0.849, val_acc=0.738, train_loss_epoch=0.909]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.711, v_num=0, train_loss_step=1.11, val_loss=0.748, val_acc=0.738, train_loss_epoch=0.909] \n",
      "Epoch 6:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.683, v_num=0, train_loss_step=1.34, val_loss=0.748, val_acc=0.738, train_loss_epoch=0.788]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.687, v_num=0, train_loss_step=0.138, val_loss=0.793, val_acc=0.721, train_loss_epoch=0.788]\n",
      "Epoch 7:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.661, v_num=0, train_loss_step=0.471, val_loss=0.793, val_acc=0.721, train_loss_epoch=0.732]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.697, v_num=0, train_loss_step=1.11, val_loss=0.726, val_acc=0.689, train_loss_epoch=0.732] \n",
      "Epoch 8:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.659, v_num=0, train_loss_step=0.562, val_loss=0.726, val_acc=0.689, train_loss_epoch=0.69]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.614, v_num=0, train_loss_step=0.225, val_loss=0.564, val_acc=0.787, train_loss_epoch=0.69]\n",
      "Epoch 9:  85%|████████▍ | 130/153 [00:24<00:04,  5.32it/s, loss=0.507, v_num=0, train_loss_step=0.473, val_loss=0.564, val_acc=0.787, train_loss_epoch=0.604]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.493, v_num=0, train_loss_step=0.0347, val_loss=0.628, val_acc=0.754, train_loss_epoch=0.604]\n",
      "Epoch 10:  85%|████████▍ | 130/153 [00:24<00:04,  5.31it/s, loss=0.667, v_num=0, train_loss_step=0.0328, val_loss=0.628, val_acc=0.754, train_loss_epoch=0.552]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 140/153 [00:27<00:02,  5.05it/s, loss=0.508, v_num=0, train_loss_step=1.7, val_loss=0.49, val_acc=0.82, train_loss_epoch=0.552]     \n",
      "Epoch 11:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.480, v_num=0, train_loss_step=0.473, val_loss=0.49, val_acc=0.82, train_loss_epoch=0.597]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.541, v_num=0, train_loss_step=0.504, val_loss=0.58, val_acc=0.787, train_loss_epoch=0.597]\n",
      "Epoch 12:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.469, v_num=0, train_loss_step=0.0979, val_loss=0.58, val_acc=0.787, train_loss_epoch=0.472]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 140/153 [00:27<00:02,  5.01it/s, loss=0.427, v_num=0, train_loss_step=1.4, val_loss=0.434, val_acc=0.852, train_loss_epoch=0.472]  \n",
      "Epoch 13:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.495, v_num=0, train_loss_step=0.182, val_loss=0.434, val_acc=0.852, train_loss_epoch=0.489] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.425, v_num=0, train_loss_step=0.333, val_loss=0.42, val_acc=0.902, train_loss_epoch=0.489] \n",
      "Epoch 14:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.510, v_num=0, train_loss_step=0.189, val_loss=0.42, val_acc=0.902, train_loss_epoch=0.484]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.427, v_num=0, train_loss_step=0.238, val_loss=0.593, val_acc=0.787, train_loss_epoch=0.484]\n",
      "Epoch 15:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.527, v_num=0, train_loss_step=0.0295, val_loss=0.593, val_acc=0.787, train_loss_epoch=0.513]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.465, v_num=0, train_loss_step=0.115, val_loss=0.375, val_acc=0.902, train_loss_epoch=0.513] \n",
      "Epoch 16:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.379, v_num=0, train_loss_step=0.717, val_loss=0.375, val_acc=0.902, train_loss_epoch=0.446]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.446, v_num=0, train_loss_step=0.144, val_loss=0.392, val_acc=0.869, train_loss_epoch=0.446]\n",
      "Epoch 17:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.353, v_num=0, train_loss_step=0.335, val_loss=0.392, val_acc=0.869, train_loss_epoch=0.462]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.360, v_num=0, train_loss_step=0.0797, val_loss=0.411, val_acc=0.869, train_loss_epoch=0.462]\n",
      "Epoch 18:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.350, v_num=0, train_loss_step=0.0548, val_loss=0.411, val_acc=0.869, train_loss_epoch=0.462]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.249, v_num=0, train_loss_step=1.07, val_loss=0.43, val_acc=0.852, train_loss_epoch=0.462]   \n",
      "Epoch 19:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.319, v_num=0, train_loss_step=0.149, val_loss=0.43, val_acc=0.852, train_loss_epoch=0.391] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.294, v_num=0, train_loss_step=0.0674, val_loss=0.36, val_acc=0.902, train_loss_epoch=0.391]\n",
      "Epoch 20:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.363, v_num=0, train_loss_step=0.751, val_loss=0.36, val_acc=0.902, train_loss_epoch=0.396]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.413, v_num=0, train_loss_step=1.28, val_loss=0.351, val_acc=0.885, train_loss_epoch=0.396]\n",
      "Epoch 21:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.293, v_num=0, train_loss_step=0.0695, val_loss=0.351, val_acc=0.885, train_loss_epoch=0.352]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.311, v_num=0, train_loss_step=0.502, val_loss=0.434, val_acc=0.869, train_loss_epoch=0.352] \n",
      "Epoch 22:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.370, v_num=0, train_loss_step=0.545, val_loss=0.434, val_acc=0.869, train_loss_epoch=0.428] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  92%|█████████▏| 140/153 [00:27<00:02,  5.11it/s, loss=0.461, v_num=0, train_loss_step=0.394, val_loss=0.514, val_acc=0.836, train_loss_epoch=0.428]\n",
      "Epoch 23:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.422, v_num=0, train_loss_step=0.0218, val_loss=0.514, val_acc=0.836, train_loss_epoch=0.342] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.458, v_num=0, train_loss_step=1.37, val_loss=0.564, val_acc=0.803, train_loss_epoch=0.342]  \n",
      "Epoch 24:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.404, v_num=0, train_loss_step=0.176, val_loss=0.564, val_acc=0.803, train_loss_epoch=0.384] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.424, v_num=0, train_loss_step=0.829, val_loss=0.506, val_acc=0.803, train_loss_epoch=0.384]\n",
      "Epoch 25:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.281, v_num=0, train_loss_step=0.0313, val_loss=0.506, val_acc=0.803, train_loss_epoch=0.424]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.268, v_num=0, train_loss_step=0.0031, val_loss=0.315, val_acc=0.902, train_loss_epoch=0.424]\n",
      "Epoch 26:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.221, v_num=0, train_loss_step=0.785, val_loss=0.315, val_acc=0.902, train_loss_epoch=0.301] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.178, v_num=0, train_loss_step=0.0506, val_loss=0.307, val_acc=0.902, train_loss_epoch=0.301]\n",
      "Epoch 27:  85%|████████▍ | 130/153 [00:24<00:04,  5.39it/s, loss=0.304, v_num=0, train_loss_step=0.0491, val_loss=0.307, val_acc=0.902, train_loss_epoch=0.277]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.303, v_num=0, train_loss_step=0.0988, val_loss=0.343, val_acc=0.885, train_loss_epoch=0.277]\n",
      "Epoch 28:  85%|████████▍ | 130/153 [00:23<00:04,  5.42it/s, loss=0.235, v_num=0, train_loss_step=0.431, val_loss=0.343, val_acc=0.885, train_loss_epoch=0.28]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28:  92%|█████████▏| 140/153 [00:27<00:02,  5.13it/s, loss=0.227, v_num=0, train_loss_step=0.0142, val_loss=0.333, val_acc=0.902, train_loss_epoch=0.28]\n",
      "Epoch 29:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.136, v_num=0, train_loss_step=0.15, val_loss=0.333, val_acc=0.902, train_loss_epoch=0.252]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.138, v_num=0, train_loss_step=0.0767, val_loss=0.323, val_acc=0.902, train_loss_epoch=0.252]\n",
      "Epoch 30:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.308, v_num=0, train_loss_step=0.0661, val_loss=0.323, val_acc=0.902, train_loss_epoch=0.209]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.242, v_num=0, train_loss_step=0.00398, val_loss=0.439, val_acc=0.869, train_loss_epoch=0.209]\n",
      "Epoch 31:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.260, v_num=0, train_loss_step=0.0127, val_loss=0.439, val_acc=0.869, train_loss_epoch=0.262] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.235, v_num=0, train_loss_step=0.00165, val_loss=0.297, val_acc=0.902, train_loss_epoch=0.262]\n",
      "Epoch 32:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.333, v_num=0, train_loss_step=0.0364, val_loss=0.297, val_acc=0.902, train_loss_epoch=0.235] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.371, v_num=0, train_loss_step=0.195, val_loss=0.27, val_acc=0.918, train_loss_epoch=0.235]  \n",
      "Epoch 33:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.211, v_num=0, train_loss_step=0.238, val_loss=0.27, val_acc=0.918, train_loss_epoch=0.253] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.238, v_num=0, train_loss_step=0.17, val_loss=0.488, val_acc=0.852, train_loss_epoch=0.253]\n",
      "Epoch 34:  85%|████████▍ | 130/153 [00:24<00:04,  5.30it/s, loss=0.214, v_num=0, train_loss_step=0.003, val_loss=0.488, val_acc=0.852, train_loss_epoch=0.253]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34:  92%|█████████▏| 140/153 [00:27<00:02,  5.02it/s, loss=0.191, v_num=0, train_loss_step=0.0022, val_loss=0.284, val_acc=0.902, train_loss_epoch=0.253]\n",
      "Epoch 35:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.287, v_num=0, train_loss_step=0.24, val_loss=0.284, val_acc=0.902, train_loss_epoch=0.219]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35:  92%|█████████▏| 140/153 [00:27<00:02,  5.02it/s, loss=0.110, v_num=0, train_loss_step=0.000708, val_loss=0.311, val_acc=0.918, train_loss_epoch=0.219]\n",
      "Epoch 36:  85%|████████▍ | 130/153 [00:23<00:04,  5.43it/s, loss=0.241, v_num=0, train_loss_step=0.0283, val_loss=0.311, val_acc=0.918, train_loss_epoch=0.215]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36:  92%|█████████▏| 140/153 [00:27<00:02,  5.15it/s, loss=0.224, v_num=0, train_loss_step=0.228, val_loss=0.88, val_acc=0.721, train_loss_epoch=0.215]  \n",
      "Epoch 37:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.174, v_num=0, train_loss_step=0.0255, val_loss=0.88, val_acc=0.721, train_loss_epoch=0.218]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.249, v_num=0, train_loss_step=0.434, val_loss=0.407, val_acc=0.885, train_loss_epoch=0.218]\n",
      "Epoch 38:  85%|████████▍ | 130/153 [00:24<00:04,  5.32it/s, loss=0.199, v_num=0, train_loss_step=0.0768, val_loss=0.407, val_acc=0.885, train_loss_epoch=0.237]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.162, v_num=0, train_loss_step=0.00457, val_loss=0.273, val_acc=0.918, train_loss_epoch=0.237]\n",
      "Epoch 39:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.272, v_num=0, train_loss_step=0.0543, val_loss=0.273, val_acc=0.918, train_loss_epoch=0.228] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.612, v_num=0, train_loss_step=0.67, val_loss=0.326, val_acc=0.902, train_loss_epoch=0.228]  \n",
      "Epoch 40:  85%|████████▍ | 130/153 [00:24<00:04,  5.31it/s, loss=0.176, v_num=0, train_loss_step=0.211, val_loss=0.326, val_acc=0.902, train_loss_epoch=0.24]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 40:  92%|█████████▏| 140/153 [00:27<00:02,  5.02it/s, loss=0.139, v_num=0, train_loss_step=0.00259, val_loss=0.246, val_acc=0.934, train_loss_epoch=0.24]\n",
      "Epoch 41:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.185, v_num=0, train_loss_step=0.104, val_loss=0.246, val_acc=0.934, train_loss_epoch=0.222] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 41:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.154, v_num=0, train_loss_step=0.126, val_loss=0.238, val_acc=0.918, train_loss_epoch=0.222]\n",
      "Epoch 42:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.220, v_num=0, train_loss_step=0.513, val_loss=0.238, val_acc=0.918, train_loss_epoch=0.2]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 42:  92%|█████████▏| 140/153 [00:27<00:02,  5.03it/s, loss=0.263, v_num=0, train_loss_step=0.0184, val_loss=0.258, val_acc=0.934, train_loss_epoch=0.2]\n",
      "Epoch 43:  85%|████████▍ | 130/153 [00:24<00:04,  5.39it/s, loss=0.452, v_num=0, train_loss_step=0.00181, val_loss=0.258, val_acc=0.934, train_loss_epoch=0.209]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 43:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.385, v_num=0, train_loss_step=0.097, val_loss=0.283, val_acc=0.918, train_loss_epoch=0.209]  \n",
      "Epoch 44:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.348, v_num=0, train_loss_step=0.187, val_loss=0.283, val_acc=0.918, train_loss_epoch=0.27]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 44:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.324, v_num=0, train_loss_step=0.053, val_loss=0.37, val_acc=0.902, train_loss_epoch=0.27] \n",
      "Epoch 45:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.110, v_num=0, train_loss_step=0.0375, val_loss=0.37, val_acc=0.902, train_loss_epoch=0.196] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 45:  92%|█████████▏| 140/153 [00:27<00:02,  5.13it/s, loss=0.131, v_num=0, train_loss_step=0.0773, val_loss=0.24, val_acc=0.934, train_loss_epoch=0.196]\n",
      "Epoch 46:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.309, v_num=0, train_loss_step=0.0304, val_loss=0.24, val_acc=0.934, train_loss_epoch=0.174] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.308, v_num=0, train_loss_step=0.0154, val_loss=0.281, val_acc=0.934, train_loss_epoch=0.174]\n",
      "Epoch 47:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.156, v_num=0, train_loss_step=0.0168, val_loss=0.281, val_acc=0.934, train_loss_epoch=0.236]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 47:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.116, v_num=0, train_loss_step=0.0539, val_loss=0.234, val_acc=0.934, train_loss_epoch=0.236]\n",
      "Epoch 48:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.141, v_num=0, train_loss_step=0.00315, val_loss=0.234, val_acc=0.934, train_loss_epoch=0.221]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 48:  92%|█████████▏| 140/153 [00:27<00:02,  5.11it/s, loss=0.098, v_num=0, train_loss_step=0.0198, val_loss=0.262, val_acc=0.918, train_loss_epoch=0.221] \n",
      "Epoch 49:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.098, v_num=0, train_loss_step=0.0274, val_loss=0.262, val_acc=0.918, train_loss_epoch=0.226] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 49:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.106, v_num=0, train_loss_step=0.00425, val_loss=0.284, val_acc=0.934, train_loss_epoch=0.226]\n",
      "Epoch 50:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.148, v_num=0, train_loss_step=0.0592, val_loss=0.284, val_acc=0.934, train_loss_epoch=0.218] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 50:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.230, v_num=0, train_loss_step=0.0161, val_loss=0.232, val_acc=0.934, train_loss_epoch=0.218]\n",
      "Epoch 51:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.173, v_num=0, train_loss_step=0.0729, val_loss=0.232, val_acc=0.934, train_loss_epoch=0.152] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 51:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.193, v_num=0, train_loss_step=1.15, val_loss=0.282, val_acc=0.934, train_loss_epoch=0.152]  \n",
      "Epoch 52:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.154, v_num=0, train_loss_step=0.163, val_loss=0.282, val_acc=0.934, train_loss_epoch=0.167]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 52:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.174, v_num=0, train_loss_step=0.922, val_loss=0.245, val_acc=0.934, train_loss_epoch=0.167]\n",
      "Epoch 53:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.263, v_num=0, train_loss_step=0.865, val_loss=0.245, val_acc=0.934, train_loss_epoch=0.171]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 53:  92%|█████████▏| 140/153 [00:27<00:02,  5.03it/s, loss=0.308, v_num=0, train_loss_step=0.0511, val_loss=0.204, val_acc=0.934, train_loss_epoch=0.171]\n",
      "Epoch 54:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.148, v_num=0, train_loss_step=0.0284, val_loss=0.204, val_acc=0.934, train_loss_epoch=0.162] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 54:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.096, v_num=0, train_loss_step=0.0556, val_loss=0.284, val_acc=0.918, train_loss_epoch=0.162]\n",
      "Epoch 55:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.088, v_num=0, train_loss_step=0.0406, val_loss=0.284, val_acc=0.918, train_loss_epoch=0.161] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 55:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.118, v_num=0, train_loss_step=0.0018, val_loss=0.214, val_acc=0.934, train_loss_epoch=0.161]\n",
      "Epoch 56:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.213, v_num=0, train_loss_step=0.522, val_loss=0.214, val_acc=0.934, train_loss_epoch=0.154] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 56:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.136, v_num=0, train_loss_step=0.00172, val_loss=0.324, val_acc=0.902, train_loss_epoch=0.154]\n",
      "Epoch 57:  85%|████████▍ | 130/153 [00:24<00:04,  5.30it/s, loss=0.096, v_num=0, train_loss_step=0.101, val_loss=0.324, val_acc=0.902, train_loss_epoch=0.177]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 57:  92%|█████████▏| 140/153 [00:27<00:02,  5.04it/s, loss=0.114, v_num=0, train_loss_step=0.00153, val_loss=0.243, val_acc=0.934, train_loss_epoch=0.177]\n",
      "Epoch 58:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.164, v_num=0, train_loss_step=0.0355, val_loss=0.243, val_acc=0.934, train_loss_epoch=0.134] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 58:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.134, v_num=0, train_loss_step=0.0412, val_loss=0.207, val_acc=0.934, train_loss_epoch=0.134]\n",
      "Epoch 59:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.183, v_num=0, train_loss_step=0.463, val_loss=0.207, val_acc=0.934, train_loss_epoch=0.149] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 59:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.127, v_num=0, train_loss_step=0.149, val_loss=0.224, val_acc=0.934, train_loss_epoch=0.149]\n",
      "Epoch 60:  85%|████████▍ | 130/153 [00:23<00:04,  5.44it/s, loss=0.119, v_num=0, train_loss_step=0.0184, val_loss=0.224, val_acc=0.934, train_loss_epoch=0.155]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 60:  92%|█████████▏| 140/153 [00:27<00:02,  5.14it/s, loss=0.084, v_num=0, train_loss_step=0.42, val_loss=0.227, val_acc=0.934, train_loss_epoch=0.155]  \n",
      "Epoch 61:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.139, v_num=0, train_loss_step=0.000579, val_loss=0.227, val_acc=0.934, train_loss_epoch=0.156]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 61:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.165, v_num=0, train_loss_step=0.00194, val_loss=0.255, val_acc=0.934, train_loss_epoch=0.156] \n",
      "Epoch 62:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.187, v_num=0, train_loss_step=0.113, val_loss=0.255, val_acc=0.934, train_loss_epoch=0.135]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 62:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.202, v_num=0, train_loss_step=0.000281, val_loss=0.235, val_acc=0.934, train_loss_epoch=0.135]\n",
      "Epoch 63:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.117, v_num=0, train_loss_step=0.0534, val_loss=0.235, val_acc=0.934, train_loss_epoch=0.144]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 63:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.242, v_num=0, train_loss_step=0.162, val_loss=0.255, val_acc=0.934, train_loss_epoch=0.144] \n",
      "Epoch 64:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.225, v_num=0, train_loss_step=0.127, val_loss=0.255, val_acc=0.934, train_loss_epoch=0.16] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 64:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.221, v_num=0, train_loss_step=0.00158, val_loss=0.231, val_acc=0.934, train_loss_epoch=0.16]\n",
      "Epoch 65:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.111, v_num=0, train_loss_step=0.0484, val_loss=0.231, val_acc=0.934, train_loss_epoch=0.139] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 65:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.165, v_num=0, train_loss_step=1.29, val_loss=0.222, val_acc=0.934, train_loss_epoch=0.139]  \n",
      "Epoch 66:  85%|████████▍ | 130/153 [00:24<00:04,  5.41it/s, loss=0.204, v_num=0, train_loss_step=0.105, val_loss=0.222, val_acc=0.934, train_loss_epoch=0.147]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 66:  92%|█████████▏| 140/153 [00:27<00:02,  5.13it/s, loss=0.232, v_num=0, train_loss_step=0.0328, val_loss=0.308, val_acc=0.918, train_loss_epoch=0.147]\n",
      "Epoch 67:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.200, v_num=0, train_loss_step=0.101, val_loss=0.308, val_acc=0.918, train_loss_epoch=0.146] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 67:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.237, v_num=0, train_loss_step=0.0598, val_loss=0.311, val_acc=0.918, train_loss_epoch=0.146]\n",
      "Epoch 68:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.180, v_num=0, train_loss_step=0.0238, val_loss=0.311, val_acc=0.918, train_loss_epoch=0.155] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 68:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.291, v_num=0, train_loss_step=1.53, val_loss=0.227, val_acc=0.934, train_loss_epoch=0.155]  \n",
      "Epoch 69:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.145, v_num=0, train_loss_step=0.0313, val_loss=0.227, val_acc=0.934, train_loss_epoch=0.182] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 69:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.155, v_num=0, train_loss_step=0.00451, val_loss=0.257, val_acc=0.918, train_loss_epoch=0.182]\n",
      "Epoch 70:  85%|████████▍ | 130/153 [00:24<00:04,  5.40it/s, loss=0.155, v_num=0, train_loss_step=0.0715, val_loss=0.257, val_acc=0.918, train_loss_epoch=0.154] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 70:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.177, v_num=0, train_loss_step=0.00137, val_loss=0.202, val_acc=0.934, train_loss_epoch=0.154]\n",
      "Epoch 71:  85%|████████▍ | 130/153 [00:23<00:04,  5.42it/s, loss=0.309, v_num=0, train_loss_step=0.00215, val_loss=0.202, val_acc=0.934, train_loss_epoch=0.152]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 71:  92%|█████████▏| 140/153 [00:27<00:02,  5.13it/s, loss=0.256, v_num=0, train_loss_step=0.000422, val_loss=0.264, val_acc=0.934, train_loss_epoch=0.152]\n",
      "Epoch 72:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.074, v_num=0, train_loss_step=0.0122, val_loss=0.264, val_acc=0.934, train_loss_epoch=0.134]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 72:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.111, v_num=0, train_loss_step=0.000792, val_loss=0.256, val_acc=0.934, train_loss_epoch=0.134]\n",
      "Epoch 73:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.063, v_num=0, train_loss_step=0.0213, val_loss=0.256, val_acc=0.934, train_loss_epoch=0.171]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 73:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.069, v_num=0, train_loss_step=0.0655, val_loss=0.235, val_acc=0.934, train_loss_epoch=0.171]\n",
      "Epoch 74:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.118, v_num=0, train_loss_step=0.000978, val_loss=0.235, val_acc=0.934, train_loss_epoch=0.116]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 74:  92%|█████████▏| 140/153 [00:27<00:02,  5.02it/s, loss=0.141, v_num=0, train_loss_step=0.00363, val_loss=0.192, val_acc=0.934, train_loss_epoch=0.116] \n",
      "Epoch 75:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.137, v_num=0, train_loss_step=0.0386, val_loss=0.192, val_acc=0.934, train_loss_epoch=0.136] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 75:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.196, v_num=0, train_loss_step=0.131, val_loss=0.232, val_acc=0.934, train_loss_epoch=0.136] \n",
      "Epoch 76:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.045, v_num=0, train_loss_step=0.0163, val_loss=0.232, val_acc=0.934, train_loss_epoch=0.12]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 76:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.085, v_num=0, train_loss_step=0.137, val_loss=0.2, val_acc=0.934, train_loss_epoch=0.12]   \n",
      "Epoch 77:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.125, v_num=0, train_loss_step=0.656, val_loss=0.2, val_acc=0.934, train_loss_epoch=0.11]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 77:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.126, v_num=0, train_loss_step=0.104, val_loss=0.191, val_acc=0.934, train_loss_epoch=0.11]\n",
      "Epoch 78:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.209, v_num=0, train_loss_step=0.267, val_loss=0.191, val_acc=0.934, train_loss_epoch=0.103]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 78:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.208, v_num=0, train_loss_step=0.296, val_loss=0.216, val_acc=0.934, train_loss_epoch=0.103]\n",
      "Epoch 79:  85%|████████▍ | 130/153 [00:24<00:04,  5.32it/s, loss=0.098, v_num=0, train_loss_step=0.0667, val_loss=0.216, val_acc=0.934, train_loss_epoch=0.144] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 79:  92%|█████████▏| 140/153 [00:27<00:02,  5.05it/s, loss=0.097, v_num=0, train_loss_step=0.0772, val_loss=0.222, val_acc=0.934, train_loss_epoch=0.144]\n",
      "Epoch 80:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.122, v_num=0, train_loss_step=0.884, val_loss=0.222, val_acc=0.934, train_loss_epoch=0.131] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 80:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.108, v_num=0, train_loss_step=0.144, val_loss=0.21, val_acc=0.934, train_loss_epoch=0.131] \n",
      "Epoch 81:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.069, v_num=0, train_loss_step=0.00967, val_loss=0.21, val_acc=0.934, train_loss_epoch=0.0995]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 81:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.145, v_num=0, train_loss_step=0.00057, val_loss=0.204, val_acc=0.934, train_loss_epoch=0.0995]\n",
      "Epoch 82:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.165, v_num=0, train_loss_step=0.00273, val_loss=0.204, val_acc=0.934, train_loss_epoch=0.113] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 82:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.174, v_num=0, train_loss_step=0.000723, val_loss=0.159, val_acc=0.934, train_loss_epoch=0.113]\n",
      "Epoch 83:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.084, v_num=0, train_loss_step=0.0146, val_loss=0.159, val_acc=0.934, train_loss_epoch=0.108]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 83:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.052, v_num=0, train_loss_step=0.128, val_loss=0.177, val_acc=0.934, train_loss_epoch=0.108] \n",
      "Epoch 84:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.098, v_num=0, train_loss_step=0.461, val_loss=0.177, val_acc=0.934, train_loss_epoch=0.112] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 84:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.111, v_num=0, train_loss_step=0.23, val_loss=0.193, val_acc=0.934, train_loss_epoch=0.112] \n",
      "Epoch 85:  85%|████████▍ | 130/153 [00:24<00:04,  5.30it/s, loss=0.172, v_num=0, train_loss_step=0.255, val_loss=0.193, val_acc=0.934, train_loss_epoch=0.101] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 85:  92%|█████████▏| 140/153 [00:27<00:02,  5.01it/s, loss=0.243, v_num=0, train_loss_step=0.000417, val_loss=0.208, val_acc=0.951, train_loss_epoch=0.101]\n",
      "Epoch 86:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.104, v_num=0, train_loss_step=0.335, val_loss=0.208, val_acc=0.951, train_loss_epoch=0.0985]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 86:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.158, v_num=0, train_loss_step=1.16, val_loss=0.218, val_acc=0.934, train_loss_epoch=0.0985] \n",
      "Epoch 87:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.082, v_num=0, train_loss_step=0.0213, val_loss=0.218, val_acc=0.934, train_loss_epoch=0.119] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 87:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.096, v_num=0, train_loss_step=0.0718, val_loss=0.244, val_acc=0.934, train_loss_epoch=0.119]\n",
      "Epoch 88:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.059, v_num=0, train_loss_step=0.375, val_loss=0.244, val_acc=0.934, train_loss_epoch=0.107] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 88:  92%|█████████▏| 140/153 [00:27<00:02,  5.11it/s, loss=0.062, v_num=0, train_loss_step=0.214, val_loss=0.231, val_acc=0.934, train_loss_epoch=0.107]\n",
      "Epoch 89:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.117, v_num=0, train_loss_step=0.153, val_loss=0.231, val_acc=0.934, train_loss_epoch=0.107]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 89:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.110, v_num=0, train_loss_step=0.114, val_loss=0.223, val_acc=0.918, train_loss_epoch=0.107]\n",
      "Epoch 90:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.209, v_num=0, train_loss_step=0.536, val_loss=0.223, val_acc=0.918, train_loss_epoch=0.0972] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 90:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.176, v_num=0, train_loss_step=0.000556, val_loss=0.186, val_acc=0.934, train_loss_epoch=0.0972]\n",
      "Epoch 91:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.248, v_num=0, train_loss_step=1.56, val_loss=0.186, val_acc=0.934, train_loss_epoch=0.117]     \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 91:  92%|█████████▏| 140/153 [00:27<00:02,  5.12it/s, loss=0.210, v_num=0, train_loss_step=0.00101, val_loss=0.19, val_acc=0.951, train_loss_epoch=0.117]\n",
      "Epoch 92:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.119, v_num=0, train_loss_step=0.342, val_loss=0.19, val_acc=0.951, train_loss_epoch=0.116]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.136, v_num=0, train_loss_step=0.0987, val_loss=0.343, val_acc=0.918, train_loss_epoch=0.116]\n",
      "Epoch 93:  85%|████████▍ | 130/153 [00:24<00:04,  5.41it/s, loss=0.136, v_num=0, train_loss_step=0.00909, val_loss=0.343, val_acc=0.918, train_loss_epoch=0.126]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 93:  92%|█████████▏| 140/153 [00:27<00:02,  5.14it/s, loss=0.122, v_num=0, train_loss_step=9.86e-5, val_loss=0.176, val_acc=0.934, train_loss_epoch=0.126]\n",
      "Epoch 94:  85%|████████▍ | 130/153 [00:24<00:04,  5.31it/s, loss=0.074, v_num=0, train_loss_step=0.00856, val_loss=0.176, val_acc=0.934, train_loss_epoch=0.117]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 94:  92%|█████████▏| 140/153 [00:27<00:02,  5.05it/s, loss=0.101, v_num=0, train_loss_step=0.187, val_loss=0.249, val_acc=0.951, train_loss_epoch=0.117]  \n",
      "Epoch 95:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.072, v_num=0, train_loss_step=0.0948, val_loss=0.249, val_acc=0.951, train_loss_epoch=0.0961] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 95:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.134, v_num=0, train_loss_step=1.8, val_loss=0.199, val_acc=0.934, train_loss_epoch=0.0961]   \n",
      "Epoch 96:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.096, v_num=0, train_loss_step=0.4, val_loss=0.199, val_acc=0.934, train_loss_epoch=0.104]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 96:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.114, v_num=0, train_loss_step=0.017, val_loss=0.234, val_acc=0.934, train_loss_epoch=0.104]\n",
      "Epoch 97:  85%|████████▍ | 130/153 [00:24<00:04,  5.41it/s, loss=0.161, v_num=0, train_loss_step=0.0108, val_loss=0.234, val_acc=0.934, train_loss_epoch=0.0969]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 97:  92%|█████████▏| 140/153 [00:27<00:02,  5.11it/s, loss=0.147, v_num=0, train_loss_step=0.0612, val_loss=0.247, val_acc=0.934, train_loss_epoch=0.0969]\n",
      "Epoch 98:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.121, v_num=0, train_loss_step=0.00646, val_loss=0.247, val_acc=0.934, train_loss_epoch=0.101]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 98:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.049, v_num=0, train_loss_step=0.000359, val_loss=0.23, val_acc=0.934, train_loss_epoch=0.101]\n",
      "Epoch 99:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.094, v_num=0, train_loss_step=0.607, val_loss=0.23, val_acc=0.934, train_loss_epoch=0.0913]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 99:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.094, v_num=0, train_loss_step=0.0261, val_loss=0.176, val_acc=0.934, train_loss_epoch=0.0913]\n",
      "Epoch 100:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.073, v_num=0, train_loss_step=0.00189, val_loss=0.176, val_acc=0.934, train_loss_epoch=0.0943]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 100:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.062, v_num=0, train_loss_step=0.0146, val_loss=0.158, val_acc=0.934, train_loss_epoch=0.0943] \n",
      "Epoch 101:  85%|████████▍ | 130/153 [00:24<00:04,  5.34it/s, loss=0.076, v_num=0, train_loss_step=0.369, val_loss=0.158, val_acc=0.934, train_loss_epoch=0.0886]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 101:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.068, v_num=0, train_loss_step=0.0197, val_loss=0.17, val_acc=0.934, train_loss_epoch=0.0886]\n",
      "Epoch 102:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.098, v_num=0, train_loss_step=0.00947, val_loss=0.17, val_acc=0.934, train_loss_epoch=0.0886]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 102:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.091, v_num=0, train_loss_step=0.00198, val_loss=0.139, val_acc=0.934, train_loss_epoch=0.0886]\n",
      "Epoch 103:  85%|████████▍ | 130/153 [00:24<00:04,  5.38it/s, loss=0.079, v_num=0, train_loss_step=0.0394, val_loss=0.139, val_acc=0.934, train_loss_epoch=0.0963] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 103:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.083, v_num=0, train_loss_step=0.115, val_loss=0.17, val_acc=0.951, train_loss_epoch=0.0963]  \n",
      "Epoch 104:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.097, v_num=0, train_loss_step=0.00129, val_loss=0.17, val_acc=0.951, train_loss_epoch=0.085]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 104:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.109, v_num=0, train_loss_step=0.00696, val_loss=0.201, val_acc=0.934, train_loss_epoch=0.085]\n",
      "Epoch 105:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.107, v_num=0, train_loss_step=0.00112, val_loss=0.201, val_acc=0.934, train_loss_epoch=0.0854]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 105:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.089, v_num=0, train_loss_step=0.0262, val_loss=0.181, val_acc=0.934, train_loss_epoch=0.0854] \n",
      "Epoch 106:  85%|████████▍ | 130/153 [00:24<00:04,  5.37it/s, loss=0.056, v_num=0, train_loss_step=0.0495, val_loss=0.181, val_acc=0.934, train_loss_epoch=0.0788]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 106:  92%|█████████▏| 140/153 [00:27<00:02,  5.10it/s, loss=0.060, v_num=0, train_loss_step=0.00579, val_loss=0.166, val_acc=0.934, train_loss_epoch=0.0788]\n",
      "Epoch 107:  85%|████████▍ | 130/153 [00:24<00:04,  5.25it/s, loss=0.093, v_num=0, train_loss_step=0.32, val_loss=0.166, val_acc=0.934, train_loss_epoch=0.0927]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 107:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.131, v_num=0, train_loss_step=0.00338, val_loss=0.165, val_acc=0.951, train_loss_epoch=0.0927]\n",
      "Epoch 108:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.077, v_num=0, train_loss_step=0.000641, val_loss=0.165, val_acc=0.951, train_loss_epoch=0.0749]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 108:  92%|█████████▏| 140/153 [00:27<00:02,  5.05it/s, loss=0.045, v_num=0, train_loss_step=0.00104, val_loss=0.171, val_acc=0.934, train_loss_epoch=0.0749] \n",
      "Epoch 109:  85%|████████▍ | 130/153 [00:25<00:04,  5.19it/s, loss=0.015, v_num=0, train_loss_step=0.00277, val_loss=0.171, val_acc=0.934, train_loss_epoch=0.079] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 109:  92%|█████████▏| 140/153 [00:28<00:02,  4.90it/s, loss=0.045, v_num=0, train_loss_step=0.00149, val_loss=0.163, val_acc=0.951, train_loss_epoch=0.079]\n",
      "Epoch 110:  85%|████████▍ | 130/153 [00:25<00:04,  5.04it/s, loss=0.080, v_num=0, train_loss_step=0.432, val_loss=0.163, val_acc=0.951, train_loss_epoch=0.0892]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 110:  92%|█████████▏| 140/153 [00:29<00:02,  4.81it/s, loss=0.154, v_num=0, train_loss_step=0.000182, val_loss=0.255, val_acc=0.934, train_loss_epoch=0.0892]\n",
      "Epoch 111:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.052, v_num=0, train_loss_step=0.00255, val_loss=0.255, val_acc=0.934, train_loss_epoch=0.107]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 111:  92%|█████████▏| 140/153 [00:27<00:02,  5.09it/s, loss=0.056, v_num=0, train_loss_step=0.00644, val_loss=0.16, val_acc=0.934, train_loss_epoch=0.107] \n",
      "Epoch 112:  85%|████████▍ | 130/153 [00:25<00:04,  5.16it/s, loss=0.084, v_num=0, train_loss_step=0.00105, val_loss=0.16, val_acc=0.934, train_loss_epoch=0.0804]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 112:  92%|█████████▏| 140/153 [00:28<00:02,  4.91it/s, loss=0.072, v_num=0, train_loss_step=0.00179, val_loss=0.143, val_acc=0.951, train_loss_epoch=0.0804]\n",
      "Epoch 113:  85%|████████▍ | 130/153 [00:25<00:04,  5.08it/s, loss=0.045, v_num=0, train_loss_step=0.00159, val_loss=0.143, val_acc=0.951, train_loss_epoch=0.0628]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 113:  92%|█████████▏| 140/153 [00:29<00:02,  4.82it/s, loss=0.021, v_num=0, train_loss_step=0.0818, val_loss=0.131, val_acc=0.951, train_loss_epoch=0.0628] \n",
      "Epoch 114:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.089, v_num=0, train_loss_step=0.0224, val_loss=0.131, val_acc=0.951, train_loss_epoch=0.0721] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 114:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.077, v_num=0, train_loss_step=0.00447, val_loss=0.113, val_acc=0.934, train_loss_epoch=0.0721]\n",
      "Epoch 115:  85%|████████▍ | 130/153 [00:26<00:04,  4.83it/s, loss=0.078, v_num=0, train_loss_step=0.348, val_loss=0.113, val_acc=0.934, train_loss_epoch=0.0825]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 115:  92%|█████████▏| 140/153 [00:30<00:02,  4.55it/s, loss=0.047, v_num=0, train_loss_step=0.000976, val_loss=0.198, val_acc=0.951, train_loss_epoch=0.0825]\n",
      "Epoch 116:  85%|████████▍ | 130/153 [00:28<00:05,  4.56it/s, loss=0.058, v_num=0, train_loss_step=0.0103, val_loss=0.198, val_acc=0.951, train_loss_epoch=0.0709]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 116:  92%|█████████▏| 140/153 [00:32<00:02,  4.34it/s, loss=0.087, v_num=0, train_loss_step=0.457, val_loss=0.168, val_acc=0.951, train_loss_epoch=0.0709] \n",
      "Epoch 117:  85%|████████▍ | 130/153 [00:26<00:04,  4.84it/s, loss=0.100, v_num=0, train_loss_step=0.34, val_loss=0.168, val_acc=0.951, train_loss_epoch=0.0687]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 117:  92%|█████████▏| 140/153 [00:30<00:02,  4.58it/s, loss=0.070, v_num=0, train_loss_step=0.00145, val_loss=0.164, val_acc=0.967, train_loss_epoch=0.0687]\n",
      "Epoch 118:  85%|████████▍ | 130/153 [00:26<00:04,  4.83it/s, loss=0.027, v_num=0, train_loss_step=0.08, val_loss=0.164, val_acc=0.967, train_loss_epoch=0.0705]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 118:  92%|█████████▏| 140/153 [00:30<00:02,  4.60it/s, loss=0.049, v_num=0, train_loss_step=0.0133, val_loss=0.176, val_acc=0.951, train_loss_epoch=0.0705]\n",
      "Epoch 119:  85%|████████▍ | 130/153 [00:25<00:04,  5.08it/s, loss=0.043, v_num=0, train_loss_step=0.00461, val_loss=0.176, val_acc=0.951, train_loss_epoch=0.0877]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 119:  92%|█████████▏| 140/153 [00:29<00:02,  4.79it/s, loss=0.046, v_num=0, train_loss_step=0.000945, val_loss=0.165, val_acc=0.934, train_loss_epoch=0.0877]\n",
      "Epoch 120:  85%|████████▍ | 130/153 [00:26<00:04,  4.90it/s, loss=0.071, v_num=0, train_loss_step=0.0715, val_loss=0.165, val_acc=0.934, train_loss_epoch=0.0746]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 120:  92%|█████████▏| 140/153 [00:29<00:02,  4.67it/s, loss=0.063, v_num=0, train_loss_step=0.00143, val_loss=0.16, val_acc=0.951, train_loss_epoch=0.0746]\n",
      "Epoch 121:  85%|████████▍ | 130/153 [00:25<00:04,  5.09it/s, loss=0.064, v_num=0, train_loss_step=0.0292, val_loss=0.16, val_acc=0.951, train_loss_epoch=0.0723]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 121:  92%|█████████▏| 140/153 [00:29<00:02,  4.82it/s, loss=0.053, v_num=0, train_loss_step=0.0328, val_loss=0.131, val_acc=0.984, train_loss_epoch=0.0723]\n",
      "Epoch 122:  85%|████████▍ | 130/153 [00:26<00:04,  4.91it/s, loss=0.069, v_num=0, train_loss_step=0.0428, val_loss=0.131, val_acc=0.984, train_loss_epoch=0.0718]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 122:  92%|█████████▏| 140/153 [00:29<00:02,  4.69it/s, loss=0.075, v_num=0, train_loss_step=0.0218, val_loss=0.156, val_acc=0.951, train_loss_epoch=0.0718]\n",
      "Epoch 123:  85%|████████▍ | 130/153 [00:25<00:04,  5.15it/s, loss=0.168, v_num=0, train_loss_step=0.545, val_loss=0.156, val_acc=0.951, train_loss_epoch=0.0781]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 123:  92%|█████████▏| 140/153 [00:28<00:02,  4.89it/s, loss=0.147, v_num=0, train_loss_step=0.000418, val_loss=0.157, val_acc=0.951, train_loss_epoch=0.0781]\n",
      "Epoch 124:  85%|████████▍ | 130/153 [00:25<00:04,  5.07it/s, loss=0.056, v_num=0, train_loss_step=0.00632, val_loss=0.157, val_acc=0.951, train_loss_epoch=0.0847] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 124:  92%|█████████▏| 140/153 [00:29<00:02,  4.77it/s, loss=0.113, v_num=0, train_loss_step=0.799, val_loss=0.199, val_acc=0.951, train_loss_epoch=0.0847]  \n",
      "Epoch 124:  92%|█████████▏| 140/153 [00:29<00:02,  4.76it/s, loss=0.113, v_num=0, train_loss_step=0.799, val_loss=0.199, val_acc=0.951, train_loss_epoch=0.0847]\n"
     ]
    }
   ],
   "source": [
    "configs['DATASET']['AUGMENTATION'] = 'noise'\n",
    "configs['DATASET']['NOISE_PATH']= '../datasets/MUSAN/free-sound/'\n",
    "configs['LOSS'] = 'cross_entropy'\n",
    "configs['CHECKPOINT']['SAVE_NAME'] = 'crnn-bmw-noise'\n",
    "torch.cuda.empty_cache()\n",
    "do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: noise\n",
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name        | Type        | Params\n",
      "---------------------------------------------\n",
      "0  | conv1       | Conv2d      | 640   \n",
      "1  | bn1         | BatchNorm2d | 128   \n",
      "2  | dropout1    | Dropout     | 0     \n",
      "3  | conv2       | Conv2d      | 73 K  \n",
      "4  | bn2         | BatchNorm2d | 256   \n",
      "5  | dropout2    | Dropout     | 0     \n",
      "6  | conv3       | Conv2d      | 147 K \n",
      "7  | bn3         | BatchNorm2d | 256   \n",
      "8  | dropout3    | Dropout     | 0     \n",
      "9  | conv4       | Conv2d      | 147 K \n",
      "10 | bn4         | BatchNorm2d | 256   \n",
      "11 | dropout4    | Dropout     | 0     \n",
      "12 | rnn         | GRU         | 21 K  \n",
      "13 | dropout_rnn | Dropout     | 0     \n",
      "14 | linear      | Linear      | 198   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  85%|████████▍ | 130/153 [00:25<00:04,  5.11it/s, loss=1.317, v_num=1, train_loss_step=1.15]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 140/153 [00:28<00:02,  4.85it/s, loss=1.315, v_num=1, train_loss_step=1.09, val_loss=1.14, val_acc=0.656]\n",
      "Epoch 1:  85%|████████▍ | 130/153 [00:26<00:04,  4.94it/s, loss=1.040, v_num=1, train_loss_step=0.648, val_loss=1.14, val_acc=0.656, train_loss_epoch=1.32]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 140/153 [00:29<00:02,  4.70it/s, loss=1.101, v_num=1, train_loss_step=1.63, val_loss=1.13, val_acc=0.689, train_loss_epoch=1.32] \n",
      "Epoch 2:  85%|████████▍ | 130/153 [00:26<00:04,  4.98it/s, loss=1.113, v_num=1, train_loss_step=1.86, val_loss=1.13, val_acc=0.689, train_loss_epoch=1.17] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 140/153 [00:29<00:02,  4.72it/s, loss=1.074, v_num=1, train_loss_step=0.862, val_loss=1.14, val_acc=0.607, train_loss_epoch=1.17]\n",
      "Epoch 3:  85%|████████▍ | 130/153 [00:26<00:04,  4.95it/s, loss=1.004, v_num=1, train_loss_step=0.671, val_loss=1.14, val_acc=0.607, train_loss_epoch=1.13]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 140/153 [00:29<00:02,  4.70it/s, loss=0.918, v_num=1, train_loss_step=1.27, val_loss=0.948, val_acc=0.754, train_loss_epoch=1.13]\n",
      "Epoch 4:  85%|████████▍ | 130/153 [00:25<00:04,  5.08it/s, loss=0.977, v_num=1, train_loss_step=0.907, val_loss=0.948, val_acc=0.754, train_loss_epoch=1.05]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 140/153 [00:29<00:02,  4.83it/s, loss=0.949, v_num=1, train_loss_step=0.625, val_loss=1.05, val_acc=0.689, train_loss_epoch=1.05] \n",
      "Epoch 5:  85%|████████▍ | 130/153 [00:26<00:04,  4.88it/s, loss=0.863, v_num=1, train_loss_step=0.766, val_loss=1.05, val_acc=0.689, train_loss_epoch=0.963]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 140/153 [00:30<00:02,  4.65it/s, loss=0.807, v_num=1, train_loss_step=0.529, val_loss=0.766, val_acc=0.852, train_loss_epoch=0.963]\n",
      "Epoch 6:  85%|████████▍ | 130/153 [00:25<00:04,  5.17it/s, loss=0.848, v_num=1, train_loss_step=0.862, val_loss=0.766, val_acc=0.852, train_loss_epoch=0.862]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 140/153 [00:28<00:02,  4.90it/s, loss=0.805, v_num=1, train_loss_step=1.39, val_loss=0.816, val_acc=0.836, train_loss_epoch=0.862] \n",
      "Epoch 7:  85%|████████▍ | 130/153 [00:26<00:04,  4.88it/s, loss=0.801, v_num=1, train_loss_step=0.815, val_loss=0.816, val_acc=0.836, train_loss_epoch=0.848]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 140/153 [00:30<00:02,  4.65it/s, loss=0.812, v_num=1, train_loss_step=1.27, val_loss=0.84, val_acc=0.787, train_loss_epoch=0.848]  \n",
      "Epoch 8:  85%|████████▍ | 130/153 [00:25<00:04,  5.10it/s, loss=0.831, v_num=1, train_loss_step=0.934, val_loss=0.84, val_acc=0.787, train_loss_epoch=0.837]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 140/153 [00:28<00:02,  4.84it/s, loss=0.766, v_num=1, train_loss_step=0.72, val_loss=0.82, val_acc=0.836, train_loss_epoch=0.837] \n",
      "Epoch 9:  85%|████████▍ | 130/153 [00:26<00:04,  4.98it/s, loss=0.736, v_num=1, train_loss_step=0.476, val_loss=0.82, val_acc=0.836, train_loss_epoch=0.765]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 140/153 [00:29<00:02,  4.69it/s, loss=0.789, v_num=1, train_loss_step=0.528, val_loss=0.982, val_acc=0.77, train_loss_epoch=0.765]\n",
      "Epoch 10:  85%|████████▍ | 130/153 [00:25<00:04,  5.09it/s, loss=0.949, v_num=1, train_loss_step=0.661, val_loss=0.982, val_acc=0.77, train_loss_epoch=0.762]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 140/153 [00:28<00:02,  4.84it/s, loss=0.845, v_num=1, train_loss_step=1.37, val_loss=0.75, val_acc=0.82, train_loss_epoch=0.762]  \n",
      "Epoch 11:  85%|████████▍ | 130/153 [00:26<00:04,  4.96it/s, loss=0.776, v_num=1, train_loss_step=0.66, val_loss=0.75, val_acc=0.82, train_loss_epoch=0.806] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 140/153 [00:29<00:02,  4.72it/s, loss=0.812, v_num=1, train_loss_step=0.735, val_loss=0.771, val_acc=0.82, train_loss_epoch=0.806]\n",
      "Epoch 12:  85%|████████▍ | 130/153 [00:25<00:04,  5.01it/s, loss=0.685, v_num=1, train_loss_step=1.5, val_loss=0.771, val_acc=0.82, train_loss_epoch=0.75]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 140/153 [00:29<00:02,  4.74it/s, loss=0.826, v_num=1, train_loss_step=0.681, val_loss=0.854, val_acc=0.803, train_loss_epoch=0.75]\n",
      "Epoch 13:  85%|████████▍ | 130/153 [00:26<00:04,  4.99it/s, loss=0.704, v_num=1, train_loss_step=0.435, val_loss=0.854, val_acc=0.803, train_loss_epoch=0.749]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  92%|█████████▏| 140/153 [00:29<00:02,  4.70it/s, loss=0.672, v_num=1, train_loss_step=0.446, val_loss=0.675, val_acc=0.885, train_loss_epoch=0.749]\n",
      "Epoch 14:  85%|████████▍ | 130/153 [00:25<00:04,  5.11it/s, loss=0.751, v_num=1, train_loss_step=0.539, val_loss=0.675, val_acc=0.885, train_loss_epoch=0.717]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  92%|█████████▏| 140/153 [00:28<00:02,  4.84it/s, loss=0.763, v_num=1, train_loss_step=0.463, val_loss=0.67, val_acc=0.885, train_loss_epoch=0.717] \n",
      "Epoch 15:  85%|████████▍ | 130/153 [00:25<00:04,  5.10it/s, loss=0.707, v_num=1, train_loss_step=0.466, val_loss=0.67, val_acc=0.885, train_loss_epoch=0.718]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  92%|█████████▏| 140/153 [00:29<00:02,  4.78it/s, loss=0.669, v_num=1, train_loss_step=0.688, val_loss=0.654, val_acc=0.902, train_loss_epoch=0.718]\n",
      "Epoch 16:  85%|████████▍ | 130/153 [00:25<00:04,  5.01it/s, loss=0.799, v_num=1, train_loss_step=0.948, val_loss=0.654, val_acc=0.902, train_loss_epoch=0.696]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  92%|█████████▏| 140/153 [00:29<00:02,  4.77it/s, loss=0.803, v_num=1, train_loss_step=0.471, val_loss=0.703, val_acc=0.885, train_loss_epoch=0.696]\n",
      "Epoch 17:  85%|████████▍ | 130/153 [00:25<00:04,  5.03it/s, loss=0.790, v_num=1, train_loss_step=0.63, val_loss=0.703, val_acc=0.885, train_loss_epoch=0.716] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  92%|█████████▏| 140/153 [00:29<00:02,  4.72it/s, loss=0.848, v_num=1, train_loss_step=1.08, val_loss=0.756, val_acc=0.852, train_loss_epoch=0.716]\n",
      "Epoch 18:  85%|████████▍ | 130/153 [00:26<00:04,  4.92it/s, loss=0.779, v_num=1, train_loss_step=0.539, val_loss=0.756, val_acc=0.852, train_loss_epoch=0.704]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  92%|█████████▏| 140/153 [00:29<00:02,  4.69it/s, loss=0.730, v_num=1, train_loss_step=0.524, val_loss=0.674, val_acc=0.902, train_loss_epoch=0.704]\n",
      "Epoch 19:  85%|████████▍ | 130/153 [00:25<00:04,  5.11it/s, loss=0.690, v_num=1, train_loss_step=0.703, val_loss=0.674, val_acc=0.902, train_loss_epoch=0.707]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  92%|█████████▏| 140/153 [00:29<00:02,  4.81it/s, loss=0.569, v_num=1, train_loss_step=0.431, val_loss=0.712, val_acc=0.852, train_loss_epoch=0.707]\n",
      "Epoch 20:  85%|████████▍ | 130/153 [00:26<00:04,  4.90it/s, loss=0.774, v_num=1, train_loss_step=0.567, val_loss=0.712, val_acc=0.852, train_loss_epoch=0.684]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  92%|█████████▏| 140/153 [00:29<00:02,  4.67it/s, loss=0.784, v_num=1, train_loss_step=1.3, val_loss=0.806, val_acc=0.803, train_loss_epoch=0.684]  \n",
      "Epoch 21:  85%|████████▍ | 130/153 [00:25<00:04,  5.11it/s, loss=0.682, v_num=1, train_loss_step=0.659, val_loss=0.806, val_acc=0.803, train_loss_epoch=0.69]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  92%|█████████▏| 140/153 [00:28<00:02,  4.84it/s, loss=0.700, v_num=1, train_loss_step=0.747, val_loss=0.643, val_acc=0.918, train_loss_epoch=0.69]\n",
      "Epoch 22:  85%|████████▍ | 130/153 [00:26<00:04,  4.91it/s, loss=0.686, v_num=1, train_loss_step=0.464, val_loss=0.643, val_acc=0.918, train_loss_epoch=0.726]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  92%|█████████▏| 140/153 [00:30<00:02,  4.64it/s, loss=0.613, v_num=1, train_loss_step=0.491, val_loss=0.646, val_acc=0.902, train_loss_epoch=0.726]\n",
      "Epoch 23:  85%|████████▍ | 130/153 [00:25<00:04,  5.03it/s, loss=0.654, v_num=1, train_loss_step=0.455, val_loss=0.646, val_acc=0.902, train_loss_epoch=0.65] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  92%|█████████▏| 140/153 [00:29<00:02,  4.78it/s, loss=0.704, v_num=1, train_loss_step=1.03, val_loss=0.695, val_acc=0.869, train_loss_epoch=0.65] \n",
      "Epoch 24:  85%|████████▍ | 130/153 [00:26<00:04,  4.85it/s, loss=0.662, v_num=1, train_loss_step=0.605, val_loss=0.695, val_acc=0.869, train_loss_epoch=0.671]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 140/153 [00:30<00:02,  4.60it/s, loss=0.625, v_num=1, train_loss_step=0.467, val_loss=0.738, val_acc=0.869, train_loss_epoch=0.671]\n",
      "Epoch 25:  85%|████████▍ | 130/153 [00:25<00:04,  5.09it/s, loss=0.661, v_num=1, train_loss_step=1.22, val_loss=0.738, val_acc=0.869, train_loss_epoch=0.655] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25:  92%|█████████▏| 140/153 [00:29<00:02,  4.81it/s, loss=0.683, v_num=1, train_loss_step=0.445, val_loss=0.62, val_acc=0.902, train_loss_epoch=0.655]\n",
      "Epoch 26:  85%|████████▍ | 130/153 [00:25<00:04,  5.19it/s, loss=0.654, v_num=1, train_loss_step=0.436, val_loss=0.62, val_acc=0.902, train_loss_epoch=0.627]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26:  92%|█████████▏| 140/153 [00:28<00:02,  4.92it/s, loss=0.591, v_num=1, train_loss_step=0.454, val_loss=0.606, val_acc=0.934, train_loss_epoch=0.627]\n",
      "Epoch 27:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.632, v_num=1, train_loss_step=0.694, val_loss=0.606, val_acc=0.934, train_loss_epoch=0.611]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27:  92%|█████████▏| 140/153 [00:27<00:02,  5.05it/s, loss=0.598, v_num=1, train_loss_step=0.444, val_loss=0.624, val_acc=0.902, train_loss_epoch=0.611]\n",
      "Epoch 28:  85%|████████▍ | 130/153 [00:25<00:04,  5.17it/s, loss=0.552, v_num=1, train_loss_step=0.464, val_loss=0.624, val_acc=0.902, train_loss_epoch=0.616]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28:  92%|█████████▏| 140/153 [00:28<00:02,  4.91it/s, loss=0.500, v_num=1, train_loss_step=0.441, val_loss=0.589, val_acc=0.934, train_loss_epoch=0.616]\n",
      "Epoch 29:  85%|████████▍ | 130/153 [00:24<00:04,  5.35it/s, loss=0.631, v_num=1, train_loss_step=0.657, val_loss=0.589, val_acc=0.934, train_loss_epoch=0.586]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29:  92%|█████████▏| 140/153 [00:27<00:02,  5.06it/s, loss=0.637, v_num=1, train_loss_step=0.435, val_loss=0.607, val_acc=0.902, train_loss_epoch=0.586]\n",
      "Epoch 30:  85%|████████▍ | 130/153 [00:24<00:04,  5.24it/s, loss=0.592, v_num=1, train_loss_step=0.51, val_loss=0.607, val_acc=0.902, train_loss_epoch=0.629] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30:  92%|█████████▏| 140/153 [00:28<00:02,  4.96it/s, loss=0.575, v_num=1, train_loss_step=0.435, val_loss=0.592, val_acc=0.934, train_loss_epoch=0.629]\n",
      "Epoch 31:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.632, v_num=1, train_loss_step=0.439, val_loss=0.592, val_acc=0.934, train_loss_epoch=0.596]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31:  92%|█████████▏| 140/153 [00:27<00:02,  5.03it/s, loss=0.686, v_num=1, train_loss_step=0.451, val_loss=0.595, val_acc=0.934, train_loss_epoch=0.596]\n",
      "Epoch 32:  85%|████████▍ | 130/153 [00:24<00:04,  5.25it/s, loss=0.543, v_num=1, train_loss_step=0.495, val_loss=0.595, val_acc=0.934, train_loss_epoch=0.607]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.577, v_num=1, train_loss_step=1.6, val_loss=0.635, val_acc=0.902, train_loss_epoch=0.607]  \n",
      "Epoch 33:  85%|████████▍ | 130/153 [00:24<00:04,  5.24it/s, loss=0.569, v_num=1, train_loss_step=0.444, val_loss=0.635, val_acc=0.902, train_loss_epoch=0.625]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33:  92%|█████████▏| 140/153 [00:28<00:02,  4.97it/s, loss=0.548, v_num=1, train_loss_step=0.429, val_loss=0.592, val_acc=0.918, train_loss_epoch=0.625]\n",
      "Epoch 34:  85%|████████▍ | 130/153 [00:24<00:04,  5.36it/s, loss=0.609, v_num=1, train_loss_step=0.802, val_loss=0.592, val_acc=0.918, train_loss_epoch=0.581]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34:  92%|█████████▏| 140/153 [00:27<00:02,  5.04it/s, loss=0.693, v_num=1, train_loss_step=1.43, val_loss=0.619, val_acc=0.934, train_loss_epoch=0.581] \n",
      "Epoch 35:  85%|████████▍ | 130/153 [00:24<00:04,  5.27it/s, loss=0.702, v_num=1, train_loss_step=0.434, val_loss=0.619, val_acc=0.934, train_loss_epoch=0.579]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.627, v_num=1, train_loss_step=0.707, val_loss=0.625, val_acc=0.918, train_loss_epoch=0.579]\n",
      "Epoch 36:  85%|████████▍ | 130/153 [00:24<00:04,  5.26it/s, loss=0.515, v_num=1, train_loss_step=0.609, val_loss=0.625, val_acc=0.918, train_loss_epoch=0.606]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.588, v_num=1, train_loss_step=0.442, val_loss=0.594, val_acc=0.934, train_loss_epoch=0.606]\n",
      "Epoch 37:  85%|████████▍ | 130/153 [00:24<00:04,  5.27it/s, loss=0.559, v_num=1, train_loss_step=0.444, val_loss=0.594, val_acc=0.934, train_loss_epoch=0.592]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37:  92%|█████████▏| 140/153 [00:28<00:02,  4.97it/s, loss=0.517, v_num=1, train_loss_step=0.469, val_loss=0.585, val_acc=0.934, train_loss_epoch=0.592]\n",
      "Epoch 38:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.540, v_num=1, train_loss_step=0.443, val_loss=0.585, val_acc=0.934, train_loss_epoch=0.567]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38:  92%|█████████▏| 140/153 [00:28<00:02,  4.99it/s, loss=0.565, v_num=1, train_loss_step=0.447, val_loss=0.585, val_acc=0.934, train_loss_epoch=0.567]\n",
      "Epoch 39:  85%|████████▍ | 130/153 [00:24<00:04,  5.27it/s, loss=0.598, v_num=1, train_loss_step=0.514, val_loss=0.585, val_acc=0.934, train_loss_epoch=0.556]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.623, v_num=1, train_loss_step=0.445, val_loss=0.765, val_acc=0.82, train_loss_epoch=0.556] \n",
      "Epoch 40:  85%|████████▍ | 130/153 [00:24<00:04,  5.25it/s, loss=0.581, v_num=1, train_loss_step=0.787, val_loss=0.765, val_acc=0.82, train_loss_epoch=0.581]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 40:  92%|█████████▏| 140/153 [00:28<00:02,  4.97it/s, loss=0.611, v_num=1, train_loss_step=0.433, val_loss=0.569, val_acc=0.918, train_loss_epoch=0.581]\n",
      "Epoch 41:  85%|████████▍ | 130/153 [00:25<00:04,  5.16it/s, loss=0.524, v_num=1, train_loss_step=0.48, val_loss=0.569, val_acc=0.918, train_loss_epoch=0.567] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 41:  92%|█████████▏| 140/153 [00:28<00:02,  4.87it/s, loss=0.522, v_num=1, train_loss_step=0.475, val_loss=0.605, val_acc=0.918, train_loss_epoch=0.567]\n",
      "Epoch 42:  85%|████████▍ | 130/153 [00:24<00:04,  5.22it/s, loss=0.609, v_num=1, train_loss_step=0.443, val_loss=0.605, val_acc=0.918, train_loss_epoch=0.572]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 42:  92%|█████████▏| 140/153 [00:28<00:02,  4.94it/s, loss=0.629, v_num=1, train_loss_step=0.439, val_loss=0.572, val_acc=0.918, train_loss_epoch=0.572]\n",
      "Epoch 43:  85%|████████▍ | 130/153 [00:24<00:04,  5.30it/s, loss=0.567, v_num=1, train_loss_step=0.444, val_loss=0.572, val_acc=0.918, train_loss_epoch=0.591]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 43:  92%|█████████▏| 140/153 [00:28<00:02,  5.00it/s, loss=0.570, v_num=1, train_loss_step=0.455, val_loss=0.644, val_acc=0.918, train_loss_epoch=0.591]\n",
      "Epoch 44:  85%|████████▍ | 130/153 [00:25<00:04,  5.19it/s, loss=0.580, v_num=1, train_loss_step=0.431, val_loss=0.644, val_acc=0.918, train_loss_epoch=0.581]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 44:  92%|█████████▏| 140/153 [00:28<00:02,  4.87it/s, loss=0.602, v_num=1, train_loss_step=0.434, val_loss=0.546, val_acc=0.934, train_loss_epoch=0.581]\n",
      "Epoch 45:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.534, v_num=1, train_loss_step=0.465, val_loss=0.546, val_acc=0.934, train_loss_epoch=0.572]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 45:  92%|█████████▏| 140/153 [00:28<00:02,  4.97it/s, loss=0.539, v_num=1, train_loss_step=0.467, val_loss=0.561, val_acc=0.918, train_loss_epoch=0.572]\n",
      "Epoch 46:  85%|████████▍ | 130/153 [00:24<00:04,  5.27it/s, loss=0.525, v_num=1, train_loss_step=0.439, val_loss=0.561, val_acc=0.918, train_loss_epoch=0.561]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46:  92%|█████████▏| 140/153 [00:28<00:02,  4.99it/s, loss=0.536, v_num=1, train_loss_step=0.511, val_loss=0.57, val_acc=0.918, train_loss_epoch=0.561] \n",
      "Epoch 47:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.610, v_num=1, train_loss_step=0.44, val_loss=0.57, val_acc=0.918, train_loss_epoch=0.565] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 47:  92%|█████████▏| 140/153 [00:28<00:02,  5.00it/s, loss=0.685, v_num=1, train_loss_step=2.08, val_loss=0.59, val_acc=0.934, train_loss_epoch=0.565]\n",
      "Epoch 48:  85%|████████▍ | 130/153 [00:24<00:04,  5.24it/s, loss=0.551, v_num=1, train_loss_step=0.451, val_loss=0.59, val_acc=0.934, train_loss_epoch=0.565]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 48:  92%|█████████▏| 140/153 [00:28<00:02,  4.96it/s, loss=0.563, v_num=1, train_loss_step=1.07, val_loss=0.549, val_acc=0.918, train_loss_epoch=0.565]\n",
      "Epoch 49:  85%|████████▍ | 130/153 [00:24<00:04,  5.32it/s, loss=0.562, v_num=1, train_loss_step=0.499, val_loss=0.549, val_acc=0.918, train_loss_epoch=0.565]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 49:  92%|█████████▏| 140/153 [00:27<00:02,  5.03it/s, loss=0.533, v_num=1, train_loss_step=0.518, val_loss=0.585, val_acc=0.918, train_loss_epoch=0.565]\n",
      "Epoch 50:  85%|████████▍ | 130/153 [00:24<00:04,  5.21it/s, loss=0.580, v_num=1, train_loss_step=0.557, val_loss=0.585, val_acc=0.918, train_loss_epoch=0.595]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 50:  92%|█████████▏| 140/153 [00:28<00:02,  4.94it/s, loss=0.560, v_num=1, train_loss_step=0.505, val_loss=0.578, val_acc=0.934, train_loss_epoch=0.595]\n",
      "Epoch 51:  85%|████████▍ | 130/153 [00:24<00:04,  5.23it/s, loss=0.589, v_num=1, train_loss_step=0.485, val_loss=0.578, val_acc=0.934, train_loss_epoch=0.541]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 51:  92%|█████████▏| 140/153 [00:28<00:02,  4.96it/s, loss=0.546, v_num=1, train_loss_step=0.484, val_loss=0.563, val_acc=0.918, train_loss_epoch=0.541]\n",
      "Epoch 52:  85%|████████▍ | 130/153 [00:24<00:04,  5.26it/s, loss=0.562, v_num=1, train_loss_step=0.439, val_loss=0.563, val_acc=0.918, train_loss_epoch=0.541]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 52:  92%|█████████▏| 140/153 [00:28<00:02,  4.99it/s, loss=0.526, v_num=1, train_loss_step=0.448, val_loss=0.534, val_acc=0.934, train_loss_epoch=0.541]\n",
      "Epoch 53:  85%|████████▍ | 130/153 [00:24<00:04,  5.25it/s, loss=0.572, v_num=1, train_loss_step=0.455, val_loss=0.534, val_acc=0.934, train_loss_epoch=0.526]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 53:  92%|█████████▏| 140/153 [00:28<00:02,  4.96it/s, loss=0.637, v_num=1, train_loss_step=0.441, val_loss=0.557, val_acc=0.918, train_loss_epoch=0.526]\n",
      "Epoch 54:  85%|████████▍ | 130/153 [00:24<00:04,  5.24it/s, loss=0.553, v_num=1, train_loss_step=0.488, val_loss=0.557, val_acc=0.918, train_loss_epoch=0.543]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 54:  92%|█████████▏| 140/153 [00:28<00:02,  4.95it/s, loss=0.522, v_num=1, train_loss_step=0.447, val_loss=0.557, val_acc=0.918, train_loss_epoch=0.543]\n",
      "Epoch 55:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.506, v_num=1, train_loss_step=0.429, val_loss=0.557, val_acc=0.918, train_loss_epoch=0.533]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 55:  92%|█████████▏| 140/153 [00:27<00:02,  5.00it/s, loss=0.514, v_num=1, train_loss_step=0.653, val_loss=0.543, val_acc=0.918, train_loss_epoch=0.533]\n",
      "Epoch 56:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.486, v_num=1, train_loss_step=0.444, val_loss=0.543, val_acc=0.918, train_loss_epoch=0.534]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 56:  92%|█████████▏| 140/153 [00:27<00:02,  5.00it/s, loss=0.515, v_num=1, train_loss_step=0.439, val_loss=0.564, val_acc=0.918, train_loss_epoch=0.534]\n",
      "Epoch 57:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.606, v_num=1, train_loss_step=0.465, val_loss=0.564, val_acc=0.918, train_loss_epoch=0.537]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 57:  92%|█████████▏| 140/153 [00:28<00:02,  5.00it/s, loss=0.570, v_num=1, train_loss_step=0.444, val_loss=0.548, val_acc=0.934, train_loss_epoch=0.537]\n",
      "Epoch 58:  85%|████████▍ | 130/153 [00:24<00:04,  5.23it/s, loss=0.537, v_num=1, train_loss_step=0.801, val_loss=0.548, val_acc=0.934, train_loss_epoch=0.554]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 58:  92%|█████████▏| 140/153 [00:28<00:02,  4.96it/s, loss=0.523, v_num=1, train_loss_step=0.435, val_loss=0.551, val_acc=0.934, train_loss_epoch=0.554]\n",
      "Epoch 59:  85%|████████▍ | 130/153 [00:24<00:04,  5.31it/s, loss=0.536, v_num=1, train_loss_step=0.465, val_loss=0.551, val_acc=0.934, train_loss_epoch=0.525]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 59:  92%|█████████▏| 140/153 [00:27<00:02,  5.00it/s, loss=0.564, v_num=1, train_loss_step=0.504, val_loss=0.544, val_acc=0.934, train_loss_epoch=0.525]\n",
      "Epoch 60:  85%|████████▍ | 130/153 [00:24<00:04,  5.23it/s, loss=0.496, v_num=1, train_loss_step=0.537, val_loss=0.544, val_acc=0.934, train_loss_epoch=0.536]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 60:  92%|█████████▏| 140/153 [00:28<00:02,  4.95it/s, loss=0.492, v_num=1, train_loss_step=0.467, val_loss=0.526, val_acc=0.951, train_loss_epoch=0.536]\n",
      "Epoch 61:  85%|████████▍ | 130/153 [00:24<00:04,  5.32it/s, loss=0.504, v_num=1, train_loss_step=0.444, val_loss=0.526, val_acc=0.951, train_loss_epoch=0.529]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 61:  92%|█████████▏| 140/153 [00:27<00:02,  5.02it/s, loss=0.470, v_num=1, train_loss_step=0.624, val_loss=0.534, val_acc=0.951, train_loss_epoch=0.529]\n",
      "Epoch 62:  85%|████████▍ | 130/153 [00:24<00:04,  5.33it/s, loss=0.502, v_num=1, train_loss_step=0.44, val_loss=0.534, val_acc=0.951, train_loss_epoch=0.521] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 62:  92%|█████████▏| 140/153 [00:27<00:02,  5.04it/s, loss=0.510, v_num=1, train_loss_step=0.51, val_loss=0.548, val_acc=0.934, train_loss_epoch=0.521]\n",
      "Epoch 63:  85%|████████▍ | 130/153 [00:24<00:04,  5.21it/s, loss=0.508, v_num=1, train_loss_step=0.448, val_loss=0.548, val_acc=0.934, train_loss_epoch=0.514]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 63:  92%|█████████▏| 140/153 [00:28<00:02,  4.94it/s, loss=0.532, v_num=1, train_loss_step=0.444, val_loss=0.543, val_acc=0.934, train_loss_epoch=0.514]\n",
      "Epoch 64:  85%|████████▍ | 130/153 [00:24<00:04,  5.22it/s, loss=0.565, v_num=1, train_loss_step=0.471, val_loss=0.543, val_acc=0.934, train_loss_epoch=0.525]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 64:  92%|█████████▏| 140/153 [00:28<00:02,  4.94it/s, loss=0.620, v_num=1, train_loss_step=1.17, val_loss=0.52, val_acc=0.934, train_loss_epoch=0.525]  \n",
      "Epoch 65:  85%|████████▍ | 130/153 [00:24<00:04,  5.23it/s, loss=0.507, v_num=1, train_loss_step=0.461, val_loss=0.52, val_acc=0.934, train_loss_epoch=0.537]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 65:  92%|█████████▏| 140/153 [00:28<00:02,  4.96it/s, loss=0.522, v_num=1, train_loss_step=0.445, val_loss=0.544, val_acc=0.951, train_loss_epoch=0.537]\n",
      "Epoch 66:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.489, v_num=1, train_loss_step=0.454, val_loss=0.544, val_acc=0.951, train_loss_epoch=0.531]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 66:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.553, v_num=1, train_loss_step=1.24, val_loss=0.558, val_acc=0.934, train_loss_epoch=0.531] \n",
      "Epoch 67:  85%|████████▍ | 130/153 [00:24<00:04,  5.31it/s, loss=0.535, v_num=1, train_loss_step=0.459, val_loss=0.558, val_acc=0.934, train_loss_epoch=0.516]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 67:  92%|█████████▏| 140/153 [00:27<00:02,  5.00it/s, loss=0.529, v_num=1, train_loss_step=0.461, val_loss=0.598, val_acc=0.951, train_loss_epoch=0.516]\n",
      "Epoch 68:  85%|████████▍ | 130/153 [00:24<00:04,  5.26it/s, loss=0.498, v_num=1, train_loss_step=0.554, val_loss=0.598, val_acc=0.951, train_loss_epoch=0.535]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 68:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.493, v_num=1, train_loss_step=0.602, val_loss=0.527, val_acc=0.951, train_loss_epoch=0.535]\n",
      "Epoch 69:  85%|████████▍ | 130/153 [00:24<00:04,  5.25it/s, loss=0.560, v_num=1, train_loss_step=1.08, val_loss=0.527, val_acc=0.951, train_loss_epoch=0.529] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 69:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.528, v_num=1, train_loss_step=0.444, val_loss=0.58, val_acc=0.918, train_loss_epoch=0.529]\n",
      "Epoch 70:  85%|████████▍ | 130/153 [00:24<00:04,  5.21it/s, loss=0.488, v_num=1, train_loss_step=0.461, val_loss=0.58, val_acc=0.918, train_loss_epoch=0.518]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 70:  92%|█████████▏| 140/153 [00:28<00:02,  4.94it/s, loss=0.499, v_num=1, train_loss_step=0.438, val_loss=0.547, val_acc=0.951, train_loss_epoch=0.518]\n",
      "Epoch 71:  85%|████████▍ | 130/153 [00:24<00:04,  5.25it/s, loss=0.537, v_num=1, train_loss_step=0.461, val_loss=0.547, val_acc=0.951, train_loss_epoch=0.519]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 71:  92%|█████████▏| 140/153 [00:28<00:02,  4.95it/s, loss=0.531, v_num=1, train_loss_step=0.438, val_loss=0.531, val_acc=0.934, train_loss_epoch=0.519]\n",
      "Epoch 72:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.551, v_num=1, train_loss_step=0.448, val_loss=0.531, val_acc=0.934, train_loss_epoch=0.515]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 72:  92%|█████████▏| 140/153 [00:27<00:02,  5.00it/s, loss=0.500, v_num=1, train_loss_step=0.448, val_loss=0.574, val_acc=0.934, train_loss_epoch=0.515]\n",
      "Epoch 73:  85%|████████▍ | 130/153 [00:24<00:04,  5.25it/s, loss=0.518, v_num=1, train_loss_step=0.562, val_loss=0.574, val_acc=0.934, train_loss_epoch=0.513]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 73:  92%|█████████▏| 140/153 [00:28<00:02,  4.97it/s, loss=0.489, v_num=1, train_loss_step=0.43, val_loss=0.537, val_acc=0.951, train_loss_epoch=0.513] \n",
      "Epoch 74:  85%|████████▍ | 130/153 [00:24<00:04,  5.24it/s, loss=0.500, v_num=1, train_loss_step=0.439, val_loss=0.537, val_acc=0.951, train_loss_epoch=0.521]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 74:  92%|█████████▏| 140/153 [00:28<00:02,  4.96it/s, loss=0.520, v_num=1, train_loss_step=0.478, val_loss=0.53, val_acc=0.951, train_loss_epoch=0.521] \n",
      "Epoch 75:  85%|████████▍ | 130/153 [00:24<00:04,  5.27it/s, loss=0.484, v_num=1, train_loss_step=0.643, val_loss=0.53, val_acc=0.951, train_loss_epoch=0.533]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 75:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.482, v_num=1, train_loss_step=0.466, val_loss=0.518, val_acc=0.951, train_loss_epoch=0.533]\n",
      "Epoch 76:  85%|████████▍ | 130/153 [00:24<00:04,  5.20it/s, loss=0.497, v_num=1, train_loss_step=0.444, val_loss=0.518, val_acc=0.951, train_loss_epoch=0.503]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 76:  92%|█████████▏| 140/153 [00:28<00:02,  4.92it/s, loss=0.488, v_num=1, train_loss_step=0.431, val_loss=0.511, val_acc=0.967, train_loss_epoch=0.503]\n",
      "Epoch 77:  85%|████████▍ | 130/153 [00:24<00:04,  5.30it/s, loss=0.471, v_num=1, train_loss_step=0.453, val_loss=0.511, val_acc=0.967, train_loss_epoch=0.504]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 77:  92%|█████████▏| 140/153 [00:27<00:02,  5.00it/s, loss=0.492, v_num=1, train_loss_step=0.436, val_loss=0.506, val_acc=0.967, train_loss_epoch=0.504]\n",
      "Epoch 78:  85%|████████▍ | 130/153 [00:24<00:04,  5.25it/s, loss=0.488, v_num=1, train_loss_step=0.462, val_loss=0.506, val_acc=0.967, train_loss_epoch=0.493]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 78:  92%|█████████▏| 140/153 [00:28<00:02,  4.96it/s, loss=0.480, v_num=1, train_loss_step=0.463, val_loss=0.507, val_acc=0.951, train_loss_epoch=0.493]\n",
      "Epoch 79:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.487, v_num=1, train_loss_step=0.447, val_loss=0.507, val_acc=0.951, train_loss_epoch=0.498]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 79:  92%|█████████▏| 140/153 [00:27<00:02,  5.00it/s, loss=0.482, v_num=1, train_loss_step=0.438, val_loss=0.512, val_acc=0.934, train_loss_epoch=0.498]\n",
      "Epoch 80:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.498, v_num=1, train_loss_step=0.439, val_loss=0.512, val_acc=0.934, train_loss_epoch=0.504]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 80:  92%|█████████▏| 140/153 [00:28<00:02,  5.00it/s, loss=0.499, v_num=1, train_loss_step=0.46, val_loss=0.511, val_acc=0.951, train_loss_epoch=0.504] \n",
      "Epoch 81:  85%|████████▍ | 130/153 [00:24<00:04,  5.27it/s, loss=0.545, v_num=1, train_loss_step=0.44, val_loss=0.511, val_acc=0.951, train_loss_epoch=0.496] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 81:  92%|█████████▏| 140/153 [00:28<00:02,  4.99it/s, loss=0.532, v_num=1, train_loss_step=0.435, val_loss=0.501, val_acc=0.951, train_loss_epoch=0.496]\n",
      "Epoch 82:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.465, v_num=1, train_loss_step=0.433, val_loss=0.501, val_acc=0.951, train_loss_epoch=0.507]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 82:  92%|█████████▏| 140/153 [00:28<00:02,  5.00it/s, loss=0.479, v_num=1, train_loss_step=0.434, val_loss=0.516, val_acc=0.967, train_loss_epoch=0.507]\n",
      "Epoch 83:  85%|████████▍ | 130/153 [00:24<00:04,  5.27it/s, loss=0.466, v_num=1, train_loss_step=0.437, val_loss=0.516, val_acc=0.967, train_loss_epoch=0.491]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 83:  92%|█████████▏| 140/153 [00:28<00:02,  4.99it/s, loss=0.492, v_num=1, train_loss_step=0.499, val_loss=0.518, val_acc=0.967, train_loss_epoch=0.491]\n",
      "Epoch 84:  85%|████████▍ | 130/153 [00:24<00:04,  5.27it/s, loss=0.456, v_num=1, train_loss_step=0.453, val_loss=0.518, val_acc=0.967, train_loss_epoch=0.482]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 84:  92%|█████████▏| 140/153 [00:28<00:02,  4.99it/s, loss=0.475, v_num=1, train_loss_step=0.481, val_loss=0.534, val_acc=0.951, train_loss_epoch=0.482]\n",
      "Epoch 85:  85%|████████▍ | 130/153 [00:24<00:04,  5.26it/s, loss=0.505, v_num=1, train_loss_step=0.684, val_loss=0.534, val_acc=0.951, train_loss_epoch=0.5]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 85:  92%|█████████▏| 140/153 [00:28<00:02,  4.99it/s, loss=0.520, v_num=1, train_loss_step=0.432, val_loss=0.542, val_acc=0.934, train_loss_epoch=0.5]\n",
      "Epoch 86:  85%|████████▍ | 130/153 [00:24<00:04,  5.21it/s, loss=0.504, v_num=1, train_loss_step=0.489, val_loss=0.542, val_acc=0.934, train_loss_epoch=0.491]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 86:  92%|█████████▏| 140/153 [00:28<00:02,  4.93it/s, loss=0.487, v_num=1, train_loss_step=0.43, val_loss=0.536, val_acc=0.934, train_loss_epoch=0.491] \n",
      "Epoch 87:  85%|████████▍ | 130/153 [00:24<00:04,  5.26it/s, loss=0.526, v_num=1, train_loss_step=0.534, val_loss=0.536, val_acc=0.934, train_loss_epoch=0.492]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 87:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.517, v_num=1, train_loss_step=0.506, val_loss=0.507, val_acc=0.951, train_loss_epoch=0.492]\n",
      "Epoch 88:  85%|████████▍ | 130/153 [00:24<00:04,  5.26it/s, loss=0.472, v_num=1, train_loss_step=0.498, val_loss=0.507, val_acc=0.951, train_loss_epoch=0.492]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 88:  92%|█████████▏| 140/153 [00:28<00:02,  4.97it/s, loss=0.485, v_num=1, train_loss_step=0.434, val_loss=0.508, val_acc=0.967, train_loss_epoch=0.492]\n",
      "Epoch 89:  85%|████████▍ | 130/153 [00:24<00:04,  5.25it/s, loss=0.474, v_num=1, train_loss_step=0.583, val_loss=0.508, val_acc=0.967, train_loss_epoch=0.482]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 89:  92%|█████████▏| 140/153 [00:28<00:02,  4.95it/s, loss=0.492, v_num=1, train_loss_step=0.436, val_loss=0.516, val_acc=0.967, train_loss_epoch=0.482]\n",
      "Epoch 90:  85%|████████▍ | 130/153 [00:24<00:04,  5.21it/s, loss=0.570, v_num=1, train_loss_step=0.907, val_loss=0.516, val_acc=0.967, train_loss_epoch=0.488]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 90:  92%|█████████▏| 140/153 [00:28<00:02,  4.94it/s, loss=0.579, v_num=1, train_loss_step=0.469, val_loss=0.523, val_acc=0.967, train_loss_epoch=0.488]\n",
      "Epoch 91:  85%|████████▍ | 130/153 [00:24<00:04,  5.24it/s, loss=0.472, v_num=1, train_loss_step=0.439, val_loss=0.523, val_acc=0.967, train_loss_epoch=0.487]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 91:  92%|█████████▏| 140/153 [00:28<00:02,  4.97it/s, loss=0.469, v_num=1, train_loss_step=0.457, val_loss=0.519, val_acc=0.951, train_loss_epoch=0.487]\n",
      "Epoch 92:  85%|████████▍ | 130/153 [00:24<00:04,  5.26it/s, loss=0.531, v_num=1, train_loss_step=0.437, val_loss=0.519, val_acc=0.951, train_loss_epoch=0.496]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92:  92%|█████████▏| 140/153 [00:28<00:02,  4.99it/s, loss=0.516, v_num=1, train_loss_step=0.433, val_loss=0.501, val_acc=0.967, train_loss_epoch=0.496]\n",
      "Epoch 93:  85%|████████▍ | 130/153 [00:24<00:04,  5.26it/s, loss=0.523, v_num=1, train_loss_step=1.27, val_loss=0.501, val_acc=0.967, train_loss_epoch=0.495] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 93:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.546, v_num=1, train_loss_step=0.556, val_loss=0.504, val_acc=0.967, train_loss_epoch=0.495]\n",
      "Epoch 94:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.474, v_num=1, train_loss_step=0.432, val_loss=0.504, val_acc=0.967, train_loss_epoch=0.5]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 94:  92%|█████████▏| 140/153 [00:28<00:02,  4.99it/s, loss=0.480, v_num=1, train_loss_step=0.517, val_loss=0.488, val_acc=0.967, train_loss_epoch=0.5]\n",
      "Epoch 95:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.486, v_num=1, train_loss_step=0.477, val_loss=0.488, val_acc=0.967, train_loss_epoch=0.475]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 95:  92%|█████████▏| 140/153 [00:27<00:02,  5.01it/s, loss=0.492, v_num=1, train_loss_step=0.431, val_loss=0.489, val_acc=0.967, train_loss_epoch=0.475]\n",
      "Epoch 96:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.486, v_num=1, train_loss_step=0.586, val_loss=0.489, val_acc=0.967, train_loss_epoch=0.482]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 96:  92%|█████████▏| 140/153 [00:28<00:02,  4.99it/s, loss=0.477, v_num=1, train_loss_step=0.469, val_loss=0.492, val_acc=0.951, train_loss_epoch=0.482]\n",
      "Epoch 97:  85%|████████▍ | 130/153 [00:24<00:04,  5.21it/s, loss=0.490, v_num=1, train_loss_step=0.443, val_loss=0.492, val_acc=0.951, train_loss_epoch=0.477]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 97:  92%|█████████▏| 140/153 [00:28<00:02,  4.93it/s, loss=0.483, v_num=1, train_loss_step=0.446, val_loss=0.496, val_acc=0.984, train_loss_epoch=0.477]\n",
      "Epoch 98:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.476, v_num=1, train_loss_step=0.442, val_loss=0.496, val_acc=0.984, train_loss_epoch=0.483]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 98:  92%|█████████▏| 140/153 [00:27<00:02,  5.01it/s, loss=0.448, v_num=1, train_loss_step=0.467, val_loss=0.507, val_acc=0.967, train_loss_epoch=0.483]\n",
      "Epoch 99:  85%|████████▍ | 130/153 [00:24<00:04,  5.31it/s, loss=0.473, v_num=1, train_loss_step=0.436, val_loss=0.507, val_acc=0.967, train_loss_epoch=0.482]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 99:  92%|█████████▏| 140/153 [00:27<00:02,  5.02it/s, loss=0.464, v_num=1, train_loss_step=0.439, val_loss=0.491, val_acc=0.984, train_loss_epoch=0.482]\n",
      "Epoch 100:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.498, v_num=1, train_loss_step=0.434, val_loss=0.491, val_acc=0.984, train_loss_epoch=0.486]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 100:  92%|█████████▏| 140/153 [00:28<00:02,  5.00it/s, loss=0.505, v_num=1, train_loss_step=0.461, val_loss=0.498, val_acc=0.967, train_loss_epoch=0.486]\n",
      "Epoch 101:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.463, v_num=1, train_loss_step=0.449, val_loss=0.498, val_acc=0.967, train_loss_epoch=0.474]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 101:  92%|█████████▏| 140/153 [00:28<00:02,  5.00it/s, loss=0.455, v_num=1, train_loss_step=0.44, val_loss=0.489, val_acc=0.984, train_loss_epoch=0.474] \n",
      "Epoch 102:  85%|████████▍ | 130/153 [00:24<00:04,  5.23it/s, loss=0.475, v_num=1, train_loss_step=0.442, val_loss=0.489, val_acc=0.984, train_loss_epoch=0.477]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 102:  92%|█████████▏| 140/153 [00:28<00:02,  4.96it/s, loss=0.478, v_num=1, train_loss_step=0.655, val_loss=0.488, val_acc=0.967, train_loss_epoch=0.477]\n",
      "Epoch 103:  85%|████████▍ | 130/153 [00:24<00:04,  5.25it/s, loss=0.475, v_num=1, train_loss_step=0.44, val_loss=0.488, val_acc=0.967, train_loss_epoch=0.478] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 103:  92%|█████████▏| 140/153 [00:28<00:02,  4.96it/s, loss=0.467, v_num=1, train_loss_step=0.474, val_loss=0.492, val_acc=0.967, train_loss_epoch=0.478]\n",
      "Epoch 104:  85%|████████▍ | 130/153 [00:24<00:04,  5.27it/s, loss=0.524, v_num=1, train_loss_step=0.487, val_loss=0.492, val_acc=0.967, train_loss_epoch=0.477]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 104:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.496, v_num=1, train_loss_step=0.439, val_loss=0.495, val_acc=0.967, train_loss_epoch=0.477]\n",
      "Epoch 105:  85%|████████▍ | 130/153 [00:24<00:04,  5.27it/s, loss=0.491, v_num=1, train_loss_step=0.461, val_loss=0.495, val_acc=0.967, train_loss_epoch=0.484]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 105:  92%|█████████▏| 140/153 [00:28<00:02,  4.99it/s, loss=0.515, v_num=1, train_loss_step=0.627, val_loss=0.492, val_acc=0.967, train_loss_epoch=0.484]\n",
      "Epoch 106:  85%|████████▍ | 130/153 [00:24<00:04,  5.27it/s, loss=0.465, v_num=1, train_loss_step=0.442, val_loss=0.492, val_acc=0.967, train_loss_epoch=0.473]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 106:  92%|█████████▏| 140/153 [00:28<00:02,  4.99it/s, loss=0.446, v_num=1, train_loss_step=0.429, val_loss=0.484, val_acc=0.984, train_loss_epoch=0.473]\n",
      "Epoch 107:  85%|████████▍ | 130/153 [00:25<00:04,  5.16it/s, loss=0.462, v_num=1, train_loss_step=0.446, val_loss=0.484, val_acc=0.984, train_loss_epoch=0.472]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 107:  92%|█████████▏| 140/153 [00:28<00:02,  4.85it/s, loss=0.452, v_num=1, train_loss_step=0.449, val_loss=0.491, val_acc=0.967, train_loss_epoch=0.472]\n",
      "Epoch 108:  85%|████████▍ | 130/153 [00:25<00:04,  5.15it/s, loss=0.493, v_num=1, train_loss_step=0.43, val_loss=0.491, val_acc=0.967, train_loss_epoch=0.478] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 108:  92%|█████████▏| 140/153 [00:28<00:02,  4.87it/s, loss=0.484, v_num=1, train_loss_step=0.446, val_loss=0.495, val_acc=0.967, train_loss_epoch=0.478]\n",
      "Epoch 109:  85%|████████▍ | 130/153 [00:24<00:04,  5.22it/s, loss=0.465, v_num=1, train_loss_step=0.452, val_loss=0.495, val_acc=0.967, train_loss_epoch=0.474]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 109:  92%|█████████▏| 140/153 [00:28<00:02,  4.95it/s, loss=0.501, v_num=1, train_loss_step=0.946, val_loss=0.497, val_acc=0.984, train_loss_epoch=0.474]\n",
      "Epoch 110:  85%|████████▍ | 130/153 [00:24<00:04,  5.30it/s, loss=0.477, v_num=1, train_loss_step=0.485, val_loss=0.497, val_acc=0.984, train_loss_epoch=0.482]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 110:  92%|█████████▏| 140/153 [00:27<00:02,  5.01it/s, loss=0.471, v_num=1, train_loss_step=0.459, val_loss=0.49, val_acc=0.984, train_loss_epoch=0.482] \n",
      "Epoch 111:  85%|████████▍ | 130/153 [00:24<00:04,  5.23it/s, loss=0.448, v_num=1, train_loss_step=0.454, val_loss=0.49, val_acc=0.984, train_loss_epoch=0.475]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 111:  92%|█████████▏| 140/153 [00:28<00:02,  4.94it/s, loss=0.454, v_num=1, train_loss_step=0.428, val_loss=0.489, val_acc=0.984, train_loss_epoch=0.475]\n",
      "Epoch 112:  85%|████████▍ | 130/153 [00:24<00:04,  5.25it/s, loss=0.464, v_num=1, train_loss_step=0.457, val_loss=0.489, val_acc=0.984, train_loss_epoch=0.464]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 112:  92%|█████████▏| 140/153 [00:28<00:02,  4.97it/s, loss=0.463, v_num=1, train_loss_step=0.44, val_loss=0.487, val_acc=0.984, train_loss_epoch=0.464] \n",
      "Epoch 113:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.477, v_num=1, train_loss_step=0.476, val_loss=0.487, val_acc=0.984, train_loss_epoch=0.461]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 113:  92%|█████████▏| 140/153 [00:27<00:02,  5.00it/s, loss=0.462, v_num=1, train_loss_step=0.433, val_loss=0.492, val_acc=0.984, train_loss_epoch=0.461]\n",
      "Epoch 114:  85%|████████▍ | 130/153 [00:24<00:04,  5.26it/s, loss=0.529, v_num=1, train_loss_step=0.501, val_loss=0.492, val_acc=0.984, train_loss_epoch=0.465]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 114:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.531, v_num=1, train_loss_step=0.453, val_loss=0.501, val_acc=0.984, train_loss_epoch=0.465]\n",
      "Epoch 115:  85%|████████▍ | 130/153 [00:24<00:04,  5.27it/s, loss=0.457, v_num=1, train_loss_step=0.434, val_loss=0.501, val_acc=0.984, train_loss_epoch=0.483]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 115:  92%|█████████▏| 140/153 [00:28<00:02,  4.98it/s, loss=0.462, v_num=1, train_loss_step=0.545, val_loss=0.487, val_acc=0.984, train_loss_epoch=0.483]\n",
      "Epoch 116:  85%|████████▍ | 130/153 [00:24<00:04,  5.23it/s, loss=0.461, v_num=1, train_loss_step=0.448, val_loss=0.487, val_acc=0.984, train_loss_epoch=0.465]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 116:  92%|█████████▏| 140/153 [00:28<00:02,  4.94it/s, loss=0.460, v_num=1, train_loss_step=0.425, val_loss=0.485, val_acc=0.967, train_loss_epoch=0.465]\n",
      "Epoch 117:  85%|████████▍ | 130/153 [00:24<00:04,  5.25it/s, loss=0.469, v_num=1, train_loss_step=0.538, val_loss=0.485, val_acc=0.967, train_loss_epoch=0.475]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 117:  92%|█████████▏| 140/153 [00:28<00:02,  4.96it/s, loss=0.471, v_num=1, train_loss_step=0.487, val_loss=0.483, val_acc=0.984, train_loss_epoch=0.475]\n",
      "Epoch 118:  85%|████████▍ | 130/153 [00:25<00:04,  5.20it/s, loss=0.461, v_num=1, train_loss_step=0.455, val_loss=0.483, val_acc=0.984, train_loss_epoch=0.471]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 118:  92%|█████████▏| 140/153 [00:28<00:02,  4.93it/s, loss=0.456, v_num=1, train_loss_step=0.496, val_loss=0.487, val_acc=0.984, train_loss_epoch=0.471]\n",
      "Epoch 119:  85%|████████▍ | 130/153 [00:24<00:04,  5.27it/s, loss=0.458, v_num=1, train_loss_step=0.465, val_loss=0.487, val_acc=0.984, train_loss_epoch=0.47] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 119:  92%|█████████▏| 140/153 [00:28<00:02,  4.97it/s, loss=0.462, v_num=1, train_loss_step=0.435, val_loss=0.49, val_acc=0.967, train_loss_epoch=0.47] \n",
      "Epoch 120:  85%|████████▍ | 130/153 [00:24<00:04,  5.24it/s, loss=0.490, v_num=1, train_loss_step=0.464, val_loss=0.49, val_acc=0.967, train_loss_epoch=0.464]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 120:  92%|█████████▏| 140/153 [00:28<00:02,  4.96it/s, loss=0.500, v_num=1, train_loss_step=0.456, val_loss=0.493, val_acc=0.967, train_loss_epoch=0.464]\n",
      "Epoch 121:  85%|████████▍ | 130/153 [00:24<00:04,  5.29it/s, loss=0.458, v_num=1, train_loss_step=0.457, val_loss=0.493, val_acc=0.967, train_loss_epoch=0.474]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 121:  92%|█████████▏| 140/153 [00:27<00:02,  5.00it/s, loss=0.462, v_num=1, train_loss_step=0.491, val_loss=0.496, val_acc=0.967, train_loss_epoch=0.474]\n",
      "Epoch 122:  85%|████████▍ | 130/153 [00:24<00:04,  5.30it/s, loss=0.455, v_num=1, train_loss_step=0.452, val_loss=0.496, val_acc=0.967, train_loss_epoch=0.465]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 122:  92%|█████████▏| 140/153 [00:27<00:02,  5.01it/s, loss=0.456, v_num=1, train_loss_step=0.432, val_loss=0.495, val_acc=0.967, train_loss_epoch=0.465]\n",
      "Epoch 123:  85%|████████▍ | 130/153 [00:24<00:04,  5.28it/s, loss=0.469, v_num=1, train_loss_step=0.443, val_loss=0.495, val_acc=0.967, train_loss_epoch=0.463]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 123:  92%|█████████▏| 140/153 [00:27<00:02,  5.00it/s, loss=0.468, v_num=1, train_loss_step=0.434, val_loss=0.497, val_acc=0.967, train_loss_epoch=0.463]\n",
      "Epoch 124:  85%|████████▍ | 130/153 [00:24<00:04,  5.24it/s, loss=0.472, v_num=1, train_loss_step=0.44, val_loss=0.497, val_acc=0.967, train_loss_epoch=0.467] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 124:  92%|█████████▏| 140/153 [00:28<00:02,  4.96it/s, loss=0.472, v_num=1, train_loss_step=0.443, val_loss=0.485, val_acc=0.967, train_loss_epoch=0.467]\n",
      "Epoch 124:  92%|█████████▏| 140/153 [00:28<00:02,  4.95it/s, loss=0.472, v_num=1, train_loss_step=0.443, val_loss=0.485, val_acc=0.967, train_loss_epoch=0.467]\n"
     ]
    }
   ],
   "source": [
    "configs['DATASET']['AUGMENTATION'] = 'noise'\n",
    "configs['DATASET']['NOISE_PATH']= '../datasets/MUSAN/free-sound/'\n",
    "configs['LOSS'] = 'label_smoothing_cross_entropy'\n",
    "configs['CHECKPOINT']['SAVE_NAME'] = 'crnn-bmw-noise-ls0.1'\n",
    "torch.cuda.empty_cache()\n",
    "do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: uniform\n",
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name        | Type        | Params\n",
      "---------------------------------------------\n",
      "0  | conv1       | Conv2d      | 640   \n",
      "1  | bn1         | BatchNorm2d | 128   \n",
      "2  | dropout1    | Dropout     | 0     \n",
      "3  | conv2       | Conv2d      | 73 K  \n",
      "4  | bn2         | BatchNorm2d | 256   \n",
      "5  | dropout2    | Dropout     | 0     \n",
      "6  | conv3       | Conv2d      | 147 K \n",
      "7  | bn3         | BatchNorm2d | 256   \n",
      "8  | dropout3    | Dropout     | 0     \n",
      "9  | conv4       | Conv2d      | 147 K \n",
      "10 | bn4         | BatchNorm2d | 256   \n",
      "11 | dropout4    | Dropout     | 0     \n",
      "12 | rnn         | GRU         | 21 K  \n",
      "13 | dropout_rnn | Dropout     | 0     \n",
      "14 | linear      | Linear      | 198   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  85%|████████▍ | 130/153 [00:22<00:03,  5.79it/s, loss=0.946, v_num=3, train_loss_step=0.872]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 140/153 [00:26<00:02,  5.35it/s, loss=0.905, v_num=3, train_loss_step=0.83, val_loss=0.985, val_acc=0.672]\n",
      "Epoch 1:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=1.076, v_num=3, train_loss_step=1.12, val_loss=0.985, val_acc=0.672, train_loss_epoch=1.19] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=1.137, v_num=3, train_loss_step=3.39, val_loss=0.861, val_acc=0.754, train_loss_epoch=1.19]\n",
      "Epoch 2:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.869, v_num=3, train_loss_step=0.574, val_loss=0.861, val_acc=0.754, train_loss_epoch=1.01]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.846, v_num=3, train_loss_step=0.507, val_loss=0.794, val_acc=0.705, train_loss_epoch=1.01]\n",
      "Epoch 3:  85%|████████▍ | 130/153 [00:22<00:03,  5.89it/s, loss=0.740, v_num=3, train_loss_step=0.791, val_loss=0.794, val_acc=0.705, train_loss_epoch=0.899] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 140/153 [00:25<00:02,  5.41it/s, loss=0.845, v_num=3, train_loss_step=0.119, val_loss=0.729, val_acc=0.787, train_loss_epoch=0.899]\n",
      "Epoch 4:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.565, v_num=3, train_loss_step=0.817, val_loss=0.729, val_acc=0.787, train_loss_epoch=0.75] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 140/153 [00:26<00:02,  5.31it/s, loss=0.506, v_num=3, train_loss_step=0.0358, val_loss=1.08, val_acc=0.705, train_loss_epoch=0.75]\n",
      "Epoch 5:  85%|████████▍ | 130/153 [00:22<00:03,  5.88it/s, loss=0.592, v_num=3, train_loss_step=0.603, val_loss=1.08, val_acc=0.705, train_loss_epoch=0.62] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.565, v_num=3, train_loss_step=0.0726, val_loss=0.825, val_acc=0.738, train_loss_epoch=0.62]\n",
      "Epoch 6:  85%|████████▍ | 130/153 [00:22<00:03,  5.89it/s, loss=0.477, v_num=3, train_loss_step=0.473, val_loss=0.825, val_acc=0.738, train_loss_epoch=0.562]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.518, v_num=3, train_loss_step=0.109, val_loss=0.619, val_acc=0.738, train_loss_epoch=0.562]\n",
      "Epoch 7:  85%|████████▍ | 130/153 [00:22<00:03,  5.88it/s, loss=0.665, v_num=3, train_loss_step=0.699, val_loss=0.619, val_acc=0.738, train_loss_epoch=0.555]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 140/153 [00:25<00:02,  5.39it/s, loss=0.655, v_num=3, train_loss_step=0.212, val_loss=0.481, val_acc=0.836, train_loss_epoch=0.555]\n",
      "Epoch 8:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.442, v_num=3, train_loss_step=0.487, val_loss=0.481, val_acc=0.836, train_loss_epoch=0.467]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.334, v_num=3, train_loss_step=0.0212, val_loss=0.429, val_acc=0.836, train_loss_epoch=0.467]\n",
      "Epoch 9:  85%|████████▍ | 130/153 [00:22<00:03,  5.84it/s, loss=0.344, v_num=3, train_loss_step=0.218, val_loss=0.429, val_acc=0.836, train_loss_epoch=0.494] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 140/153 [00:25<00:02,  5.39it/s, loss=0.391, v_num=3, train_loss_step=0.0263, val_loss=0.652, val_acc=0.787, train_loss_epoch=0.494]\n",
      "Epoch 10:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.504, v_num=3, train_loss_step=1.3, val_loss=0.652, val_acc=0.787, train_loss_epoch=0.486]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.450, v_num=3, train_loss_step=0.122, val_loss=0.448, val_acc=0.852, train_loss_epoch=0.486]\n",
      "Epoch 11:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.317, v_num=3, train_loss_step=0.0362, val_loss=0.448, val_acc=0.852, train_loss_epoch=0.455]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.288, v_num=3, train_loss_step=0.145, val_loss=0.504, val_acc=0.787, train_loss_epoch=0.455] \n",
      "Epoch 12:  85%|████████▍ | 130/153 [00:21<00:03,  6.03it/s, loss=0.450, v_num=3, train_loss_step=0.21, val_loss=0.504, val_acc=0.787, train_loss_epoch=0.38]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 140/153 [00:25<00:02,  5.52it/s, loss=0.523, v_num=3, train_loss_step=0.119, val_loss=0.546, val_acc=0.82, train_loss_epoch=0.38]\n",
      "Epoch 13:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.205, v_num=3, train_loss_step=0.0916, val_loss=0.546, val_acc=0.82, train_loss_epoch=0.37]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.323, v_num=3, train_loss_step=0.0739, val_loss=0.589, val_acc=0.803, train_loss_epoch=0.37]\n",
      "Epoch 14:  85%|████████▍ | 130/153 [00:21<00:03,  6.00it/s, loss=0.374, v_num=3, train_loss_step=0.0116, val_loss=0.589, val_acc=0.803, train_loss_epoch=0.317] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  92%|█████████▏| 140/153 [00:25<00:02,  5.52it/s, loss=0.295, v_num=3, train_loss_step=0.0747, val_loss=0.707, val_acc=0.803, train_loss_epoch=0.317]\n",
      "Epoch 15:  85%|████████▍ | 130/153 [00:21<00:03,  5.99it/s, loss=0.289, v_num=3, train_loss_step=0.485, val_loss=0.707, val_acc=0.803, train_loss_epoch=0.337] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  92%|█████████▏| 140/153 [00:25<00:02,  5.51it/s, loss=0.267, v_num=3, train_loss_step=0.0362, val_loss=0.677, val_acc=0.803, train_loss_epoch=0.337]\n",
      "Epoch 16:  85%|████████▍ | 130/153 [00:21<00:03,  6.00it/s, loss=0.594, v_num=3, train_loss_step=0.0917, val_loss=0.677, val_acc=0.803, train_loss_epoch=0.321]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.396, v_num=3, train_loss_step=0.00902, val_loss=0.416, val_acc=0.885, train_loss_epoch=0.321]\n",
      "Epoch 17:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.266, v_num=3, train_loss_step=0.334, val_loss=0.416, val_acc=0.885, train_loss_epoch=0.318]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.365, v_num=3, train_loss_step=1.36, val_loss=0.46, val_acc=0.852, train_loss_epoch=0.318]  \n",
      "Epoch 18:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.312, v_num=3, train_loss_step=0.66, val_loss=0.46, val_acc=0.852, train_loss_epoch=0.322]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.378, v_num=3, train_loss_step=1.59, val_loss=0.216, val_acc=0.918, train_loss_epoch=0.322]\n",
      "Epoch 19:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.185, v_num=3, train_loss_step=0.465, val_loss=0.216, val_acc=0.918, train_loss_epoch=0.314] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.208, v_num=3, train_loss_step=0.0284, val_loss=0.467, val_acc=0.852, train_loss_epoch=0.314]\n",
      "Epoch 20:  85%|████████▍ | 130/153 [00:21<00:03,  5.99it/s, loss=0.185, v_num=3, train_loss_step=0.0218, val_loss=0.467, val_acc=0.852, train_loss_epoch=0.22] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  92%|█████████▏| 140/153 [00:25<00:02,  5.51it/s, loss=0.209, v_num=3, train_loss_step=0.376, val_loss=0.264, val_acc=0.869, train_loss_epoch=0.22] \n",
      "Epoch 21:  85%|████████▍ | 130/153 [00:21<00:03,  6.01it/s, loss=0.214, v_num=3, train_loss_step=0.1, val_loss=0.264, val_acc=0.869, train_loss_epoch=0.292]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  92%|█████████▏| 140/153 [00:25<00:02,  5.53it/s, loss=0.205, v_num=3, train_loss_step=0.094, val_loss=0.697, val_acc=0.754, train_loss_epoch=0.292]\n",
      "Epoch 22:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.393, v_num=3, train_loss_step=0.408, val_loss=0.697, val_acc=0.754, train_loss_epoch=0.224]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  92%|█████████▏| 140/153 [00:25<00:02,  5.51it/s, loss=0.430, v_num=3, train_loss_step=0.00951, val_loss=0.264, val_acc=0.902, train_loss_epoch=0.224]\n",
      "Epoch 23:  85%|████████▍ | 130/153 [00:21<00:03,  5.99it/s, loss=0.408, v_num=3, train_loss_step=0.998, val_loss=0.264, val_acc=0.902, train_loss_epoch=0.309]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.363, v_num=3, train_loss_step=2.19, val_loss=0.252, val_acc=0.902, train_loss_epoch=0.309] \n",
      "Epoch 24:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.187, v_num=3, train_loss_step=0.0234, val_loss=0.252, val_acc=0.902, train_loss_epoch=0.272] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.262, v_num=3, train_loss_step=0.348, val_loss=0.468, val_acc=0.852, train_loss_epoch=0.272] \n",
      "Epoch 25:  85%|████████▍ | 130/153 [00:21<00:03,  6.01it/s, loss=0.063, v_num=3, train_loss_step=0.0308, val_loss=0.468, val_acc=0.852, train_loss_epoch=0.233] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.121, v_num=3, train_loss_step=0.00292, val_loss=0.342, val_acc=0.885, train_loss_epoch=0.233]\n",
      "Epoch 26:  85%|████████▍ | 130/153 [00:21<00:03,  6.01it/s, loss=0.180, v_num=3, train_loss_step=0.0246, val_loss=0.342, val_acc=0.885, train_loss_epoch=0.182] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.253, v_num=3, train_loss_step=0.697, val_loss=0.311, val_acc=0.885, train_loss_epoch=0.182] \n",
      "Epoch 27:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.093, v_num=3, train_loss_step=0.137, val_loss=0.311, val_acc=0.885, train_loss_epoch=0.194]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.088, v_num=3, train_loss_step=0.0542, val_loss=0.223, val_acc=0.902, train_loss_epoch=0.194]\n",
      "Epoch 28:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.170, v_num=3, train_loss_step=0.361, val_loss=0.223, val_acc=0.902, train_loss_epoch=0.155] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.185, v_num=3, train_loss_step=0.618, val_loss=0.193, val_acc=0.934, train_loss_epoch=0.155]\n",
      "Epoch 29:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.054, v_num=3, train_loss_step=0.0028, val_loss=0.193, val_acc=0.934, train_loss_epoch=0.147] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.138, v_num=3, train_loss_step=0.899, val_loss=0.185, val_acc=0.934, train_loss_epoch=0.147] \n",
      "Epoch 30:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.104, v_num=3, train_loss_step=0.00273, val_loss=0.185, val_acc=0.934, train_loss_epoch=0.15]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.084, v_num=3, train_loss_step=0.00691, val_loss=0.188, val_acc=0.885, train_loss_epoch=0.15]\n",
      "Epoch 31:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.152, v_num=3, train_loss_step=0.0343, val_loss=0.188, val_acc=0.885, train_loss_epoch=0.111] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.168, v_num=3, train_loss_step=0.0122, val_loss=0.412, val_acc=0.869, train_loss_epoch=0.111]\n",
      "Epoch 32:  85%|████████▍ | 130/153 [00:21<00:03,  6.00it/s, loss=0.081, v_num=3, train_loss_step=0.0197, val_loss=0.412, val_acc=0.869, train_loss_epoch=0.125]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32:  92%|█████████▏| 140/153 [00:25<00:02,  5.51it/s, loss=0.062, v_num=3, train_loss_step=0.0135, val_loss=0.34, val_acc=0.869, train_loss_epoch=0.125] \n",
      "Epoch 33:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.139, v_num=3, train_loss_step=0.0301, val_loss=0.34, val_acc=0.869, train_loss_epoch=0.138] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.096, v_num=3, train_loss_step=0.00314, val_loss=0.481, val_acc=0.852, train_loss_epoch=0.138]\n",
      "Epoch 34:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.074, v_num=3, train_loss_step=0.0273, val_loss=0.481, val_acc=0.852, train_loss_epoch=0.133] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.061, v_num=3, train_loss_step=0.0211, val_loss=0.2, val_acc=0.885, train_loss_epoch=0.133]  \n",
      "Epoch 35:  85%|████████▍ | 130/153 [00:21<00:03,  6.00it/s, loss=0.175, v_num=3, train_loss_step=0.0195, val_loss=0.2, val_acc=0.885, train_loss_epoch=0.0971] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35:  92%|█████████▏| 140/153 [00:25<00:02,  5.52it/s, loss=0.246, v_num=3, train_loss_step=1.26, val_loss=0.374, val_acc=0.902, train_loss_epoch=0.0971]\n",
      "Epoch 36:  85%|████████▍ | 130/153 [00:21<00:03,  6.00it/s, loss=0.197, v_num=3, train_loss_step=0.378, val_loss=0.374, val_acc=0.902, train_loss_epoch=0.136]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.148, v_num=3, train_loss_step=0.0121, val_loss=0.434, val_acc=0.869, train_loss_epoch=0.136]\n",
      "Epoch 37:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.293, v_num=3, train_loss_step=0.117, val_loss=0.434, val_acc=0.869, train_loss_epoch=0.187]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.326, v_num=3, train_loss_step=0.826, val_loss=0.488, val_acc=0.836, train_loss_epoch=0.187]\n",
      "Epoch 38:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.132, v_num=3, train_loss_step=0.146, val_loss=0.488, val_acc=0.836, train_loss_epoch=0.18]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.127, v_num=3, train_loss_step=0.00722, val_loss=0.174, val_acc=0.934, train_loss_epoch=0.18]\n",
      "Epoch 39:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.091, v_num=3, train_loss_step=0.00769, val_loss=0.174, val_acc=0.934, train_loss_epoch=0.127]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.109, v_num=3, train_loss_step=0.0158, val_loss=0.271, val_acc=0.885, train_loss_epoch=0.127] \n",
      "Epoch 40:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.095, v_num=3, train_loss_step=0.0178, val_loss=0.271, val_acc=0.885, train_loss_epoch=0.149]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 40:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.131, v_num=3, train_loss_step=0.0094, val_loss=0.188, val_acc=0.934, train_loss_epoch=0.149]\n",
      "Epoch 41:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.056, v_num=3, train_loss_step=0.00509, val_loss=0.188, val_acc=0.934, train_loss_epoch=0.116]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 41:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.049, v_num=3, train_loss_step=0.0398, val_loss=0.224, val_acc=0.885, train_loss_epoch=0.116] \n",
      "Epoch 42:  85%|████████▍ | 130/153 [00:21<00:03,  6.03it/s, loss=0.049, v_num=3, train_loss_step=0.00609, val_loss=0.224, val_acc=0.885, train_loss_epoch=0.0872]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 42:  92%|█████████▏| 140/153 [00:25<00:02,  5.51it/s, loss=0.089, v_num=3, train_loss_step=0.0617, val_loss=0.107, val_acc=0.967, train_loss_epoch=0.0872] \n",
      "Epoch 43:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.072, v_num=3, train_loss_step=0.208, val_loss=0.107, val_acc=0.967, train_loss_epoch=0.124]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 43:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.056, v_num=3, train_loss_step=0.000435, val_loss=0.292, val_acc=0.918, train_loss_epoch=0.124]\n",
      "Epoch 44:  85%|████████▍ | 130/153 [00:21<00:03,  6.02it/s, loss=0.082, v_num=3, train_loss_step=0.00849, val_loss=0.292, val_acc=0.918, train_loss_epoch=0.0953]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 44:  92%|█████████▏| 140/153 [00:25<00:02,  5.52it/s, loss=0.074, v_num=3, train_loss_step=0.0233, val_loss=0.143, val_acc=0.951, train_loss_epoch=0.0953] \n",
      "Epoch 45:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.109, v_num=3, train_loss_step=0.0111, val_loss=0.143, val_acc=0.951, train_loss_epoch=0.0795] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 45:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.082, v_num=3, train_loss_step=0.187, val_loss=0.217, val_acc=0.934, train_loss_epoch=0.0795] \n",
      "Epoch 46:  85%|████████▍ | 130/153 [00:21<00:03,  5.99it/s, loss=0.030, v_num=3, train_loss_step=0.00547, val_loss=0.217, val_acc=0.934, train_loss_epoch=0.0824] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 46:  92%|█████████▏| 140/153 [00:25<00:02,  5.51it/s, loss=0.038, v_num=3, train_loss_step=0.000534, val_loss=0.171, val_acc=0.951, train_loss_epoch=0.0824]\n",
      "Epoch 47:  85%|████████▍ | 130/153 [00:21<00:03,  6.01it/s, loss=0.057, v_num=3, train_loss_step=0.00595, val_loss=0.171, val_acc=0.951, train_loss_epoch=0.072]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 47:  92%|█████████▏| 140/153 [00:25<00:02,  5.53it/s, loss=0.040, v_num=3, train_loss_step=0.0111, val_loss=0.145, val_acc=0.934, train_loss_epoch=0.072] \n",
      "Epoch 48:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.116, v_num=3, train_loss_step=0.0727, val_loss=0.145, val_acc=0.934, train_loss_epoch=0.0608]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 48:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.104, v_num=3, train_loss_step=0.00952, val_loss=0.476, val_acc=0.852, train_loss_epoch=0.0608]\n",
      "Epoch 49:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.044, v_num=3, train_loss_step=0.0105, val_loss=0.476, val_acc=0.852, train_loss_epoch=0.101]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 49:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.046, v_num=3, train_loss_step=0.0631, val_loss=0.389, val_acc=0.869, train_loss_epoch=0.101]\n",
      "Epoch 50:  85%|████████▍ | 130/153 [00:21<00:03,  6.01it/s, loss=0.022, v_num=3, train_loss_step=0.00404, val_loss=0.389, val_acc=0.869, train_loss_epoch=0.0708]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 50:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.019, v_num=3, train_loss_step=0.0033, val_loss=0.184, val_acc=0.934, train_loss_epoch=0.0708] \n",
      "Epoch 51:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.098, v_num=3, train_loss_step=0.00669, val_loss=0.184, val_acc=0.934, train_loss_epoch=0.0354]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 51:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.098, v_num=3, train_loss_step=0.236, val_loss=0.227, val_acc=0.934, train_loss_epoch=0.0354]  \n",
      "Epoch 52:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.049, v_num=3, train_loss_step=0.0281, val_loss=0.227, val_acc=0.934, train_loss_epoch=0.0601] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 52:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.089, v_num=3, train_loss_step=0.00363, val_loss=0.234, val_acc=0.902, train_loss_epoch=0.0601]\n",
      "Epoch 53:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.021, v_num=3, train_loss_step=0.0428, val_loss=0.234, val_acc=0.902, train_loss_epoch=0.064]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 53:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.024, v_num=3, train_loss_step=0.0232, val_loss=0.147, val_acc=0.934, train_loss_epoch=0.064]\n",
      "Epoch 54:  85%|████████▍ | 130/153 [00:21<00:03,  6.01it/s, loss=0.033, v_num=3, train_loss_step=0.00818, val_loss=0.147, val_acc=0.934, train_loss_epoch=0.0246]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 54:  92%|█████████▏| 140/153 [00:25<00:02,  5.51it/s, loss=0.036, v_num=3, train_loss_step=0.0321, val_loss=0.143, val_acc=0.951, train_loss_epoch=0.0246] \n",
      "Epoch 55:  85%|████████▍ | 130/153 [00:21<00:03,  5.91it/s, loss=0.018, v_num=3, train_loss_step=0.00303, val_loss=0.143, val_acc=0.951, train_loss_epoch=0.0337]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 55:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.023, v_num=3, train_loss_step=0.0268, val_loss=0.111, val_acc=0.951, train_loss_epoch=0.0337] \n",
      "Epoch 56:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.015, v_num=3, train_loss_step=0.00907, val_loss=0.111, val_acc=0.951, train_loss_epoch=0.03] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 56:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.045, v_num=3, train_loss_step=0.293, val_loss=0.266, val_acc=0.918, train_loss_epoch=0.03]  \n",
      "Epoch 57:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.043, v_num=3, train_loss_step=0.0207, val_loss=0.266, val_acc=0.918, train_loss_epoch=0.021] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 57:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.019, v_num=3, train_loss_step=0.000444, val_loss=0.144, val_acc=0.967, train_loss_epoch=0.021]\n",
      "Epoch 58:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.016, v_num=3, train_loss_step=0.00142, val_loss=0.144, val_acc=0.967, train_loss_epoch=0.0323]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 58:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.019, v_num=3, train_loss_step=0.00887, val_loss=0.157, val_acc=0.951, train_loss_epoch=0.0323]\n",
      "Epoch 59:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.031, v_num=3, train_loss_step=0.0258, val_loss=0.157, val_acc=0.951, train_loss_epoch=0.0187] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 59:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.050, v_num=3, train_loss_step=0.00729, val_loss=0.305, val_acc=0.902, train_loss_epoch=0.0187]\n",
      "Epoch 60:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.021, v_num=3, train_loss_step=0.00145, val_loss=0.305, val_acc=0.902, train_loss_epoch=0.0217]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 60:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.019, v_num=3, train_loss_step=0.00384, val_loss=0.296, val_acc=0.885, train_loss_epoch=0.0217]\n",
      "Epoch 61:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.085, v_num=3, train_loss_step=0.107, val_loss=0.296, val_acc=0.885, train_loss_epoch=0.0164]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 61:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.085, v_num=3, train_loss_step=0.000355, val_loss=0.17, val_acc=0.934, train_loss_epoch=0.0164]\n",
      "Epoch 62:  85%|████████▍ | 130/153 [00:21<00:03,  5.99it/s, loss=0.009, v_num=3, train_loss_step=0.00157, val_loss=0.17, val_acc=0.934, train_loss_epoch=0.057]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 62:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.008, v_num=3, train_loss_step=0.00192, val_loss=0.152, val_acc=0.967, train_loss_epoch=0.057]\n",
      "Epoch 63:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.010, v_num=3, train_loss_step=0.00987, val_loss=0.152, val_acc=0.967, train_loss_epoch=0.0225]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 63:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.007, v_num=3, train_loss_step=0.000521, val_loss=0.209, val_acc=0.918, train_loss_epoch=0.0225]\n",
      "Epoch 64:  85%|████████▍ | 130/153 [00:21<00:03,  6.01it/s, loss=0.061, v_num=3, train_loss_step=0.000908, val_loss=0.209, val_acc=0.918, train_loss_epoch=0.0547]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 64:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.053, v_num=3, train_loss_step=0.00691, val_loss=0.168, val_acc=0.951, train_loss_epoch=0.0547] \n",
      "Epoch 65:  85%|████████▍ | 130/153 [00:22<00:03,  5.89it/s, loss=0.019, v_num=3, train_loss_step=0.00816, val_loss=0.168, val_acc=0.951, train_loss_epoch=0.0428]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 65:  92%|█████████▏| 140/153 [00:25<00:02,  5.41it/s, loss=0.010, v_num=3, train_loss_step=0.000718, val_loss=0.155, val_acc=0.951, train_loss_epoch=0.0428]\n",
      "Epoch 66:  85%|████████▍ | 130/153 [00:21<00:03,  5.99it/s, loss=0.030, v_num=3, train_loss_step=0.0252, val_loss=0.155, val_acc=0.951, train_loss_epoch=0.0351]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 66:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.035, v_num=3, train_loss_step=0.00883, val_loss=0.369, val_acc=0.902, train_loss_epoch=0.0351]\n",
      "Epoch 67:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.014, v_num=3, train_loss_step=0.0133, val_loss=0.369, val_acc=0.902, train_loss_epoch=0.0461]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 67:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.014, v_num=3, train_loss_step=0.00192, val_loss=0.285, val_acc=0.918, train_loss_epoch=0.0461]\n",
      "Epoch 68:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.009, v_num=3, train_loss_step=0.0106, val_loss=0.285, val_acc=0.918, train_loss_epoch=0.0274] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 68:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.009, v_num=3, train_loss_step=0.00695, val_loss=0.278, val_acc=0.934, train_loss_epoch=0.0274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.033, v_num=3, train_loss_step=0.00403, val_loss=0.278, val_acc=0.934, train_loss_epoch=0.0202]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 69:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.028, v_num=3, train_loss_step=0.000905, val_loss=0.221, val_acc=0.918, train_loss_epoch=0.0202]\n",
      "Epoch 70:  85%|████████▍ | 130/153 [00:22<00:03,  5.91it/s, loss=0.025, v_num=3, train_loss_step=0.0016, val_loss=0.221, val_acc=0.918, train_loss_epoch=0.0477]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 70:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.027, v_num=3, train_loss_step=0.00454, val_loss=0.165, val_acc=0.951, train_loss_epoch=0.0477]\n",
      "Epoch 71:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.020, v_num=3, train_loss_step=0.00937, val_loss=0.165, val_acc=0.951, train_loss_epoch=0.0327]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 71:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.027, v_num=3, train_loss_step=0.00182, val_loss=0.185, val_acc=0.934, train_loss_epoch=0.0327]\n",
      "Epoch 72:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.018, v_num=3, train_loss_step=0.000859, val_loss=0.185, val_acc=0.934, train_loss_epoch=0.0337]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 72:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.024, v_num=3, train_loss_step=0.184, val_loss=0.138, val_acc=0.951, train_loss_epoch=0.0337]   \n",
      "Epoch 73:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.056, v_num=3, train_loss_step=0.00427, val_loss=0.138, val_acc=0.951, train_loss_epoch=0.021]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 73:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.060, v_num=3, train_loss_step=0.00147, val_loss=0.152, val_acc=0.951, train_loss_epoch=0.021]\n",
      "Epoch 74:  85%|████████▍ | 130/153 [00:21<00:03,  6.00it/s, loss=0.014, v_num=3, train_loss_step=0.00208, val_loss=0.152, val_acc=0.951, train_loss_epoch=0.0297]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 74:  92%|█████████▏| 140/153 [00:25<00:02,  5.51it/s, loss=0.006, v_num=3, train_loss_step=0.000829, val_loss=0.229, val_acc=0.934, train_loss_epoch=0.0297]\n",
      "Epoch 75:  85%|████████▍ | 130/153 [00:21<00:03,  5.99it/s, loss=0.008, v_num=3, train_loss_step=0.0117, val_loss=0.229, val_acc=0.934, train_loss_epoch=0.0116]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 75:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.009, v_num=3, train_loss_step=0.00299, val_loss=0.187, val_acc=0.951, train_loss_epoch=0.0116]\n",
      "Epoch 76:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.011, v_num=3, train_loss_step=0.0104, val_loss=0.187, val_acc=0.951, train_loss_epoch=0.0107]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 76:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.009, v_num=3, train_loss_step=0.00452, val_loss=0.172, val_acc=0.951, train_loss_epoch=0.0107]\n",
      "Epoch 77:  85%|████████▍ | 130/153 [00:21<00:03,  6.00it/s, loss=0.010, v_num=3, train_loss_step=0.00328, val_loss=0.172, val_acc=0.951, train_loss_epoch=0.00878]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 77:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.012, v_num=3, train_loss_step=0.0058, val_loss=0.267, val_acc=0.918, train_loss_epoch=0.00878] \n",
      "Epoch 78:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.006, v_num=3, train_loss_step=0.00206, val_loss=0.267, val_acc=0.918, train_loss_epoch=0.0106]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 78:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.006, v_num=3, train_loss_step=0.00554, val_loss=0.157, val_acc=0.967, train_loss_epoch=0.0106]\n",
      "Epoch 79:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.011, v_num=3, train_loss_step=0.0152, val_loss=0.157, val_acc=0.967, train_loss_epoch=0.0105]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 79:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.012, v_num=3, train_loss_step=0.00632, val_loss=0.226, val_acc=0.951, train_loss_epoch=0.0105]\n",
      "Epoch 80:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.008, v_num=3, train_loss_step=0.0135, val_loss=0.226, val_acc=0.951, train_loss_epoch=0.00958]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 80:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.009, v_num=3, train_loss_step=0.000726, val_loss=0.164, val_acc=0.951, train_loss_epoch=0.00958]\n",
      "Epoch 81:  85%|████████▍ | 130/153 [00:21<00:03,  6.03it/s, loss=0.006, v_num=3, train_loss_step=0.0192, val_loss=0.164, val_acc=0.951, train_loss_epoch=0.00926]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 81:  92%|█████████▏| 140/153 [00:25<00:02,  5.53it/s, loss=0.005, v_num=3, train_loss_step=0.00222, val_loss=0.184, val_acc=0.951, train_loss_epoch=0.00926]\n",
      "Epoch 82:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.027, v_num=3, train_loss_step=0.00211, val_loss=0.184, val_acc=0.951, train_loss_epoch=0.00777]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 82:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.024, v_num=3, train_loss_step=0.345, val_loss=0.23, val_acc=0.951, train_loss_epoch=0.00777]   \n",
      "Epoch 83:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.005, v_num=3, train_loss_step=0.00103, val_loss=0.23, val_acc=0.951, train_loss_epoch=0.0138]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 83:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.005, v_num=3, train_loss_step=0.00512, val_loss=0.169, val_acc=0.934, train_loss_epoch=0.0138]\n",
      "Epoch 84:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.008, v_num=3, train_loss_step=0.00463, val_loss=0.169, val_acc=0.934, train_loss_epoch=0.0127] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 84:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.006, v_num=3, train_loss_step=0.000547, val_loss=0.196, val_acc=0.934, train_loss_epoch=0.0127]\n",
      "Epoch 85:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.022, v_num=3, train_loss_step=0.006, val_loss=0.196, val_acc=0.934, train_loss_epoch=0.00666]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 85:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.010, v_num=3, train_loss_step=0.016, val_loss=0.16, val_acc=0.951, train_loss_epoch=0.00666] \n",
      "Epoch 86:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.005, v_num=3, train_loss_step=0.00139, val_loss=0.16, val_acc=0.951, train_loss_epoch=0.0146]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 86:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.006, v_num=3, train_loss_step=0.00107, val_loss=0.117, val_acc=0.951, train_loss_epoch=0.0146]\n",
      "Epoch 87:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.004, v_num=3, train_loss_step=0.00156, val_loss=0.117, val_acc=0.951, train_loss_epoch=0.0086] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 87:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.006, v_num=3, train_loss_step=0.00719, val_loss=0.129, val_acc=0.951, train_loss_epoch=0.0086]\n",
      "Epoch 88:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.062, v_num=3, train_loss_step=0.123, val_loss=0.129, val_acc=0.951, train_loss_epoch=0.0109]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 88:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.063, v_num=3, train_loss_step=0.0213, val_loss=0.218, val_acc=0.951, train_loss_epoch=0.0109]\n",
      "Epoch 89:  85%|████████▍ | 130/153 [00:21<00:03,  5.99it/s, loss=0.008, v_num=3, train_loss_step=0.0037, val_loss=0.218, val_acc=0.951, train_loss_epoch=0.0208] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 89:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.009, v_num=3, train_loss_step=0.00522, val_loss=0.14, val_acc=0.951, train_loss_epoch=0.0208]\n",
      "Epoch 90:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.015, v_num=3, train_loss_step=0.013, val_loss=0.14, val_acc=0.951, train_loss_epoch=0.0117]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 90:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.006, v_num=3, train_loss_step=0.000605, val_loss=0.225, val_acc=0.951, train_loss_epoch=0.0117]\n",
      "Epoch 91:  85%|████████▍ | 130/153 [00:22<00:03,  5.87it/s, loss=0.007, v_num=3, train_loss_step=0.0169, val_loss=0.225, val_acc=0.951, train_loss_epoch=0.0249]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91:  92%|█████████▏| 140/153 [00:26<00:02,  5.36it/s, loss=0.010, v_num=3, train_loss_step=0.0199, val_loss=0.173, val_acc=0.951, train_loss_epoch=0.0249]\n",
      "Epoch 92:  85%|████████▍ | 130/153 [00:22<00:03,  5.81it/s, loss=0.013, v_num=3, train_loss_step=0.00493, val_loss=0.173, val_acc=0.951, train_loss_epoch=0.00807]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 92:  92%|█████████▏| 140/153 [00:26<00:02,  5.37it/s, loss=0.013, v_num=3, train_loss_step=0.000175, val_loss=0.165, val_acc=0.951, train_loss_epoch=0.00807]\n",
      "Epoch 93:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.009, v_num=3, train_loss_step=0.00332, val_loss=0.165, val_acc=0.951, train_loss_epoch=0.00825] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 93:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.005, v_num=3, train_loss_step=0.00915, val_loss=0.106, val_acc=0.967, train_loss_epoch=0.00825]\n",
      "Epoch 94:  85%|████████▍ | 130/153 [00:21<00:03,  6.00it/s, loss=0.010, v_num=3, train_loss_step=0.109, val_loss=0.106, val_acc=0.967, train_loss_epoch=0.0114]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 94:  92%|█████████▏| 140/153 [00:25<00:02,  5.51it/s, loss=0.013, v_num=3, train_loss_step=0.000675, val_loss=0.144, val_acc=0.967, train_loss_epoch=0.0114]\n",
      "Epoch 95:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.011, v_num=3, train_loss_step=0.0107, val_loss=0.144, val_acc=0.967, train_loss_epoch=0.00922] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 95:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.013, v_num=3, train_loss_step=0.00157, val_loss=0.244, val_acc=0.918, train_loss_epoch=0.00922]\n",
      "Epoch 96:  85%|████████▍ | 130/153 [00:23<00:04,  5.62it/s, loss=0.012, v_num=3, train_loss_step=0.00964, val_loss=0.244, val_acc=0.918, train_loss_epoch=0.0156] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 96:  92%|█████████▏| 140/153 [00:26<00:02,  5.22it/s, loss=0.014, v_num=3, train_loss_step=0.00238, val_loss=0.185, val_acc=0.951, train_loss_epoch=0.0156]\n",
      "Epoch 97:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.006, v_num=3, train_loss_step=0.0047, val_loss=0.185, val_acc=0.951, train_loss_epoch=0.0205] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 97:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.006, v_num=3, train_loss_step=0.00418, val_loss=0.147, val_acc=0.951, train_loss_epoch=0.0205]\n",
      "Epoch 98:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.006, v_num=3, train_loss_step=0.0107, val_loss=0.147, val_acc=0.951, train_loss_epoch=0.00591]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 98:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.006, v_num=3, train_loss_step=0.00789, val_loss=0.163, val_acc=0.951, train_loss_epoch=0.00591]\n",
      "Epoch 99:  85%|████████▍ | 130/153 [00:22<00:03,  5.90it/s, loss=0.006, v_num=3, train_loss_step=0.00504, val_loss=0.163, val_acc=0.951, train_loss_epoch=0.00551] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 99:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.005, v_num=3, train_loss_step=0.00081, val_loss=0.181, val_acc=0.951, train_loss_epoch=0.00551]\n",
      "Epoch 100:  85%|████████▍ | 130/153 [00:22<00:03,  5.80it/s, loss=0.009, v_num=3, train_loss_step=0.00535, val_loss=0.181, val_acc=0.951, train_loss_epoch=0.00584]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 100:  92%|█████████▏| 140/153 [00:26<00:02,  5.33it/s, loss=0.005, v_num=3, train_loss_step=0.000634, val_loss=0.188, val_acc=0.951, train_loss_epoch=0.00584]\n",
      "Epoch 101:  85%|████████▍ | 130/153 [00:23<00:04,  5.46it/s, loss=0.005, v_num=3, train_loss_step=0.00525, val_loss=0.188, val_acc=0.951, train_loss_epoch=0.00539] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 101:  92%|█████████▏| 140/153 [00:27<00:02,  5.07it/s, loss=0.006, v_num=3, train_loss_step=0.00725, val_loss=0.189, val_acc=0.951, train_loss_epoch=0.00539]\n",
      "Epoch 102:  85%|████████▍ | 130/153 [00:22<00:03,  5.91it/s, loss=0.009, v_num=3, train_loss_step=0.00272, val_loss=0.189, val_acc=0.951, train_loss_epoch=0.00567]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 102:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.006, v_num=3, train_loss_step=0.00523, val_loss=0.154, val_acc=0.967, train_loss_epoch=0.00567]\n",
      "Epoch 103:  85%|████████▍ | 130/153 [00:21<00:03,  6.00it/s, loss=0.006, v_num=3, train_loss_step=0.00377, val_loss=0.154, val_acc=0.967, train_loss_epoch=0.00839]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 103:  92%|█████████▏| 140/153 [00:25<00:02,  5.52it/s, loss=0.006, v_num=3, train_loss_step=0.00156, val_loss=0.164, val_acc=0.951, train_loss_epoch=0.00839]\n",
      "Epoch 104:  85%|████████▍ | 130/153 [00:21<00:03,  6.01it/s, loss=0.004, v_num=3, train_loss_step=0.00538, val_loss=0.164, val_acc=0.951, train_loss_epoch=0.00505]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 104:  92%|█████████▏| 140/153 [00:25<00:02,  5.52it/s, loss=0.005, v_num=3, train_loss_step=0.00336, val_loss=0.148, val_acc=0.951, train_loss_epoch=0.00505]\n",
      "Epoch 105:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.005, v_num=3, train_loss_step=0.0014, val_loss=0.148, val_acc=0.951, train_loss_epoch=0.00478] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 105:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.006, v_num=3, train_loss_step=0.000161, val_loss=0.182, val_acc=0.951, train_loss_epoch=0.00478]\n",
      "Epoch 106:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.004, v_num=3, train_loss_step=0.00135, val_loss=0.182, val_acc=0.951, train_loss_epoch=0.00555] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 106:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.005, v_num=3, train_loss_step=0.000487, val_loss=0.177, val_acc=0.951, train_loss_epoch=0.00555]\n",
      "Epoch 107:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.003, v_num=3, train_loss_step=0.000297, val_loss=0.177, val_acc=0.951, train_loss_epoch=0.00506]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 107:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.005, v_num=3, train_loss_step=0.0219, val_loss=0.151, val_acc=0.951, train_loss_epoch=0.00506]  \n",
      "Epoch 108:  85%|████████▍ | 130/153 [00:22<00:03,  5.87it/s, loss=0.006, v_num=3, train_loss_step=0.00158, val_loss=0.151, val_acc=0.951, train_loss_epoch=0.00478] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 108:  92%|█████████▏| 140/153 [00:25<00:02,  5.39it/s, loss=0.005, v_num=3, train_loss_step=0.000726, val_loss=0.137, val_acc=0.967, train_loss_epoch=0.00478]\n",
      "Epoch 109:  85%|████████▍ | 130/153 [00:21<00:03,  5.99it/s, loss=0.005, v_num=3, train_loss_step=0.00109, val_loss=0.137, val_acc=0.967, train_loss_epoch=0.00575] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 109:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.005, v_num=3, train_loss_step=0.000223, val_loss=0.133, val_acc=0.967, train_loss_epoch=0.00575]\n",
      "Epoch 110:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.006, v_num=3, train_loss_step=0.0534, val_loss=0.133, val_acc=0.967, train_loss_epoch=0.00631]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 110:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.007, v_num=3, train_loss_step=0.00614, val_loss=0.276, val_acc=0.918, train_loss_epoch=0.00631]\n",
      "Epoch 111:  85%|████████▍ | 130/153 [00:21<00:03,  5.99it/s, loss=0.009, v_num=3, train_loss_step=0.0579, val_loss=0.276, val_acc=0.918, train_loss_epoch=0.00731]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 111:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.009, v_num=3, train_loss_step=0.00304, val_loss=0.148, val_acc=0.951, train_loss_epoch=0.00731]\n",
      "Epoch 112:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.004, v_num=3, train_loss_step=0.00189, val_loss=0.148, val_acc=0.951, train_loss_epoch=0.00832]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 112:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.004, v_num=3, train_loss_step=0.000572, val_loss=0.149, val_acc=0.967, train_loss_epoch=0.00832]\n",
      "Epoch 113:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.005, v_num=3, train_loss_step=0.00565, val_loss=0.149, val_acc=0.967, train_loss_epoch=0.00531] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 113:  92%|█████████▏| 140/153 [00:25<00:02,  5.51it/s, loss=0.004, v_num=3, train_loss_step=0.000522, val_loss=0.187, val_acc=0.951, train_loss_epoch=0.00531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.005, v_num=3, train_loss_step=0.0024, val_loss=0.187, val_acc=0.951, train_loss_epoch=0.00525]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 114:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.006, v_num=3, train_loss_step=0.00269, val_loss=0.196, val_acc=0.951, train_loss_epoch=0.00525]\n",
      "Epoch 115:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.005, v_num=3, train_loss_step=0.0122, val_loss=0.196, val_acc=0.951, train_loss_epoch=0.00575]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 115:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.008, v_num=3, train_loss_step=0.0142, val_loss=0.165, val_acc=0.951, train_loss_epoch=0.00575]\n",
      "Epoch 116:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.004, v_num=3, train_loss_step=0.00725, val_loss=0.165, val_acc=0.951, train_loss_epoch=0.00603]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 116:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.005, v_num=3, train_loss_step=0.00524, val_loss=0.146, val_acc=0.951, train_loss_epoch=0.00603]\n",
      "Epoch 117:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.005, v_num=3, train_loss_step=0.00471, val_loss=0.146, val_acc=0.951, train_loss_epoch=0.00475]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 117:  92%|█████████▏| 140/153 [00:25<00:02,  5.51it/s, loss=0.003, v_num=3, train_loss_step=0.00207, val_loss=0.244, val_acc=0.918, train_loss_epoch=0.00475]\n",
      "Epoch 118:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.006, v_num=3, train_loss_step=0.000686, val_loss=0.244, val_acc=0.918, train_loss_epoch=0.00486]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 118:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.006, v_num=3, train_loss_step=0.000262, val_loss=0.224, val_acc=0.918, train_loss_epoch=0.00486]\n",
      "Epoch 119:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.006, v_num=3, train_loss_step=0.00115, val_loss=0.224, val_acc=0.918, train_loss_epoch=0.00515] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 119:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.006, v_num=3, train_loss_step=0.00792, val_loss=0.149, val_acc=0.951, train_loss_epoch=0.00515]\n",
      "Epoch 120:  85%|████████▍ | 130/153 [00:22<00:03,  5.84it/s, loss=0.003, v_num=3, train_loss_step=0.0011, val_loss=0.149, val_acc=0.951, train_loss_epoch=0.0044]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 120:  92%|█████████▏| 140/153 [00:26<00:02,  5.34it/s, loss=0.003, v_num=3, train_loss_step=0.00522, val_loss=0.226, val_acc=0.918, train_loss_epoch=0.0044]\n",
      "Epoch 121:  85%|████████▍ | 130/153 [00:22<00:03,  5.82it/s, loss=0.003, v_num=3, train_loss_step=0.00157, val_loss=0.226, val_acc=0.918, train_loss_epoch=0.00476] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 121:  92%|█████████▏| 140/153 [00:26<00:02,  5.37it/s, loss=0.003, v_num=3, train_loss_step=0.00223, val_loss=0.175, val_acc=0.934, train_loss_epoch=0.00476]\n",
      "Epoch 122:  85%|████████▍ | 130/153 [00:23<00:04,  5.63it/s, loss=0.007, v_num=3, train_loss_step=0.00662, val_loss=0.175, val_acc=0.934, train_loss_epoch=0.00492] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 122:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.006, v_num=3, train_loss_step=0.00109, val_loss=0.253, val_acc=0.918, train_loss_epoch=0.00492]\n",
      "Epoch 123:  85%|████████▍ | 130/153 [00:22<00:03,  5.84it/s, loss=0.004, v_num=3, train_loss_step=0.00199, val_loss=0.253, val_acc=0.918, train_loss_epoch=0.00532]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 123:  92%|█████████▏| 140/153 [00:25<00:02,  5.40it/s, loss=0.004, v_num=3, train_loss_step=0.0337, val_loss=0.176, val_acc=0.934, train_loss_epoch=0.00532] \n",
      "Epoch 124:  85%|████████▍ | 130/153 [00:22<00:03,  5.91it/s, loss=0.008, v_num=3, train_loss_step=0.00262, val_loss=0.176, val_acc=0.934, train_loss_epoch=0.00463]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 124:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.009, v_num=3, train_loss_step=0.000956, val_loss=0.224, val_acc=0.918, train_loss_epoch=0.00463]\n",
      "Epoch 124:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.009, v_num=3, train_loss_step=0.000956, val_loss=0.224, val_acc=0.918, train_loss_epoch=0.00463]\n"
     ]
    }
   ],
   "source": [
    "configs['DATASET']['AUGMENTATION'] = 'uniform'\n",
    "configs['LOSS'] = 'cross_entropy'\n",
    "configs['CHECKPOINT']['SAVE_NAME'] = 'crnn-bmw-uniform'\n",
    "torch.cuda.empty_cache()\n",
    "do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: uniform\n",
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name        | Type        | Params\n",
      "---------------------------------------------\n",
      "0  | conv1       | Conv2d      | 640   \n",
      "1  | bn1         | BatchNorm2d | 128   \n",
      "2  | dropout1    | Dropout     | 0     \n",
      "3  | conv2       | Conv2d      | 73 K  \n",
      "4  | bn2         | BatchNorm2d | 256   \n",
      "5  | dropout2    | Dropout     | 0     \n",
      "6  | conv3       | Conv2d      | 147 K \n",
      "7  | bn3         | BatchNorm2d | 256   \n",
      "8  | dropout3    | Dropout     | 0     \n",
      "9  | conv4       | Conv2d      | 147 K \n",
      "10 | bn4         | BatchNorm2d | 256   \n",
      "11 | dropout4    | Dropout     | 0     \n",
      "12 | rnn         | GRU         | 21 K  \n",
      "13 | dropout_rnn | Dropout     | 0     \n",
      "14 | linear      | Linear      | 198   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=1.271, v_num=4, train_loss_step=1.02]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=1.254, v_num=4, train_loss_step=1.27, val_loss=1.15, val_acc=0.672]\n",
      "Epoch 1:  85%|████████▍ | 130/153 [00:22<00:03,  5.90it/s, loss=1.055, v_num=4, train_loss_step=0.846, val_loss=1.15, val_acc=0.672, train_loss_epoch=1.33]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=1.050, v_num=4, train_loss_step=1.86, val_loss=1.04, val_acc=0.672, train_loss_epoch=1.33] \n",
      "Epoch 2:  85%|████████▍ | 130/153 [00:21<00:03,  5.99it/s, loss=0.985, v_num=4, train_loss_step=0.691, val_loss=1.04, val_acc=0.672, train_loss_epoch=1.14]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=1.055, v_num=4, train_loss_step=2.5, val_loss=1.11, val_acc=0.656, train_loss_epoch=1.14]  \n",
      "Epoch 3:  85%|████████▍ | 130/153 [00:21<00:03,  5.91it/s, loss=1.070, v_num=4, train_loss_step=1.14, val_loss=1.11, val_acc=0.656, train_loss_epoch=1.02] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=1.055, v_num=4, train_loss_step=0.885, val_loss=0.882, val_acc=0.77, train_loss_epoch=1.02]\n",
      "Epoch 4:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.836, v_num=4, train_loss_step=0.453, val_loss=0.882, val_acc=0.77, train_loss_epoch=0.996]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.874, v_num=4, train_loss_step=0.47, val_loss=0.898, val_acc=0.738, train_loss_epoch=0.996]\n",
      "Epoch 5:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.887, v_num=4, train_loss_step=1.43, val_loss=0.898, val_acc=0.738, train_loss_epoch=0.876] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.956, v_num=4, train_loss_step=0.456, val_loss=0.893, val_acc=0.82, train_loss_epoch=0.876]\n",
      "Epoch 6:  85%|████████▍ | 130/153 [00:22<00:03,  5.84it/s, loss=0.837, v_num=4, train_loss_step=0.762, val_loss=0.893, val_acc=0.82, train_loss_epoch=0.814]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 140/153 [00:26<00:02,  5.37it/s, loss=0.776, v_num=4, train_loss_step=0.828, val_loss=0.854, val_acc=0.787, train_loss_epoch=0.814]\n",
      "Epoch 7:  85%|████████▍ | 130/153 [00:22<00:03,  5.88it/s, loss=0.834, v_num=4, train_loss_step=0.742, val_loss=0.854, val_acc=0.787, train_loss_epoch=0.806]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 140/153 [00:26<00:02,  5.38it/s, loss=0.972, v_num=4, train_loss_step=2.2, val_loss=0.944, val_acc=0.754, train_loss_epoch=0.806]  \n",
      "Epoch 8:  85%|████████▍ | 130/153 [00:22<00:03,  5.88it/s, loss=0.698, v_num=4, train_loss_step=0.518, val_loss=0.944, val_acc=0.754, train_loss_epoch=0.788]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 140/153 [00:26<00:02,  5.38it/s, loss=0.654, v_num=4, train_loss_step=0.45, val_loss=0.913, val_acc=0.77, train_loss_epoch=0.788]  \n",
      "Epoch 9:  85%|████████▍ | 130/153 [00:22<00:03,  5.91it/s, loss=0.762, v_num=4, train_loss_step=0.675, val_loss=0.913, val_acc=0.77, train_loss_epoch=0.764]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.799, v_num=4, train_loss_step=0.844, val_loss=0.736, val_acc=0.82, train_loss_epoch=0.764]\n",
      "Epoch 10:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.841, v_num=4, train_loss_step=0.458, val_loss=0.736, val_acc=0.82, train_loss_epoch=0.717]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.793, v_num=4, train_loss_step=1.09, val_loss=0.798, val_acc=0.803, train_loss_epoch=0.717]\n",
      "Epoch 11:  85%|████████▍ | 130/153 [00:22<00:03,  5.90it/s, loss=0.668, v_num=4, train_loss_step=0.452, val_loss=0.798, val_acc=0.803, train_loss_epoch=0.747]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 140/153 [00:25<00:02,  5.41it/s, loss=0.671, v_num=4, train_loss_step=0.428, val_loss=0.989, val_acc=0.738, train_loss_epoch=0.747]\n",
      "Epoch 12:  85%|████████▍ | 130/153 [00:21<00:03,  5.91it/s, loss=0.692, v_num=4, train_loss_step=0.788, val_loss=0.989, val_acc=0.738, train_loss_epoch=0.706]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.730, v_num=4, train_loss_step=0.571, val_loss=0.688, val_acc=0.852, train_loss_epoch=0.706]\n",
      "Epoch 13:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.645, v_num=4, train_loss_step=0.443, val_loss=0.688, val_acc=0.852, train_loss_epoch=0.699]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.672, v_num=4, train_loss_step=0.45, val_loss=0.786, val_acc=0.82, train_loss_epoch=0.699]  \n",
      "Epoch 14:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.603, v_num=4, train_loss_step=0.776, val_loss=0.786, val_acc=0.82, train_loss_epoch=0.659]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.686, v_num=4, train_loss_step=1.84, val_loss=0.639, val_acc=0.902, train_loss_epoch=0.659]\n",
      "Epoch 15:  85%|████████▍ | 130/153 [00:22<00:03,  5.90it/s, loss=0.680, v_num=4, train_loss_step=0.472, val_loss=0.639, val_acc=0.902, train_loss_epoch=0.68]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.654, v_num=4, train_loss_step=0.435, val_loss=0.725, val_acc=0.869, train_loss_epoch=0.68]\n",
      "Epoch 16:  85%|████████▍ | 130/153 [00:22<00:03,  5.88it/s, loss=0.692, v_num=4, train_loss_step=0.567, val_loss=0.725, val_acc=0.869, train_loss_epoch=0.722]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  92%|█████████▏| 140/153 [00:25<00:02,  5.39it/s, loss=0.625, v_num=4, train_loss_step=0.458, val_loss=0.682, val_acc=0.869, train_loss_epoch=0.722]\n",
      "Epoch 17:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.617, v_num=4, train_loss_step=0.449, val_loss=0.682, val_acc=0.869, train_loss_epoch=0.649]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.678, v_num=4, train_loss_step=0.435, val_loss=0.75, val_acc=0.852, train_loss_epoch=0.649] \n",
      "Epoch 18:  85%|████████▍ | 130/153 [00:22<00:03,  5.90it/s, loss=0.611, v_num=4, train_loss_step=0.431, val_loss=0.75, val_acc=0.852, train_loss_epoch=0.647]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  92%|█████████▏| 140/153 [00:25<00:02,  5.40it/s, loss=0.558, v_num=4, train_loss_step=0.608, val_loss=0.583, val_acc=0.902, train_loss_epoch=0.647]\n",
      "Epoch 19:  85%|████████▍ | 130/153 [00:21<00:03,  5.91it/s, loss=0.651, v_num=4, train_loss_step=0.726, val_loss=0.583, val_acc=0.902, train_loss_epoch=0.605]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.630, v_num=4, train_loss_step=0.533, val_loss=0.793, val_acc=0.836, train_loss_epoch=0.605]\n",
      "Epoch 20:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.594, v_num=4, train_loss_step=1.04, val_loss=0.793, val_acc=0.836, train_loss_epoch=0.581] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.581, v_num=4, train_loss_step=0.441, val_loss=0.684, val_acc=0.869, train_loss_epoch=0.581]\n",
      "Epoch 21:  85%|████████▍ | 130/153 [00:21<00:03,  6.03it/s, loss=0.563, v_num=4, train_loss_step=0.46, val_loss=0.684, val_acc=0.869, train_loss_epoch=0.617] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  92%|█████████▏| 140/153 [00:25<00:02,  5.52it/s, loss=0.548, v_num=4, train_loss_step=0.638, val_loss=0.767, val_acc=0.852, train_loss_epoch=0.617]\n",
      "Epoch 22:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.632, v_num=4, train_loss_step=0.746, val_loss=0.767, val_acc=0.852, train_loss_epoch=0.614]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.663, v_num=4, train_loss_step=1.17, val_loss=0.829, val_acc=0.836, train_loss_epoch=0.614] \n",
      "Epoch 23:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.659, v_num=4, train_loss_step=1.54, val_loss=0.829, val_acc=0.836, train_loss_epoch=0.615] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.692, v_num=4, train_loss_step=0.597, val_loss=1.13, val_acc=0.738, train_loss_epoch=0.615]\n",
      "Epoch 24:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.565, v_num=4, train_loss_step=0.463, val_loss=1.13, val_acc=0.738, train_loss_epoch=0.622]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.603, v_num=4, train_loss_step=0.692, val_loss=0.587, val_acc=0.934, train_loss_epoch=0.622]\n",
      "Epoch 25:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.516, v_num=4, train_loss_step=0.452, val_loss=0.587, val_acc=0.934, train_loss_epoch=0.6]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.536, v_num=4, train_loss_step=0.448, val_loss=0.616, val_acc=0.918, train_loss_epoch=0.6]\n",
      "Epoch 26:  85%|████████▍ | 130/153 [00:22<00:03,  5.89it/s, loss=0.513, v_num=4, train_loss_step=0.992, val_loss=0.616, val_acc=0.918, train_loss_epoch=0.544]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26:  92%|█████████▏| 140/153 [00:25<00:02,  5.39it/s, loss=0.493, v_num=4, train_loss_step=0.484, val_loss=0.512, val_acc=0.951, train_loss_epoch=0.544]\n",
      "Epoch 27:  85%|████████▍ | 130/153 [00:22<00:03,  5.89it/s, loss=0.546, v_num=4, train_loss_step=0.499, val_loss=0.512, val_acc=0.951, train_loss_epoch=0.527]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27:  92%|█████████▏| 140/153 [00:25<00:02,  5.41it/s, loss=0.525, v_num=4, train_loss_step=0.441, val_loss=0.533, val_acc=0.918, train_loss_epoch=0.527]\n",
      "Epoch 28:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.500, v_num=4, train_loss_step=0.471, val_loss=0.533, val_acc=0.918, train_loss_epoch=0.525]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.495, v_num=4, train_loss_step=0.446, val_loss=0.612, val_acc=0.852, train_loss_epoch=0.525]\n",
      "Epoch 29:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.470, v_num=4, train_loss_step=0.44, val_loss=0.612, val_acc=0.852, train_loss_epoch=0.514] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.472, v_num=4, train_loss_step=0.447, val_loss=0.617, val_acc=0.869, train_loss_epoch=0.514]\n",
      "Epoch 30:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.473, v_num=4, train_loss_step=0.458, val_loss=0.617, val_acc=0.869, train_loss_epoch=0.502]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.487, v_num=4, train_loss_step=0.499, val_loss=0.507, val_acc=0.951, train_loss_epoch=0.502]\n",
      "Epoch 31:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.481, v_num=4, train_loss_step=0.574, val_loss=0.507, val_acc=0.951, train_loss_epoch=0.503]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.494, v_num=4, train_loss_step=0.448, val_loss=0.614, val_acc=0.902, train_loss_epoch=0.503]\n",
      "Epoch 32:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.479, v_num=4, train_loss_step=0.44, val_loss=0.614, val_acc=0.902, train_loss_epoch=0.507] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.504, v_num=4, train_loss_step=0.491, val_loss=0.775, val_acc=0.852, train_loss_epoch=0.507]\n",
      "Epoch 33:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.488, v_num=4, train_loss_step=0.452, val_loss=0.775, val_acc=0.852, train_loss_epoch=0.49] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.472, v_num=4, train_loss_step=0.437, val_loss=0.688, val_acc=0.836, train_loss_epoch=0.49]\n",
      "Epoch 34:  85%|████████▍ | 130/153 [00:22<00:03,  5.90it/s, loss=0.515, v_num=4, train_loss_step=0.448, val_loss=0.688, val_acc=0.836, train_loss_epoch=0.49]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.513, v_num=4, train_loss_step=0.447, val_loss=0.579, val_acc=0.918, train_loss_epoch=0.49]\n",
      "Epoch 35:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.476, v_num=4, train_loss_step=0.448, val_loss=0.579, val_acc=0.918, train_loss_epoch=0.535]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.470, v_num=4, train_loss_step=0.44, val_loss=0.692, val_acc=0.869, train_loss_epoch=0.535] \n",
      "Epoch 36:  85%|████████▍ | 130/153 [00:21<00:03,  5.99it/s, loss=0.512, v_num=4, train_loss_step=0.44, val_loss=0.692, val_acc=0.869, train_loss_epoch=0.532] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.492, v_num=4, train_loss_step=0.434, val_loss=0.745, val_acc=0.852, train_loss_epoch=0.532]\n",
      "Epoch 37:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.495, v_num=4, train_loss_step=0.444, val_loss=0.745, val_acc=0.852, train_loss_epoch=0.49] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.500, v_num=4, train_loss_step=0.603, val_loss=0.485, val_acc=0.984, train_loss_epoch=0.49]\n",
      "Epoch 38:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.503, v_num=4, train_loss_step=0.442, val_loss=0.485, val_acc=0.984, train_loss_epoch=0.506]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.526, v_num=4, train_loss_step=0.434, val_loss=0.473, val_acc=0.984, train_loss_epoch=0.506]\n",
      "Epoch 39:  85%|████████▍ | 130/153 [00:21<00:03,  6.00it/s, loss=0.525, v_num=4, train_loss_step=0.471, val_loss=0.473, val_acc=0.984, train_loss_epoch=0.495]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.504, v_num=4, train_loss_step=0.438, val_loss=0.499, val_acc=0.951, train_loss_epoch=0.495]\n",
      "Epoch 40:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.525, v_num=4, train_loss_step=0.513, val_loss=0.499, val_acc=0.951, train_loss_epoch=0.487]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 40:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.500, v_num=4, train_loss_step=0.465, val_loss=0.626, val_acc=0.869, train_loss_epoch=0.487]\n",
      "Epoch 41:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.497, v_num=4, train_loss_step=0.892, val_loss=0.626, val_acc=0.869, train_loss_epoch=0.52] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 41:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.475, v_num=4, train_loss_step=0.451, val_loss=0.572, val_acc=0.918, train_loss_epoch=0.52]\n",
      "Epoch 42:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.458, v_num=4, train_loss_step=0.46, val_loss=0.572, val_acc=0.918, train_loss_epoch=0.472] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 42:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.452, v_num=4, train_loss_step=0.436, val_loss=0.502, val_acc=0.951, train_loss_epoch=0.472]\n",
      "Epoch 43:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.458, v_num=4, train_loss_step=0.459, val_loss=0.502, val_acc=0.951, train_loss_epoch=0.466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 43:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.462, v_num=4, train_loss_step=0.439, val_loss=0.475, val_acc=0.984, train_loss_epoch=0.466]\n",
      "Epoch 44:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.459, v_num=4, train_loss_step=0.441, val_loss=0.475, val_acc=0.984, train_loss_epoch=0.458]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 44:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.457, v_num=4, train_loss_step=0.465, val_loss=0.484, val_acc=0.967, train_loss_epoch=0.458]\n",
      "Epoch 45:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.449, v_num=4, train_loss_step=0.454, val_loss=0.484, val_acc=0.967, train_loss_epoch=0.46] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 45:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.457, v_num=4, train_loss_step=0.618, val_loss=0.557, val_acc=0.918, train_loss_epoch=0.46]\n",
      "Epoch 46:  85%|████████▍ | 130/153 [00:22<00:03,  5.80it/s, loss=0.526, v_num=4, train_loss_step=0.646, val_loss=0.557, val_acc=0.918, train_loss_epoch=0.456]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.535, v_num=4, train_loss_step=0.434, val_loss=0.576, val_acc=0.918, train_loss_epoch=0.456]\n",
      "Epoch 47:  85%|████████▍ | 130/153 [00:22<00:03,  5.79it/s, loss=0.512, v_num=4, train_loss_step=0.766, val_loss=0.576, val_acc=0.918, train_loss_epoch=0.508]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 47:  92%|█████████▏| 140/153 [00:26<00:02,  5.35it/s, loss=0.496, v_num=4, train_loss_step=0.549, val_loss=0.493, val_acc=0.951, train_loss_epoch=0.508]\n",
      "Epoch 48:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.470, v_num=4, train_loss_step=0.51, val_loss=0.493, val_acc=0.951, train_loss_epoch=0.506] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 48:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.460, v_num=4, train_loss_step=0.432, val_loss=0.552, val_acc=0.934, train_loss_epoch=0.506]\n",
      "Epoch 49:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.458, v_num=4, train_loss_step=0.452, val_loss=0.552, val_acc=0.934, train_loss_epoch=0.482]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 49:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.456, v_num=4, train_loss_step=0.443, val_loss=0.551, val_acc=0.951, train_loss_epoch=0.482]\n",
      "Epoch 50:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.467, v_num=4, train_loss_step=0.435, val_loss=0.551, val_acc=0.951, train_loss_epoch=0.464]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 50:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.467, v_num=4, train_loss_step=0.438, val_loss=0.6, val_acc=0.902, train_loss_epoch=0.464]  \n",
      "Epoch 51:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.446, v_num=4, train_loss_step=0.439, val_loss=0.6, val_acc=0.902, train_loss_epoch=0.468]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 51:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.449, v_num=4, train_loss_step=0.433, val_loss=0.511, val_acc=0.934, train_loss_epoch=0.468]\n",
      "Epoch 52:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.463, v_num=4, train_loss_step=0.434, val_loss=0.511, val_acc=0.934, train_loss_epoch=0.452]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 52:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.462, v_num=4, train_loss_step=0.428, val_loss=0.475, val_acc=0.984, train_loss_epoch=0.452]\n",
      "Epoch 53:  85%|████████▍ | 130/153 [00:22<00:03,  5.91it/s, loss=0.449, v_num=4, train_loss_step=0.445, val_loss=0.475, val_acc=0.984, train_loss_epoch=0.452]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 53:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.445, v_num=4, train_loss_step=0.439, val_loss=0.482, val_acc=0.984, train_loss_epoch=0.452]\n",
      "Epoch 54:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.452, v_num=4, train_loss_step=0.452, val_loss=0.482, val_acc=0.984, train_loss_epoch=0.45] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 54:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.445, v_num=4, train_loss_step=0.43, val_loss=0.508, val_acc=0.951, train_loss_epoch=0.45] \n",
      "Epoch 55:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.445, v_num=4, train_loss_step=0.466, val_loss=0.508, val_acc=0.951, train_loss_epoch=0.452]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 55:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.456, v_num=4, train_loss_step=0.446, val_loss=0.543, val_acc=0.918, train_loss_epoch=0.452]\n",
      "Epoch 56:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.450, v_num=4, train_loss_step=0.467, val_loss=0.543, val_acc=0.918, train_loss_epoch=0.448]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 56:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.450, v_num=4, train_loss_step=0.438, val_loss=0.51, val_acc=0.934, train_loss_epoch=0.448] \n",
      "Epoch 57:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.442, v_num=4, train_loss_step=0.446, val_loss=0.51, val_acc=0.934, train_loss_epoch=0.448]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 57:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.445, v_num=4, train_loss_step=0.427, val_loss=0.485, val_acc=0.951, train_loss_epoch=0.448]\n",
      "Epoch 58:  85%|████████▍ | 130/153 [00:21<00:03,  6.01it/s, loss=0.444, v_num=4, train_loss_step=0.444, val_loss=0.485, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 58:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.444, v_num=4, train_loss_step=0.435, val_loss=0.487, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 59:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.461, v_num=4, train_loss_step=0.484, val_loss=0.487, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 59:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.453, v_num=4, train_loss_step=0.47, val_loss=0.516, val_acc=0.951, train_loss_epoch=0.445] \n",
      "Epoch 60:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.461, v_num=4, train_loss_step=0.457, val_loss=0.516, val_acc=0.951, train_loss_epoch=0.448]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 60:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.455, v_num=4, train_loss_step=0.44, val_loss=0.523, val_acc=0.934, train_loss_epoch=0.448] \n",
      "Epoch 61:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.447, v_num=4, train_loss_step=0.463, val_loss=0.523, val_acc=0.934, train_loss_epoch=0.467]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 61:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.449, v_num=4, train_loss_step=0.47, val_loss=0.546, val_acc=0.934, train_loss_epoch=0.467] \n",
      "Epoch 62:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.442, v_num=4, train_loss_step=0.451, val_loss=0.546, val_acc=0.934, train_loss_epoch=0.449]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 62:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.443, v_num=4, train_loss_step=0.442, val_loss=0.496, val_acc=0.951, train_loss_epoch=0.449]\n",
      "Epoch 63:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.448, v_num=4, train_loss_step=0.434, val_loss=0.496, val_acc=0.951, train_loss_epoch=0.447]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 63:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.452, v_num=4, train_loss_step=0.511, val_loss=0.463, val_acc=0.984, train_loss_epoch=0.447]\n",
      "Epoch 64:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.463, v_num=4, train_loss_step=0.437, val_loss=0.463, val_acc=0.984, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 64:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.449, v_num=4, train_loss_step=0.434, val_loss=0.534, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 65:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.513, v_num=4, train_loss_step=0.433, val_loss=0.534, val_acc=0.951, train_loss_epoch=0.452]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 65:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.476, v_num=4, train_loss_step=0.43, val_loss=0.497, val_acc=0.951, train_loss_epoch=0.452] \n",
      "Epoch 66:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.471, v_num=4, train_loss_step=0.442, val_loss=0.497, val_acc=0.951, train_loss_epoch=0.502]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 66:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.456, v_num=4, train_loss_step=0.436, val_loss=0.604, val_acc=0.918, train_loss_epoch=0.502]\n",
      "Epoch 67:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.455, v_num=4, train_loss_step=0.446, val_loss=0.604, val_acc=0.918, train_loss_epoch=0.463]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 67:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.460, v_num=4, train_loss_step=0.495, val_loss=0.481, val_acc=0.984, train_loss_epoch=0.463]\n",
      "Epoch 68:  85%|████████▍ | 130/153 [00:21<00:03,  6.01it/s, loss=0.447, v_num=4, train_loss_step=0.435, val_loss=0.481, val_acc=0.984, train_loss_epoch=0.456]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 68:  92%|█████████▏| 140/153 [00:25<00:02,  5.51it/s, loss=0.451, v_num=4, train_loss_step=0.457, val_loss=0.461, val_acc=0.984, train_loss_epoch=0.456]\n",
      "Epoch 69:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.444, v_num=4, train_loss_step=0.434, val_loss=0.461, val_acc=0.984, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.445, v_num=4, train_loss_step=0.467, val_loss=0.461, val_acc=0.984, train_loss_epoch=0.445]\n",
      "Epoch 70:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.449, v_num=4, train_loss_step=0.459, val_loss=0.461, val_acc=0.984, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 70:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.451, v_num=4, train_loss_step=0.438, val_loss=0.491, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 71:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.520, v_num=4, train_loss_step=0.453, val_loss=0.491, val_acc=0.951, train_loss_epoch=0.447]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 71:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.482, v_num=4, train_loss_step=0.446, val_loss=0.603, val_acc=0.885, train_loss_epoch=0.447]\n",
      "Epoch 72:  85%|████████▍ | 130/153 [00:21<00:03,  5.99it/s, loss=0.450, v_num=4, train_loss_step=0.457, val_loss=0.603, val_acc=0.885, train_loss_epoch=0.463]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 72:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.466, v_num=4, train_loss_step=0.659, val_loss=0.52, val_acc=0.934, train_loss_epoch=0.463] \n",
      "Epoch 73:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.465, v_num=4, train_loss_step=0.439, val_loss=0.52, val_acc=0.934, train_loss_epoch=0.47] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 73:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.449, v_num=4, train_loss_step=0.439, val_loss=0.493, val_acc=0.967, train_loss_epoch=0.47]\n",
      "Epoch 74:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.445, v_num=4, train_loss_step=0.441, val_loss=0.493, val_acc=0.967, train_loss_epoch=0.459]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 74:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.444, v_num=4, train_loss_step=0.447, val_loss=0.533, val_acc=0.934, train_loss_epoch=0.459]\n",
      "Epoch 75:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.447, v_num=4, train_loss_step=0.437, val_loss=0.533, val_acc=0.934, train_loss_epoch=0.446]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 75:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.445, v_num=4, train_loss_step=0.434, val_loss=0.47, val_acc=0.984, train_loss_epoch=0.446] \n",
      "Epoch 76:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.450, v_num=4, train_loss_step=0.446, val_loss=0.47, val_acc=0.984, train_loss_epoch=0.453]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 76:  92%|█████████▏| 140/153 [00:25<00:02,  5.49it/s, loss=0.449, v_num=4, train_loss_step=0.452, val_loss=0.469, val_acc=0.984, train_loss_epoch=0.453]\n",
      "Epoch 77:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.439, v_num=4, train_loss_step=0.435, val_loss=0.469, val_acc=0.984, train_loss_epoch=0.446]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 77:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.439, v_num=4, train_loss_step=0.45, val_loss=0.487, val_acc=0.951, train_loss_epoch=0.446] \n",
      "Epoch 78:  85%|████████▍ | 130/153 [00:21<00:03,  5.97it/s, loss=0.442, v_num=4, train_loss_step=0.439, val_loss=0.487, val_acc=0.951, train_loss_epoch=0.444]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 78:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.442, v_num=4, train_loss_step=0.433, val_loss=0.472, val_acc=0.967, train_loss_epoch=0.444]\n",
      "Epoch 79:  85%|████████▍ | 130/153 [00:21<00:03,  5.98it/s, loss=0.442, v_num=4, train_loss_step=0.445, val_loss=0.472, val_acc=0.967, train_loss_epoch=0.444]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 79:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.442, v_num=4, train_loss_step=0.435, val_loss=0.468, val_acc=0.984, train_loss_epoch=0.444]\n",
      "Epoch 80:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.445, v_num=4, train_loss_step=0.442, val_loss=0.468, val_acc=0.984, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 80:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.445, v_num=4, train_loss_step=0.43, val_loss=0.506, val_acc=0.951, train_loss_epoch=0.443] \n",
      "Epoch 81:  85%|████████▍ | 130/153 [00:21<00:03,  6.01it/s, loss=0.443, v_num=4, train_loss_step=0.441, val_loss=0.506, val_acc=0.951, train_loss_epoch=0.447]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 81:  92%|█████████▏| 140/153 [00:25<00:02,  5.50it/s, loss=0.439, v_num=4, train_loss_step=0.434, val_loss=0.479, val_acc=0.984, train_loss_epoch=0.447]\n",
      "Epoch 82:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.441, v_num=4, train_loss_step=0.446, val_loss=0.479, val_acc=0.984, train_loss_epoch=0.442]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 82:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.441, v_num=4, train_loss_step=0.431, val_loss=0.472, val_acc=0.984, train_loss_epoch=0.442]\n",
      "Epoch 83:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.449, v_num=4, train_loss_step=0.469, val_loss=0.472, val_acc=0.984, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 83:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.449, v_num=4, train_loss_step=0.426, val_loss=0.466, val_acc=0.984, train_loss_epoch=0.443]\n",
      "Epoch 84:  85%|████████▍ | 130/153 [00:21<00:03,  6.03it/s, loss=0.458, v_num=4, train_loss_step=0.438, val_loss=0.466, val_acc=0.984, train_loss_epoch=0.444]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 84:  92%|█████████▏| 140/153 [00:25<00:02,  5.51it/s, loss=0.448, v_num=4, train_loss_step=0.426, val_loss=0.495, val_acc=0.967, train_loss_epoch=0.444]\n",
      "Epoch 85:  85%|████████▍ | 130/153 [00:21<00:03,  5.91it/s, loss=0.449, v_num=4, train_loss_step=0.462, val_loss=0.495, val_acc=0.967, train_loss_epoch=0.447]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 85:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.446, v_num=4, train_loss_step=0.438, val_loss=0.494, val_acc=0.967, train_loss_epoch=0.447]\n",
      "Epoch 86:  85%|████████▍ | 130/153 [00:22<00:03,  5.86it/s, loss=0.442, v_num=4, train_loss_step=0.437, val_loss=0.494, val_acc=0.967, train_loss_epoch=0.458]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 86:  92%|█████████▏| 140/153 [00:26<00:02,  5.37it/s, loss=0.444, v_num=4, train_loss_step=0.453, val_loss=0.526, val_acc=0.951, train_loss_epoch=0.458]\n",
      "Epoch 87:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.441, v_num=4, train_loss_step=0.449, val_loss=0.526, val_acc=0.951, train_loss_epoch=0.447]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 87:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.447, v_num=4, train_loss_step=0.546, val_loss=0.494, val_acc=0.967, train_loss_epoch=0.447]\n",
      "Epoch 88:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.439, v_num=4, train_loss_step=0.435, val_loss=0.494, val_acc=0.967, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 88:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.439, v_num=4, train_loss_step=0.432, val_loss=0.481, val_acc=0.967, train_loss_epoch=0.445]\n",
      "Epoch 89:  85%|████████▍ | 130/153 [00:22<00:03,  5.88it/s, loss=0.444, v_num=4, train_loss_step=0.492, val_loss=0.481, val_acc=0.967, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 89:  92%|█████████▏| 140/153 [00:25<00:02,  5.39it/s, loss=0.445, v_num=4, train_loss_step=0.435, val_loss=0.488, val_acc=0.967, train_loss_epoch=0.443]\n",
      "Epoch 90:  85%|████████▍ | 130/153 [00:22<00:03,  5.90it/s, loss=0.442, v_num=4, train_loss_step=0.46, val_loss=0.488, val_acc=0.967, train_loss_epoch=0.444] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 90:  92%|█████████▏| 140/153 [00:25<00:02,  5.40it/s, loss=0.444, v_num=4, train_loss_step=0.453, val_loss=0.497, val_acc=0.967, train_loss_epoch=0.444]\n",
      "Epoch 91:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.443, v_num=4, train_loss_step=0.443, val_loss=0.497, val_acc=0.967, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 91:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.441, v_num=4, train_loss_step=0.431, val_loss=0.486, val_acc=0.967, train_loss_epoch=0.445]\n",
      "Epoch 92:  85%|████████▍ | 130/153 [00:22<00:03,  5.88it/s, loss=0.446, v_num=4, train_loss_step=0.433, val_loss=0.486, val_acc=0.967, train_loss_epoch=0.441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92:  92%|█████████▏| 140/153 [00:25<00:02,  5.41it/s, loss=0.445, v_num=4, train_loss_step=0.446, val_loss=0.462, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Epoch 93:  85%|████████▍ | 130/153 [00:22<00:03,  5.88it/s, loss=0.446, v_num=4, train_loss_step=0.44, val_loss=0.462, val_acc=0.984, train_loss_epoch=0.444] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 93:  92%|█████████▏| 140/153 [00:26<00:02,  5.38it/s, loss=0.447, v_num=4, train_loss_step=0.447, val_loss=0.472, val_acc=0.984, train_loss_epoch=0.444]\n",
      "Epoch 94:  85%|████████▍ | 130/153 [00:21<00:03,  5.91it/s, loss=0.440, v_num=4, train_loss_step=0.451, val_loss=0.472, val_acc=0.984, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 94:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.440, v_num=4, train_loss_step=0.438, val_loss=0.468, val_acc=0.984, train_loss_epoch=0.443]\n",
      "Epoch 95:  85%|████████▍ | 130/153 [00:22<00:03,  5.86it/s, loss=0.438, v_num=4, train_loss_step=0.438, val_loss=0.468, val_acc=0.984, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 95:  92%|█████████▏| 140/153 [00:26<00:02,  5.38it/s, loss=0.436, v_num=4, train_loss_step=0.433, val_loss=0.473, val_acc=0.967, train_loss_epoch=0.443]\n",
      "Epoch 96:  85%|████████▍ | 130/153 [00:22<00:03,  5.91it/s, loss=0.446, v_num=4, train_loss_step=0.487, val_loss=0.473, val_acc=0.967, train_loss_epoch=0.442]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 96:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.445, v_num=4, train_loss_step=0.428, val_loss=0.465, val_acc=0.984, train_loss_epoch=0.442]\n",
      "Epoch 97:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.442, v_num=4, train_loss_step=0.448, val_loss=0.465, val_acc=0.984, train_loss_epoch=0.444]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 97:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.443, v_num=4, train_loss_step=0.43, val_loss=0.47, val_acc=0.967, train_loss_epoch=0.444]  \n",
      "Epoch 98:  85%|████████▍ | 130/153 [00:22<00:03,  5.88it/s, loss=0.444, v_num=4, train_loss_step=0.449, val_loss=0.47, val_acc=0.967, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 98:  92%|█████████▏| 140/153 [00:25<00:02,  5.41it/s, loss=0.441, v_num=4, train_loss_step=0.43, val_loss=0.474, val_acc=0.967, train_loss_epoch=0.443]\n",
      "Epoch 99:  85%|████████▍ | 130/153 [00:22<00:03,  5.89it/s, loss=0.441, v_num=4, train_loss_step=0.438, val_loss=0.474, val_acc=0.967, train_loss_epoch=0.442]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 99:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.440, v_num=4, train_loss_step=0.428, val_loss=0.459, val_acc=0.984, train_loss_epoch=0.442]\n",
      "Epoch 100:  85%|████████▍ | 130/153 [00:22<00:03,  5.84it/s, loss=0.444, v_num=4, train_loss_step=0.436, val_loss=0.459, val_acc=0.984, train_loss_epoch=0.442]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 100:  92%|█████████▏| 140/153 [00:26<00:02,  5.38it/s, loss=0.444, v_num=4, train_loss_step=0.441, val_loss=0.478, val_acc=0.967, train_loss_epoch=0.442]\n",
      "Epoch 101:  85%|████████▍ | 130/153 [00:22<00:03,  5.90it/s, loss=0.442, v_num=4, train_loss_step=0.437, val_loss=0.478, val_acc=0.967, train_loss_epoch=0.441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 101:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.446, v_num=4, train_loss_step=0.427, val_loss=0.463, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Epoch 102:  85%|████████▍ | 130/153 [00:22<00:03,  5.89it/s, loss=0.455, v_num=4, train_loss_step=0.481, val_loss=0.463, val_acc=0.984, train_loss_epoch=0.444]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 102:  92%|█████████▏| 140/153 [00:25<00:02,  5.41it/s, loss=0.454, v_num=4, train_loss_step=0.427, val_loss=0.478, val_acc=0.984, train_loss_epoch=0.444]\n",
      "Epoch 103:  85%|████████▍ | 130/153 [00:22<00:03,  5.82it/s, loss=0.443, v_num=4, train_loss_step=0.438, val_loss=0.478, val_acc=0.984, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 103:  92%|█████████▏| 140/153 [00:26<00:02,  5.31it/s, loss=0.445, v_num=4, train_loss_step=0.425, val_loss=0.505, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 104:  85%|████████▍ | 130/153 [00:22<00:03,  5.84it/s, loss=0.441, v_num=4, train_loss_step=0.442, val_loss=0.505, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 104:  92%|█████████▏| 140/153 [00:26<00:02,  5.37it/s, loss=0.443, v_num=4, train_loss_step=0.435, val_loss=0.467, val_acc=0.984, train_loss_epoch=0.445]\n",
      "Epoch 105:  85%|████████▍ | 130/153 [00:22<00:03,  5.87it/s, loss=0.443, v_num=4, train_loss_step=0.45, val_loss=0.467, val_acc=0.984, train_loss_epoch=0.442] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 105:  92%|█████████▏| 140/153 [00:26<00:02,  5.38it/s, loss=0.444, v_num=4, train_loss_step=0.454, val_loss=0.472, val_acc=0.984, train_loss_epoch=0.442]\n",
      "Epoch 106:  85%|████████▍ | 130/153 [00:22<00:03,  5.83it/s, loss=0.446, v_num=4, train_loss_step=0.447, val_loss=0.472, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 106:  92%|█████████▏| 140/153 [00:26<00:02,  5.36it/s, loss=0.445, v_num=4, train_loss_step=0.441, val_loss=0.461, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Epoch 107:  85%|████████▍ | 130/153 [00:22<00:03,  5.84it/s, loss=0.440, v_num=4, train_loss_step=0.435, val_loss=0.461, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 107:  92%|█████████▏| 140/153 [00:26<00:02,  5.35it/s, loss=0.440, v_num=4, train_loss_step=0.437, val_loss=0.457, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Epoch 108:  85%|████████▍ | 130/153 [00:22<00:03,  5.89it/s, loss=0.441, v_num=4, train_loss_step=0.475, val_loss=0.457, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 108:  92%|█████████▏| 140/153 [00:25<00:02,  5.40it/s, loss=0.441, v_num=4, train_loss_step=0.455, val_loss=0.45, val_acc=0.984, train_loss_epoch=0.441] \n",
      "Epoch 109:  85%|████████▍ | 130/153 [00:22<00:03,  5.87it/s, loss=0.438, v_num=4, train_loss_step=0.427, val_loss=0.45, val_acc=0.984, train_loss_epoch=0.442]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 109:  92%|█████████▏| 140/153 [00:25<00:02,  5.39it/s, loss=0.438, v_num=4, train_loss_step=0.432, val_loss=0.456, val_acc=0.984, train_loss_epoch=0.442]\n",
      "Epoch 110:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.445, v_num=4, train_loss_step=0.427, val_loss=0.456, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 110:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.443, v_num=4, train_loss_step=0.436, val_loss=0.459, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Epoch 111:  85%|████████▍ | 130/153 [00:21<00:03,  5.92it/s, loss=0.450, v_num=4, train_loss_step=0.462, val_loss=0.459, val_acc=0.984, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 111:  92%|█████████▏| 140/153 [00:25<00:02,  5.40it/s, loss=0.451, v_num=4, train_loss_step=0.53, val_loss=0.457, val_acc=1, train_loss_epoch=0.443]     \n",
      "Epoch 112:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.437, v_num=4, train_loss_step=0.435, val_loss=0.457, val_acc=1, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 112:  92%|█████████▏| 140/153 [00:25<00:02,  5.48it/s, loss=0.438, v_num=4, train_loss_step=0.441, val_loss=0.454, val_acc=0.984, train_loss_epoch=0.443]\n",
      "Epoch 113:  85%|████████▍ | 130/153 [00:21<00:03,  5.91it/s, loss=0.441, v_num=4, train_loss_step=0.439, val_loss=0.454, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 113:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.440, v_num=4, train_loss_step=0.437, val_loss=0.468, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Epoch 114:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.438, v_num=4, train_loss_step=0.431, val_loss=0.468, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 114:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.439, v_num=4, train_loss_step=0.434, val_loss=0.471, val_acc=0.967, train_loss_epoch=0.441]\n",
      "Epoch 115:  85%|████████▍ | 130/153 [00:21<00:03,  5.96it/s, loss=0.441, v_num=4, train_loss_step=0.474, val_loss=0.471, val_acc=0.967, train_loss_epoch=0.441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115:  92%|█████████▏| 140/153 [00:25<00:02,  5.47it/s, loss=0.439, v_num=4, train_loss_step=0.432, val_loss=0.467, val_acc=0.967, train_loss_epoch=0.441]\n",
      "Epoch 116:  85%|████████▍ | 130/153 [00:22<00:03,  5.89it/s, loss=0.437, v_num=4, train_loss_step=0.434, val_loss=0.467, val_acc=0.967, train_loss_epoch=0.441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 116:  92%|█████████▏| 140/153 [00:25<00:02,  5.43it/s, loss=0.444, v_num=4, train_loss_step=0.494, val_loss=0.455, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Epoch 117:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.440, v_num=4, train_loss_step=0.435, val_loss=0.455, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 117:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.442, v_num=4, train_loss_step=0.438, val_loss=0.46, val_acc=0.984, train_loss_epoch=0.441] \n",
      "Epoch 118:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.438, v_num=4, train_loss_step=0.435, val_loss=0.46, val_acc=0.984, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 118:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.440, v_num=4, train_loss_step=0.473, val_loss=0.459, val_acc=0.984, train_loss_epoch=0.443]\n",
      "Epoch 119:  85%|████████▍ | 130/153 [00:21<00:03,  5.93it/s, loss=0.438, v_num=4, train_loss_step=0.435, val_loss=0.459, val_acc=0.984, train_loss_epoch=0.442]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 119:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.439, v_num=4, train_loss_step=0.43, val_loss=0.459, val_acc=0.984, train_loss_epoch=0.442] \n",
      "Epoch 120:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.439, v_num=4, train_loss_step=0.437, val_loss=0.459, val_acc=0.984, train_loss_epoch=0.442]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 120:  92%|█████████▏| 140/153 [00:25<00:02,  5.46it/s, loss=0.445, v_num=4, train_loss_step=0.601, val_loss=0.45, val_acc=0.984, train_loss_epoch=0.442] \n",
      "Epoch 121:  85%|████████▍ | 130/153 [00:22<00:03,  5.83it/s, loss=0.443, v_num=4, train_loss_step=0.442, val_loss=0.45, val_acc=0.984, train_loss_epoch=0.442]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 121:  92%|█████████▏| 140/153 [00:26<00:02,  5.35it/s, loss=0.442, v_num=4, train_loss_step=0.438, val_loss=0.449, val_acc=0.984, train_loss_epoch=0.442]\n",
      "Epoch 122:  85%|████████▍ | 130/153 [00:21<00:03,  5.95it/s, loss=0.444, v_num=4, train_loss_step=0.553, val_loss=0.449, val_acc=0.984, train_loss_epoch=0.441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 122:  92%|█████████▏| 140/153 [00:25<00:02,  5.44it/s, loss=0.445, v_num=4, train_loss_step=0.441, val_loss=0.454, val_acc=1, train_loss_epoch=0.441]    \n",
      "Epoch 123:  85%|████████▍ | 130/153 [00:21<00:03,  5.94it/s, loss=0.443, v_num=4, train_loss_step=0.439, val_loss=0.454, val_acc=1, train_loss_epoch=0.442]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 123:  92%|█████████▏| 140/153 [00:25<00:02,  5.45it/s, loss=0.442, v_num=4, train_loss_step=0.447, val_loss=0.448, val_acc=1, train_loss_epoch=0.442]\n",
      "Epoch 124:  85%|████████▍ | 130/153 [00:22<00:03,  5.90it/s, loss=0.447, v_num=4, train_loss_step=0.454, val_loss=0.448, val_acc=1, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 124:  92%|█████████▏| 140/153 [00:25<00:02,  5.42it/s, loss=0.444, v_num=4, train_loss_step=0.435, val_loss=0.488, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 124:  92%|█████████▏| 140/153 [00:25<00:02,  5.40it/s, loss=0.444, v_num=4, train_loss_step=0.435, val_loss=0.488, val_acc=0.951, train_loss_epoch=0.445]\n"
     ]
    }
   ],
   "source": [
    "configs['DATASET']['AUGMENTATION'] = 'uniform'\n",
    "configs['LOSS'] = 'label_smoothing_cross_entropy'\n",
    "configs['CHECKPOINT']['SAVE_NAME'] = 'crnn-bmw-uniform-ls0.1'\n",
    "torch.cuda.empty_cache()\n",
    "do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: gaussian\n",
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name        | Type        | Params\n",
      "---------------------------------------------\n",
      "0  | conv1       | Conv2d      | 640   \n",
      "1  | bn1         | BatchNorm2d | 128   \n",
      "2  | dropout1    | Dropout     | 0     \n",
      "3  | conv2       | Conv2d      | 73 K  \n",
      "4  | bn2         | BatchNorm2d | 256   \n",
      "5  | dropout2    | Dropout     | 0     \n",
      "6  | conv3       | Conv2d      | 147 K \n",
      "7  | bn3         | BatchNorm2d | 256   \n",
      "8  | dropout3    | Dropout     | 0     \n",
      "9  | conv4       | Conv2d      | 147 K \n",
      "10 | bn4         | BatchNorm2d | 256   \n",
      "11 | dropout4    | Dropout     | 0     \n",
      "12 | rnn         | GRU         | 21 K  \n",
      "13 | dropout_rnn | Dropout     | 0     \n",
      "14 | linear      | Linear      | 198   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=1.029, v_num=5, train_loss_step=1.16] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=1.187, v_num=5, train_loss_step=1.23, val_loss=1.01, val_acc=0.639]\n",
      "Epoch 1:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.899, v_num=5, train_loss_step=0.593, val_loss=1.01, val_acc=0.639, train_loss_epoch=1.18]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.913, v_num=5, train_loss_step=0.455, val_loss=0.935, val_acc=0.672, train_loss_epoch=1.18]\n",
      "Epoch 2:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.899, v_num=5, train_loss_step=0.872, val_loss=0.935, val_acc=0.672, train_loss_epoch=1.01]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=1.017, v_num=5, train_loss_step=3.44, val_loss=0.78, val_acc=0.754, train_loss_epoch=1.01]  \n",
      "Epoch 3:  85%|████████▍ | 130/153 [00:22<00:03,  5.84it/s, loss=0.992, v_num=5, train_loss_step=0.737, val_loss=0.78, val_acc=0.754, train_loss_epoch=0.956]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 140/153 [00:26<00:02,  5.37it/s, loss=1.005, v_num=5, train_loss_step=2.36, val_loss=0.971, val_acc=0.639, train_loss_epoch=0.956]\n",
      "Epoch 4:  85%|████████▍ | 130/153 [00:22<00:03,  5.80it/s, loss=0.634, v_num=5, train_loss_step=1.17, val_loss=0.971, val_acc=0.639, train_loss_epoch=0.839] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 140/153 [00:26<00:02,  5.38it/s, loss=0.744, v_num=5, train_loss_step=3.03, val_loss=0.991, val_acc=0.623, train_loss_epoch=0.839]\n",
      "Epoch 5:  85%|████████▍ | 130/153 [00:22<00:03,  5.81it/s, loss=0.834, v_num=5, train_loss_step=0.548, val_loss=0.991, val_acc=0.623, train_loss_epoch=0.712] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 140/153 [00:26<00:02,  5.37it/s, loss=0.881, v_num=5, train_loss_step=1.88, val_loss=0.685, val_acc=0.705, train_loss_epoch=0.712] \n",
      "Epoch 6:  85%|████████▍ | 130/153 [00:22<00:03,  5.77it/s, loss=0.533, v_num=5, train_loss_step=0.366, val_loss=0.685, val_acc=0.705, train_loss_epoch=0.631]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 140/153 [00:26<00:02,  5.34it/s, loss=0.508, v_num=5, train_loss_step=0.625, val_loss=1.02, val_acc=0.574, train_loss_epoch=0.631] \n",
      "Epoch 7:  85%|████████▍ | 130/153 [00:22<00:03,  5.82it/s, loss=0.543, v_num=5, train_loss_step=0.554, val_loss=1.02, val_acc=0.574, train_loss_epoch=0.55] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 140/153 [00:26<00:02,  5.33it/s, loss=0.670, v_num=5, train_loss_step=0.94, val_loss=0.531, val_acc=0.803, train_loss_epoch=0.55]\n",
      "Epoch 8:  85%|████████▍ | 130/153 [00:22<00:03,  5.79it/s, loss=0.523, v_num=5, train_loss_step=0.0552, val_loss=0.531, val_acc=0.803, train_loss_epoch=0.558]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 140/153 [00:26<00:02,  5.36it/s, loss=0.533, v_num=5, train_loss_step=0.597, val_loss=0.819, val_acc=0.738, train_loss_epoch=0.558] \n",
      "Epoch 9:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.447, v_num=5, train_loss_step=0.232, val_loss=0.819, val_acc=0.738, train_loss_epoch=0.473] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.468, v_num=5, train_loss_step=1.33, val_loss=0.595, val_acc=0.787, train_loss_epoch=0.473] \n",
      "Epoch 10:  85%|████████▍ | 130/153 [00:22<00:03,  5.81it/s, loss=0.632, v_num=5, train_loss_step=0.559, val_loss=0.595, val_acc=0.787, train_loss_epoch=0.497] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 140/153 [00:26<00:02,  5.37it/s, loss=0.589, v_num=5, train_loss_step=0.408, val_loss=0.651, val_acc=0.705, train_loss_epoch=0.497]\n",
      "Epoch 11:  85%|████████▍ | 130/153 [00:22<00:03,  5.80it/s, loss=0.420, v_num=5, train_loss_step=0.892, val_loss=0.651, val_acc=0.705, train_loss_epoch=0.423] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 140/153 [00:26<00:02,  5.36it/s, loss=0.447, v_num=5, train_loss_step=0.281, val_loss=0.417, val_acc=0.82, train_loss_epoch=0.423] \n",
      "Epoch 12:  85%|████████▍ | 130/153 [00:22<00:03,  5.77it/s, loss=0.335, v_num=5, train_loss_step=0.376, val_loss=0.417, val_acc=0.82, train_loss_epoch=0.44] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 140/153 [00:26<00:02,  5.36it/s, loss=0.318, v_num=5, train_loss_step=1.8, val_loss=0.811, val_acc=0.721, train_loss_epoch=0.44] \n",
      "Epoch 13:  85%|████████▍ | 130/153 [00:22<00:03,  5.78it/s, loss=0.523, v_num=5, train_loss_step=0.113, val_loss=0.811, val_acc=0.721, train_loss_epoch=0.375]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  92%|█████████▏| 140/153 [00:26<00:02,  5.35it/s, loss=0.404, v_num=5, train_loss_step=0.225, val_loss=0.523, val_acc=0.82, train_loss_epoch=0.375] \n",
      "Epoch 14:  85%|████████▍ | 130/153 [00:22<00:03,  5.81it/s, loss=0.290, v_num=5, train_loss_step=0.0435, val_loss=0.523, val_acc=0.82, train_loss_epoch=0.386]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  92%|█████████▏| 140/153 [00:26<00:02,  5.37it/s, loss=0.246, v_num=5, train_loss_step=0.989, val_loss=1.14, val_acc=0.672, train_loss_epoch=0.386] \n",
      "Epoch 15:  85%|████████▍ | 130/153 [00:22<00:03,  5.79it/s, loss=0.403, v_num=5, train_loss_step=0.8, val_loss=1.14, val_acc=0.672, train_loss_epoch=0.381]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  92%|█████████▏| 140/153 [00:26<00:02,  5.35it/s, loss=0.459, v_num=5, train_loss_step=0.0496, val_loss=0.733, val_acc=0.672, train_loss_epoch=0.381]\n",
      "Epoch 16:  85%|████████▍ | 130/153 [00:22<00:03,  5.80it/s, loss=0.230, v_num=5, train_loss_step=0.0278, val_loss=0.733, val_acc=0.672, train_loss_epoch=0.505]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  92%|█████████▏| 140/153 [00:26<00:02,  5.36it/s, loss=0.352, v_num=5, train_loss_step=0.00209, val_loss=1.21, val_acc=0.721, train_loss_epoch=0.505]\n",
      "Epoch 17:  85%|████████▍ | 130/153 [00:22<00:03,  5.79it/s, loss=0.407, v_num=5, train_loss_step=0.661, val_loss=1.21, val_acc=0.721, train_loss_epoch=0.326]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  92%|█████████▏| 140/153 [00:26<00:02,  5.35it/s, loss=0.383, v_num=5, train_loss_step=0.625, val_loss=0.576, val_acc=0.82, train_loss_epoch=0.326]\n",
      "Epoch 18:  85%|████████▍ | 130/153 [00:22<00:03,  5.82it/s, loss=0.285, v_num=5, train_loss_step=0.0723, val_loss=0.576, val_acc=0.82, train_loss_epoch=0.375]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  92%|█████████▏| 140/153 [00:26<00:02,  5.35it/s, loss=0.274, v_num=5, train_loss_step=0.00244, val_loss=0.484, val_acc=0.852, train_loss_epoch=0.375]\n",
      "Epoch 19:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.276, v_num=5, train_loss_step=0.182, val_loss=0.484, val_acc=0.852, train_loss_epoch=0.325]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.278, v_num=5, train_loss_step=0.299, val_loss=0.697, val_acc=0.738, train_loss_epoch=0.325]\n",
      "Epoch 20:  85%|████████▍ | 130/153 [00:22<00:03,  5.78it/s, loss=0.558, v_num=5, train_loss_step=0.179, val_loss=0.697, val_acc=0.738, train_loss_epoch=0.262] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  92%|█████████▏| 140/153 [00:26<00:02,  5.36it/s, loss=0.430, v_num=5, train_loss_step=0.518, val_loss=0.355, val_acc=0.852, train_loss_epoch=0.262]\n",
      "Epoch 21:  85%|████████▍ | 130/153 [00:22<00:04,  5.74it/s, loss=0.211, v_num=5, train_loss_step=0.0868, val_loss=0.355, val_acc=0.852, train_loss_epoch=0.375]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  92%|█████████▏| 140/153 [00:26<00:02,  5.33it/s, loss=0.252, v_num=5, train_loss_step=0.03, val_loss=0.398, val_acc=0.82, train_loss_epoch=0.375]   \n",
      "Epoch 22:  85%|████████▍ | 130/153 [00:22<00:03,  5.77it/s, loss=0.397, v_num=5, train_loss_step=0.687, val_loss=0.398, val_acc=0.82, train_loss_epoch=0.335]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  92%|█████████▏| 140/153 [00:26<00:02,  5.35it/s, loss=0.326, v_num=5, train_loss_step=0.0956, val_loss=0.902, val_acc=0.623, train_loss_epoch=0.335]\n",
      "Epoch 23:  85%|████████▍ | 130/153 [00:22<00:03,  5.77it/s, loss=0.282, v_num=5, train_loss_step=0.684, val_loss=0.902, val_acc=0.623, train_loss_epoch=0.259]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  92%|█████████▏| 140/153 [00:26<00:02,  5.33it/s, loss=0.328, v_num=5, train_loss_step=0.715, val_loss=0.526, val_acc=0.82, train_loss_epoch=0.259] \n",
      "Epoch 24:  85%|████████▍ | 130/153 [00:22<00:03,  5.81it/s, loss=0.269, v_num=5, train_loss_step=0.143, val_loss=0.526, val_acc=0.82, train_loss_epoch=0.258]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 140/153 [00:26<00:02,  5.37it/s, loss=0.273, v_num=5, train_loss_step=0.00214, val_loss=0.478, val_acc=0.803, train_loss_epoch=0.258]\n",
      "Epoch 25:  85%|████████▍ | 130/153 [00:22<00:03,  5.82it/s, loss=0.207, v_num=5, train_loss_step=0.104, val_loss=0.478, val_acc=0.803, train_loss_epoch=0.279]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25:  92%|█████████▏| 140/153 [00:26<00:02,  5.38it/s, loss=0.217, v_num=5, train_loss_step=0.284, val_loss=0.431, val_acc=0.852, train_loss_epoch=0.279]\n",
      "Epoch 26:  85%|████████▍ | 130/153 [00:22<00:03,  5.77it/s, loss=0.125, v_num=5, train_loss_step=0.122, val_loss=0.431, val_acc=0.852, train_loss_epoch=0.197] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26:  92%|█████████▏| 140/153 [00:26<00:02,  5.34it/s, loss=0.208, v_num=5, train_loss_step=0.851, val_loss=0.453, val_acc=0.869, train_loss_epoch=0.197]\n",
      "Epoch 27:  85%|████████▍ | 130/153 [00:22<00:03,  5.75it/s, loss=0.295, v_num=5, train_loss_step=0.0374, val_loss=0.453, val_acc=0.869, train_loss_epoch=0.229]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27:  92%|█████████▏| 140/153 [00:26<00:02,  5.33it/s, loss=0.257, v_num=5, train_loss_step=0.00113, val_loss=0.548, val_acc=0.82, train_loss_epoch=0.229]\n",
      "Epoch 28:  85%|████████▍ | 130/153 [00:22<00:03,  5.80it/s, loss=0.120, v_num=5, train_loss_step=0.0417, val_loss=0.548, val_acc=0.82, train_loss_epoch=0.169] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.166, v_num=5, train_loss_step=0.609, val_loss=1.11, val_acc=0.656, train_loss_epoch=0.169] \n",
      "Epoch 29:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.098, v_num=5, train_loss_step=0.0295, val_loss=1.11, val_acc=0.656, train_loss_epoch=0.15] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.175, v_num=5, train_loss_step=0.0724, val_loss=0.384, val_acc=0.869, train_loss_epoch=0.15]\n",
      "Epoch 30:  85%|████████▍ | 130/153 [00:22<00:03,  5.82it/s, loss=0.156, v_num=5, train_loss_step=0.0672, val_loss=0.384, val_acc=0.869, train_loss_epoch=0.141]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30:  92%|█████████▏| 140/153 [00:26<00:02,  5.38it/s, loss=0.141, v_num=5, train_loss_step=0.0077, val_loss=0.3, val_acc=0.902, train_loss_epoch=0.141]  \n",
      "Epoch 31:  85%|████████▍ | 130/153 [00:22<00:03,  5.80it/s, loss=0.099, v_num=5, train_loss_step=0.0185, val_loss=0.3, val_acc=0.902, train_loss_epoch=0.163] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31:  92%|█████████▏| 140/153 [00:26<00:02,  5.36it/s, loss=0.208, v_num=5, train_loss_step=0.749, val_loss=0.855, val_acc=0.77, train_loss_epoch=0.163]\n",
      "Epoch 32:  85%|████████▍ | 130/153 [00:22<00:03,  5.81it/s, loss=0.153, v_num=5, train_loss_step=0.0796, val_loss=0.855, val_acc=0.77, train_loss_epoch=0.179]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32:  92%|█████████▏| 140/153 [00:26<00:02,  5.36it/s, loss=0.104, v_num=5, train_loss_step=0.105, val_loss=0.535, val_acc=0.82, train_loss_epoch=0.179] \n",
      "Epoch 33:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.104, v_num=5, train_loss_step=0.102, val_loss=0.535, val_acc=0.82, train_loss_epoch=0.197] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.098, v_num=5, train_loss_step=0.00368, val_loss=0.193, val_acc=0.967, train_loss_epoch=0.197]\n",
      "Epoch 34:  85%|████████▍ | 130/153 [00:22<00:04,  5.74it/s, loss=0.175, v_num=5, train_loss_step=0.231, val_loss=0.193, val_acc=0.967, train_loss_epoch=0.156]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.093, v_num=5, train_loss_step=0.00584, val_loss=0.533, val_acc=0.836, train_loss_epoch=0.156]\n",
      "Epoch 35:  85%|████████▍ | 130/153 [00:22<00:03,  5.76it/s, loss=0.109, v_num=5, train_loss_step=0.0345, val_loss=0.533, val_acc=0.836, train_loss_epoch=0.134] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.124, v_num=5, train_loss_step=0.00534, val_loss=0.785, val_acc=0.754, train_loss_epoch=0.134]\n",
      "Epoch 36:  85%|████████▍ | 130/153 [00:22<00:04,  5.75it/s, loss=0.101, v_num=5, train_loss_step=0.0844, val_loss=0.785, val_acc=0.754, train_loss_epoch=0.141] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.148, v_num=5, train_loss_step=1.14, val_loss=0.43, val_acc=0.918, train_loss_epoch=0.141]   \n",
      "Epoch 37:  85%|████████▍ | 130/153 [00:22<00:03,  5.78it/s, loss=0.111, v_num=5, train_loss_step=0.377, val_loss=0.43, val_acc=0.918, train_loss_epoch=0.135] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37:  92%|█████████▏| 140/153 [00:26<00:02,  5.33it/s, loss=0.154, v_num=5, train_loss_step=0.0156, val_loss=0.535, val_acc=0.82, train_loss_epoch=0.135]\n",
      "Epoch 38:  85%|████████▍ | 130/153 [00:22<00:03,  5.76it/s, loss=0.168, v_num=5, train_loss_step=0.237, val_loss=0.535, val_acc=0.82, train_loss_epoch=0.139] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38:  92%|█████████▏| 140/153 [00:26<00:02,  5.33it/s, loss=0.045, v_num=5, train_loss_step=0.0171, val_loss=0.483, val_acc=0.869, train_loss_epoch=0.139]\n",
      "Epoch 39:  85%|████████▍ | 130/153 [00:22<00:04,  5.75it/s, loss=0.112, v_num=5, train_loss_step=0.0093, val_loss=0.483, val_acc=0.869, train_loss_epoch=0.121]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39:  92%|█████████▏| 140/153 [00:26<00:02,  5.31it/s, loss=0.149, v_num=5, train_loss_step=0.0309, val_loss=0.686, val_acc=0.82, train_loss_epoch=0.121] \n",
      "Epoch 40:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.203, v_num=5, train_loss_step=1.46, val_loss=0.686, val_acc=0.82, train_loss_epoch=0.119]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 40:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.242, v_num=5, train_loss_step=0.000982, val_loss=0.893, val_acc=0.721, train_loss_epoch=0.119]\n",
      "Epoch 41:  85%|████████▍ | 130/153 [00:22<00:03,  5.75it/s, loss=0.083, v_num=5, train_loss_step=0.0297, val_loss=0.893, val_acc=0.721, train_loss_epoch=0.115]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 41:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.102, v_num=5, train_loss_step=0.00373, val_loss=0.181, val_acc=0.918, train_loss_epoch=0.115]\n",
      "Epoch 42:  85%|████████▍ | 130/153 [00:23<00:04,  5.62it/s, loss=0.063, v_num=5, train_loss_step=0.0177, val_loss=0.181, val_acc=0.918, train_loss_epoch=0.125] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 42:  92%|█████████▏| 140/153 [00:26<00:02,  5.20it/s, loss=0.092, v_num=5, train_loss_step=0.00436, val_loss=0.332, val_acc=0.902, train_loss_epoch=0.125]\n",
      "Epoch 43:  85%|████████▍ | 130/153 [00:22<00:03,  5.79it/s, loss=0.192, v_num=5, train_loss_step=0.0209, val_loss=0.332, val_acc=0.902, train_loss_epoch=0.103] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 43:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.185, v_num=5, train_loss_step=0.0181, val_loss=0.448, val_acc=0.852, train_loss_epoch=0.103]\n",
      "Epoch 44:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.181, v_num=5, train_loss_step=0.996, val_loss=0.448, val_acc=0.852, train_loss_epoch=0.113]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 44:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.160, v_num=5, train_loss_step=0.00343, val_loss=0.223, val_acc=0.967, train_loss_epoch=0.113]\n",
      "Epoch 45:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.096, v_num=5, train_loss_step=0.176, val_loss=0.223, val_acc=0.967, train_loss_epoch=0.135]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 45:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.109, v_num=5, train_loss_step=0.306, val_loss=0.419, val_acc=0.852, train_loss_epoch=0.135]\n",
      "Epoch 46:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.073, v_num=5, train_loss_step=0.00238, val_loss=0.419, val_acc=0.852, train_loss_epoch=0.127]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.080, v_num=5, train_loss_step=0.000928, val_loss=0.238, val_acc=0.902, train_loss_epoch=0.127]\n",
      "Epoch 47:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.159, v_num=5, train_loss_step=1.06, val_loss=0.238, val_acc=0.902, train_loss_epoch=0.0627]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 47:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.139, v_num=5, train_loss_step=0.0209, val_loss=0.322, val_acc=0.885, train_loss_epoch=0.0627]\n",
      "Epoch 48:  85%|████████▍ | 130/153 [00:22<00:03,  5.75it/s, loss=0.072, v_num=5, train_loss_step=0.0111, val_loss=0.322, val_acc=0.885, train_loss_epoch=0.0928] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 48:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.115, v_num=5, train_loss_step=0.0108, val_loss=0.458, val_acc=0.852, train_loss_epoch=0.0928]\n",
      "Epoch 49:  85%|████████▍ | 130/153 [00:22<00:03,  5.77it/s, loss=0.053, v_num=5, train_loss_step=0.00323, val_loss=0.458, val_acc=0.852, train_loss_epoch=0.0862]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 49:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.023, v_num=5, train_loss_step=0.0401, val_loss=0.818, val_acc=0.82, train_loss_epoch=0.0862]  \n",
      "Epoch 50:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.036, v_num=5, train_loss_step=0.00894, val_loss=0.818, val_acc=0.82, train_loss_epoch=0.0848]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 50:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.061, v_num=5, train_loss_step=0.0197, val_loss=0.831, val_acc=0.82, train_loss_epoch=0.0848] \n",
      "Epoch 51:  85%|████████▍ | 130/153 [00:22<00:03,  5.75it/s, loss=0.111, v_num=5, train_loss_step=1.53, val_loss=0.831, val_acc=0.82, train_loss_epoch=0.0503]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 51:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.120, v_num=5, train_loss_step=0.198, val_loss=0.538, val_acc=0.902, train_loss_epoch=0.0503]\n",
      "Epoch 52:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.040, v_num=5, train_loss_step=0.03, val_loss=0.538, val_acc=0.902, train_loss_epoch=0.0511]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 52:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.073, v_num=5, train_loss_step=0.848, val_loss=0.674, val_acc=0.852, train_loss_epoch=0.0511]\n",
      "Epoch 53:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.040, v_num=5, train_loss_step=0.0552, val_loss=0.674, val_acc=0.852, train_loss_epoch=0.0568] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 53:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.036, v_num=5, train_loss_step=0.0163, val_loss=0.509, val_acc=0.885, train_loss_epoch=0.0568]\n",
      "Epoch 54:  85%|████████▍ | 130/153 [00:22<00:03,  5.75it/s, loss=0.056, v_num=5, train_loss_step=0.141, val_loss=0.509, val_acc=0.885, train_loss_epoch=0.036]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 54:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.059, v_num=5, train_loss_step=0.0933, val_loss=0.657, val_acc=0.885, train_loss_epoch=0.036]\n",
      "Epoch 55:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.057, v_num=5, train_loss_step=0.0212, val_loss=0.657, val_acc=0.885, train_loss_epoch=0.0382] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 55:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.019, v_num=5, train_loss_step=0.00482, val_loss=0.827, val_acc=0.803, train_loss_epoch=0.0382]\n",
      "Epoch 56:  85%|████████▍ | 130/153 [00:22<00:04,  5.74it/s, loss=0.039, v_num=5, train_loss_step=0.00257, val_loss=0.827, val_acc=0.803, train_loss_epoch=0.037] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 56:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.041, v_num=5, train_loss_step=0.133, val_loss=1.3, val_acc=0.705, train_loss_epoch=0.037]    \n",
      "Epoch 57:  85%|████████▍ | 130/153 [00:22<00:03,  5.76it/s, loss=0.043, v_num=5, train_loss_step=0.477, val_loss=1.3, val_acc=0.705, train_loss_epoch=0.0435]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 57:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.053, v_num=5, train_loss_step=0.00798, val_loss=0.798, val_acc=0.836, train_loss_epoch=0.0435]\n",
      "Epoch 58:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.025, v_num=5, train_loss_step=0.00253, val_loss=0.798, val_acc=0.836, train_loss_epoch=0.0344]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 58:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.036, v_num=5, train_loss_step=0.00734, val_loss=0.868, val_acc=0.787, train_loss_epoch=0.0344]\n",
      "Epoch 59:  85%|████████▍ | 130/153 [00:22<00:03,  5.76it/s, loss=0.041, v_num=5, train_loss_step=0.039, val_loss=0.868, val_acc=0.787, train_loss_epoch=0.0291]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 59:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.051, v_num=5, train_loss_step=0.0639, val_loss=1.85, val_acc=0.689, train_loss_epoch=0.0291]\n",
      "Epoch 60:  85%|████████▍ | 130/153 [00:22<00:04,  5.74it/s, loss=0.023, v_num=5, train_loss_step=0.00298, val_loss=1.85, val_acc=0.689, train_loss_epoch=0.0376]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 60:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.028, v_num=5, train_loss_step=0.114, val_loss=0.792, val_acc=0.82, train_loss_epoch=0.0376]  \n",
      "Epoch 61:  85%|████████▍ | 130/153 [00:22<00:03,  5.75it/s, loss=0.182, v_num=5, train_loss_step=0.0138, val_loss=0.792, val_acc=0.82, train_loss_epoch=0.0419] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 61:  92%|█████████▏| 140/153 [00:26<00:02,  5.31it/s, loss=0.077, v_num=5, train_loss_step=0.0241, val_loss=0.0966, val_acc=0.967, train_loss_epoch=0.0419]\n",
      "Epoch 62:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.112, v_num=5, train_loss_step=0.0969, val_loss=0.0966, val_acc=0.967, train_loss_epoch=0.0599] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 62:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.102, v_num=5, train_loss_step=0.00174, val_loss=0.409, val_acc=0.902, train_loss_epoch=0.0599]\n",
      "Epoch 63:  85%|████████▍ | 130/153 [00:22<00:03,  5.77it/s, loss=0.024, v_num=5, train_loss_step=0.01, val_loss=0.409, val_acc=0.902, train_loss_epoch=0.0516]    \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 63:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.012, v_num=5, train_loss_step=0.0115, val_loss=0.693, val_acc=0.836, train_loss_epoch=0.0516]\n",
      "Epoch 64:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.031, v_num=5, train_loss_step=0.0112, val_loss=0.693, val_acc=0.836, train_loss_epoch=0.0265] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 64:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.032, v_num=5, train_loss_step=0.00147, val_loss=0.681, val_acc=0.869, train_loss_epoch=0.0265]\n",
      "Epoch 65:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.043, v_num=5, train_loss_step=0.00403, val_loss=0.681, val_acc=0.869, train_loss_epoch=0.021] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 65:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.043, v_num=5, train_loss_step=0.015, val_loss=1.09, val_acc=0.689, train_loss_epoch=0.021]   \n",
      "Epoch 66:  85%|████████▍ | 130/153 [00:22<00:03,  5.77it/s, loss=0.085, v_num=5, train_loss_step=0.00524, val_loss=1.09, val_acc=0.689, train_loss_epoch=0.0289]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 66:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.014, v_num=5, train_loss_step=0.00142, val_loss=0.467, val_acc=0.885, train_loss_epoch=0.0289]\n",
      "Epoch 67:  85%|████████▍ | 130/153 [00:22<00:03,  5.78it/s, loss=0.021, v_num=5, train_loss_step=0.0295, val_loss=0.467, val_acc=0.885, train_loss_epoch=0.0672] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 67:  92%|█████████▏| 140/153 [00:26<00:02,  5.33it/s, loss=0.046, v_num=5, train_loss_step=0.00598, val_loss=0.578, val_acc=0.869, train_loss_epoch=0.0672]\n",
      "Epoch 68:  85%|████████▍ | 130/153 [00:22<00:04,  5.75it/s, loss=0.050, v_num=5, train_loss_step=0.0148, val_loss=0.578, val_acc=0.869, train_loss_epoch=0.0221]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 68:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.110, v_num=5, train_loss_step=0.000846, val_loss=1, val_acc=0.721, train_loss_epoch=0.0221]  \n",
      "Epoch 69:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.027, v_num=5, train_loss_step=0.0155, val_loss=1, val_acc=0.721, train_loss_epoch=0.0383]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 69:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.027, v_num=5, train_loss_step=0.00162, val_loss=1.1, val_acc=0.705, train_loss_epoch=0.0383]\n",
      "Epoch 70:  85%|████████▍ | 130/153 [00:22<00:03,  5.81it/s, loss=0.022, v_num=5, train_loss_step=0.00146, val_loss=1.1, val_acc=0.705, train_loss_epoch=0.0452]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 70:  92%|█████████▏| 140/153 [00:26<00:02,  5.37it/s, loss=0.021, v_num=5, train_loss_step=0.000652, val_loss=1.21, val_acc=0.656, train_loss_epoch=0.0452]\n",
      "Epoch 71:  85%|████████▍ | 130/153 [00:23<00:04,  5.56it/s, loss=0.016, v_num=5, train_loss_step=0.00431, val_loss=1.21, val_acc=0.656, train_loss_epoch=0.0251] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 71:  92%|█████████▏| 140/153 [00:27<00:02,  5.15it/s, loss=0.024, v_num=5, train_loss_step=0.141, val_loss=0.776, val_acc=0.803, train_loss_epoch=0.0251] \n",
      "Epoch 72:  85%|████████▍ | 130/153 [00:22<00:04,  5.74it/s, loss=0.104, v_num=5, train_loss_step=0.0107, val_loss=0.776, val_acc=0.803, train_loss_epoch=0.0269]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 72:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.159, v_num=5, train_loss_step=1.66, val_loss=0.489, val_acc=0.885, train_loss_epoch=0.0269]  \n",
      "Epoch 73:  85%|████████▍ | 130/153 [00:22<00:03,  5.79it/s, loss=0.075, v_num=5, train_loss_step=0.0457, val_loss=0.489, val_acc=0.885, train_loss_epoch=0.124] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 73:  92%|█████████▏| 140/153 [00:26<00:02,  5.35it/s, loss=0.166, v_num=5, train_loss_step=1.88, val_loss=1.28, val_acc=0.656, train_loss_epoch=0.124]   \n",
      "Epoch 74:  85%|████████▍ | 130/153 [00:22<00:03,  5.76it/s, loss=0.014, v_num=5, train_loss_step=0.00881, val_loss=1.28, val_acc=0.656, train_loss_epoch=0.0936]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 74:  92%|█████████▏| 140/153 [00:26<00:02,  5.31it/s, loss=0.017, v_num=5, train_loss_step=0.0487, val_loss=0.624, val_acc=0.869, train_loss_epoch=0.0936]\n",
      "Epoch 75:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.015, v_num=5, train_loss_step=0.00122, val_loss=0.624, val_acc=0.869, train_loss_epoch=0.0351]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 75:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.011, v_num=5, train_loss_step=0.0022, val_loss=0.621, val_acc=0.869, train_loss_epoch=0.0351] \n",
      "Epoch 76:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.053, v_num=5, train_loss_step=0.00635, val_loss=0.621, val_acc=0.869, train_loss_epoch=0.0191] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 76:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.078, v_num=5, train_loss_step=0.956, val_loss=1.08, val_acc=0.705, train_loss_epoch=0.0191]   \n",
      "Epoch 77:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.025, v_num=5, train_loss_step=0.013, val_loss=1.08, val_acc=0.705, train_loss_epoch=0.0295]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 77:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.023, v_num=5, train_loss_step=0.0149, val_loss=0.648, val_acc=0.852, train_loss_epoch=0.0295]\n",
      "Epoch 78:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.012, v_num=5, train_loss_step=0.0441, val_loss=0.648, val_acc=0.852, train_loss_epoch=0.0239] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 78:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.012, v_num=5, train_loss_step=0.00661, val_loss=0.652, val_acc=0.836, train_loss_epoch=0.0239]\n",
      "Epoch 79:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.015, v_num=5, train_loss_step=0.00163, val_loss=0.652, val_acc=0.836, train_loss_epoch=0.0172] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 79:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.017, v_num=5, train_loss_step=0.000165, val_loss=0.773, val_acc=0.836, train_loss_epoch=0.0172]\n",
      "Epoch 80:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.016, v_num=5, train_loss_step=0.0242, val_loss=0.773, val_acc=0.836, train_loss_epoch=0.0147]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 80:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.014, v_num=5, train_loss_step=0.000637, val_loss=0.763, val_acc=0.836, train_loss_epoch=0.0147]\n",
      "Epoch 81:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.016, v_num=5, train_loss_step=0.00375, val_loss=0.763, val_acc=0.836, train_loss_epoch=0.0122] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 81:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.018, v_num=5, train_loss_step=0.00108, val_loss=0.876, val_acc=0.82, train_loss_epoch=0.0122] \n",
      "Epoch 82:  85%|████████▍ | 130/153 [00:23<00:04,  5.57it/s, loss=0.007, v_num=5, train_loss_step=0.00732, val_loss=0.876, val_acc=0.82, train_loss_epoch=0.0146]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 82:  92%|█████████▏| 140/153 [00:27<00:02,  5.16it/s, loss=0.029, v_num=5, train_loss_step=0.000289, val_loss=0.486, val_acc=0.885, train_loss_epoch=0.0146]\n",
      "Epoch 83:  85%|████████▍ | 130/153 [00:23<00:04,  5.60it/s, loss=0.032, v_num=5, train_loss_step=0.000962, val_loss=0.486, val_acc=0.885, train_loss_epoch=0.0273]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 83:  92%|█████████▏| 140/153 [00:27<00:02,  5.18it/s, loss=0.035, v_num=5, train_loss_step=0.00491, val_loss=0.521, val_acc=0.869, train_loss_epoch=0.0273] \n",
      "Epoch 84:  85%|████████▍ | 130/153 [00:23<00:04,  5.64it/s, loss=0.015, v_num=5, train_loss_step=0.0126, val_loss=0.521, val_acc=0.869, train_loss_epoch=0.0164] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 84:  92%|█████████▏| 140/153 [00:26<00:02,  5.21it/s, loss=0.013, v_num=5, train_loss_step=0.0013, val_loss=0.69, val_acc=0.869, train_loss_epoch=0.0164] \n",
      "Epoch 85:  85%|████████▍ | 130/153 [00:22<00:04,  5.74it/s, loss=0.014, v_num=5, train_loss_step=0.0682, val_loss=0.69, val_acc=0.869, train_loss_epoch=0.0185] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 85:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.014, v_num=5, train_loss_step=8.71e-5, val_loss=0.622, val_acc=0.852, train_loss_epoch=0.0185]\n",
      "Epoch 86:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.008, v_num=5, train_loss_step=0.0511, val_loss=0.622, val_acc=0.852, train_loss_epoch=0.0107]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 86:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.010, v_num=5, train_loss_step=0.000604, val_loss=0.657, val_acc=0.852, train_loss_epoch=0.0107]\n",
      "Epoch 87:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.013, v_num=5, train_loss_step=0.00336, val_loss=0.657, val_acc=0.852, train_loss_epoch=0.00992]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 87:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.006, v_num=5, train_loss_step=0.0012, val_loss=0.76, val_acc=0.836, train_loss_epoch=0.00992]  \n",
      "Epoch 88:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.014, v_num=5, train_loss_step=0.000941, val_loss=0.76, val_acc=0.836, train_loss_epoch=0.0106]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 88:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.052, v_num=5, train_loss_step=0.00335, val_loss=0.712, val_acc=0.836, train_loss_epoch=0.0106]\n",
      "Epoch 89:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.008, v_num=5, train_loss_step=0.00252, val_loss=0.712, val_acc=0.836, train_loss_epoch=0.018] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 89:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.012, v_num=5, train_loss_step=0.0178, val_loss=0.78, val_acc=0.82, train_loss_epoch=0.018]   \n",
      "Epoch 90:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.016, v_num=5, train_loss_step=0.00693, val_loss=0.78, val_acc=0.82, train_loss_epoch=0.0143]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 90:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.009, v_num=5, train_loss_step=0.00702, val_loss=2.17, val_acc=0.656, train_loss_epoch=0.0143]\n",
      "Epoch 91:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.017, v_num=5, train_loss_step=0.007, val_loss=2.17, val_acc=0.656, train_loss_epoch=0.017]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 91:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.018, v_num=5, train_loss_step=0.00271, val_loss=0.83, val_acc=0.82, train_loss_epoch=0.017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.040, v_num=5, train_loss_step=0.00976, val_loss=0.83, val_acc=0.82, train_loss_epoch=0.0117]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 92:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.033, v_num=5, train_loss_step=0.0145, val_loss=1.34, val_acc=0.705, train_loss_epoch=0.0117]\n",
      "Epoch 93:  85%|████████▍ | 130/153 [00:22<00:04,  5.74it/s, loss=0.012, v_num=5, train_loss_step=0.00214, val_loss=1.34, val_acc=0.705, train_loss_epoch=0.0352]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 93:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.009, v_num=5, train_loss_step=0.000466, val_loss=1.01, val_acc=0.803, train_loss_epoch=0.0352]\n",
      "Epoch 94:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.008, v_num=5, train_loss_step=0.00179, val_loss=1.01, val_acc=0.803, train_loss_epoch=0.019]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 94:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.005, v_num=5, train_loss_step=0.00394, val_loss=0.959, val_acc=0.787, train_loss_epoch=0.019]\n",
      "Epoch 95:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.009, v_num=5, train_loss_step=0.00106, val_loss=0.959, val_acc=0.787, train_loss_epoch=0.00863]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 95:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.008, v_num=5, train_loss_step=0.000971, val_loss=0.81, val_acc=0.836, train_loss_epoch=0.00863]\n",
      "Epoch 96:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.006, v_num=5, train_loss_step=0.00165, val_loss=0.81, val_acc=0.836, train_loss_epoch=0.00822] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 96:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.006, v_num=5, train_loss_step=0.00183, val_loss=0.82, val_acc=0.82, train_loss_epoch=0.00822] \n",
      "Epoch 97:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.007, v_num=5, train_loss_step=0.00508, val_loss=0.82, val_acc=0.82, train_loss_epoch=0.00937] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 97:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.009, v_num=5, train_loss_step=0.000644, val_loss=0.897, val_acc=0.82, train_loss_epoch=0.00937]\n",
      "Epoch 98:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.177, v_num=5, train_loss_step=0.00528, val_loss=0.897, val_acc=0.82, train_loss_epoch=0.0105]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 98:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.078, v_num=5, train_loss_step=9.13e-5, val_loss=2.38, val_acc=0.639, train_loss_epoch=0.0105]\n",
      "Epoch 99:  85%|████████▍ | 130/153 [00:23<00:04,  5.64it/s, loss=0.035, v_num=5, train_loss_step=0.00272, val_loss=2.38, val_acc=0.639, train_loss_epoch=0.056] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 99:  92%|█████████▏| 140/153 [00:26<00:02,  5.22it/s, loss=0.037, v_num=5, train_loss_step=0.000258, val_loss=1.48, val_acc=0.639, train_loss_epoch=0.056]\n",
      "Epoch 100:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.005, v_num=5, train_loss_step=0.000975, val_loss=1.48, val_acc=0.639, train_loss_epoch=0.0146]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 100:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.007, v_num=5, train_loss_step=0.037, val_loss=1.9, val_acc=0.656, train_loss_epoch=0.0146]    \n",
      "Epoch 101:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.009, v_num=5, train_loss_step=0.0012, val_loss=1.9, val_acc=0.656, train_loss_epoch=0.0119] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 101:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.009, v_num=5, train_loss_step=0.00523, val_loss=1.98, val_acc=0.656, train_loss_epoch=0.0119]\n",
      "Epoch 102:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.007, v_num=5, train_loss_step=0.00156, val_loss=1.98, val_acc=0.656, train_loss_epoch=0.00897]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 102:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.008, v_num=5, train_loss_step=0.0224, val_loss=1.66, val_acc=0.639, train_loss_epoch=0.00897] \n",
      "Epoch 103:  85%|████████▍ | 130/153 [00:23<00:04,  5.65it/s, loss=0.012, v_num=5, train_loss_step=0.0401, val_loss=1.66, val_acc=0.639, train_loss_epoch=0.0088]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 103:  92%|█████████▏| 140/153 [00:26<00:02,  5.22it/s, loss=0.010, v_num=5, train_loss_step=0.00021, val_loss=1.59, val_acc=0.656, train_loss_epoch=0.0088]\n",
      "Epoch 104:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.005, v_num=5, train_loss_step=0.00389, val_loss=1.59, val_acc=0.656, train_loss_epoch=0.0106]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 104:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.008, v_num=5, train_loss_step=0.0212, val_loss=1.61, val_acc=0.656, train_loss_epoch=0.0106] \n",
      "Epoch 105:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.004, v_num=5, train_loss_step=0.00512, val_loss=1.61, val_acc=0.656, train_loss_epoch=0.00954]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 105:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.004, v_num=5, train_loss_step=0.000943, val_loss=1.53, val_acc=0.656, train_loss_epoch=0.00954]\n",
      "Epoch 106:  85%|████████▍ | 130/153 [00:23<00:04,  5.65it/s, loss=0.005, v_num=5, train_loss_step=0.00136, val_loss=1.53, val_acc=0.656, train_loss_epoch=0.00756] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 106:  92%|█████████▏| 140/153 [00:26<00:02,  5.22it/s, loss=0.037, v_num=5, train_loss_step=0.00138, val_loss=1.5, val_acc=0.656, train_loss_epoch=0.00756] \n",
      "Epoch 107:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.007, v_num=5, train_loss_step=0.00528, val_loss=1.5, val_acc=0.656, train_loss_epoch=0.0131] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 107:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.008, v_num=5, train_loss_step=0.00171, val_loss=1.7, val_acc=0.656, train_loss_epoch=0.0131]\n",
      "Epoch 108:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.005, v_num=5, train_loss_step=0.00128, val_loss=1.7, val_acc=0.656, train_loss_epoch=0.0106]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 108:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.005, v_num=5, train_loss_step=0.00622, val_loss=1.72, val_acc=0.639, train_loss_epoch=0.0106]\n",
      "Epoch 109:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.009, v_num=5, train_loss_step=0.0074, val_loss=1.72, val_acc=0.639, train_loss_epoch=0.00665]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 109:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.010, v_num=5, train_loss_step=0.00536, val_loss=1.83, val_acc=0.639, train_loss_epoch=0.00665]\n",
      "Epoch 110:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.003, v_num=5, train_loss_step=0.000736, val_loss=1.83, val_acc=0.639, train_loss_epoch=0.00787]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 110:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.004, v_num=5, train_loss_step=0.00182, val_loss=1.3, val_acc=0.705, train_loss_epoch=0.00787]  \n",
      "Epoch 111:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.009, v_num=5, train_loss_step=0.00292, val_loss=1.3, val_acc=0.705, train_loss_epoch=0.00966]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 111:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.007, v_num=5, train_loss_step=0.00179, val_loss=1.53, val_acc=0.656, train_loss_epoch=0.00966]\n",
      "Epoch 112:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.005, v_num=5, train_loss_step=0.00312, val_loss=1.53, val_acc=0.656, train_loss_epoch=0.0088] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 112:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.006, v_num=5, train_loss_step=0.00389, val_loss=1.98, val_acc=0.656, train_loss_epoch=0.0088]\n",
      "Epoch 113:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.008, v_num=5, train_loss_step=0.00241, val_loss=1.98, val_acc=0.656, train_loss_epoch=0.00992] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 113:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.004, v_num=5, train_loss_step=0.00343, val_loss=1.96, val_acc=0.639, train_loss_epoch=0.00992]\n",
      "Epoch 114:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.008, v_num=5, train_loss_step=0.0688, val_loss=1.96, val_acc=0.639, train_loss_epoch=0.0095]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.009, v_num=5, train_loss_step=0.00187, val_loss=1.81, val_acc=0.639, train_loss_epoch=0.0095]\n",
      "Epoch 115:  85%|████████▍ | 130/153 [00:23<00:04,  5.65it/s, loss=0.008, v_num=5, train_loss_step=0.000873, val_loss=1.81, val_acc=0.639, train_loss_epoch=0.00765]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 115:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.009, v_num=5, train_loss_step=0.0453, val_loss=2.09, val_acc=0.639, train_loss_epoch=0.00765]  \n",
      "Epoch 116:  85%|████████▍ | 130/153 [00:23<00:04,  5.64it/s, loss=0.004, v_num=5, train_loss_step=0.00125, val_loss=2.09, val_acc=0.639, train_loss_epoch=0.00794] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 116:  92%|█████████▏| 140/153 [00:26<00:02,  5.22it/s, loss=0.007, v_num=5, train_loss_step=0.00701, val_loss=1.85, val_acc=0.639, train_loss_epoch=0.00794]\n",
      "Epoch 117:  85%|████████▍ | 130/153 [00:22<00:03,  5.75it/s, loss=0.016, v_num=5, train_loss_step=0.00475, val_loss=1.85, val_acc=0.639, train_loss_epoch=0.00785] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 117:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.016, v_num=5, train_loss_step=0.0039, val_loss=1.83, val_acc=0.639, train_loss_epoch=0.00785] \n",
      "Epoch 118:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.005, v_num=5, train_loss_step=0.00637, val_loss=1.83, val_acc=0.639, train_loss_epoch=0.00795]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 118:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.004, v_num=5, train_loss_step=0.000256, val_loss=1.86, val_acc=0.656, train_loss_epoch=0.00795]\n",
      "Epoch 119:  85%|████████▍ | 130/153 [00:23<00:04,  5.63it/s, loss=0.014, v_num=5, train_loss_step=0.0133, val_loss=1.86, val_acc=0.656, train_loss_epoch=0.00771]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 119:  92%|█████████▏| 140/153 [00:26<00:02,  5.21it/s, loss=0.011, v_num=5, train_loss_step=0.00543, val_loss=1.53, val_acc=0.639, train_loss_epoch=0.00771]\n",
      "Epoch 120:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.007, v_num=5, train_loss_step=0.0102, val_loss=1.53, val_acc=0.639, train_loss_epoch=0.014]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 120:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.007, v_num=5, train_loss_step=0.0019, val_loss=1.52, val_acc=0.656, train_loss_epoch=0.014]\n",
      "Epoch 121:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.006, v_num=5, train_loss_step=0.00329, val_loss=1.52, val_acc=0.656, train_loss_epoch=0.00702]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 121:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.003, v_num=5, train_loss_step=0.00112, val_loss=1.5, val_acc=0.656, train_loss_epoch=0.00702] \n",
      "Epoch 122:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.004, v_num=5, train_loss_step=0.00251, val_loss=1.5, val_acc=0.656, train_loss_epoch=0.00632] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 122:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.003, v_num=5, train_loss_step=0.00103, val_loss=1.68, val_acc=0.656, train_loss_epoch=0.00632]\n",
      "Epoch 123:  85%|████████▍ | 130/153 [00:23<00:04,  5.62it/s, loss=0.005, v_num=5, train_loss_step=0.0095, val_loss=1.68, val_acc=0.656, train_loss_epoch=0.00518] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 123:  92%|█████████▏| 140/153 [00:27<00:02,  5.18it/s, loss=0.006, v_num=5, train_loss_step=0.00164, val_loss=1.93, val_acc=0.639, train_loss_epoch=0.00518]\n",
      "Epoch 124:  85%|████████▍ | 130/153 [00:23<00:04,  5.63it/s, loss=0.011, v_num=5, train_loss_step=0.00407, val_loss=1.93, val_acc=0.639, train_loss_epoch=0.00626]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 124:  92%|█████████▏| 140/153 [00:27<00:02,  5.18it/s, loss=0.009, v_num=5, train_loss_step=0.00112, val_loss=1.64, val_acc=0.639, train_loss_epoch=0.00626]\n",
      "Epoch 124:  92%|█████████▏| 140/153 [00:27<00:02,  5.16it/s, loss=0.009, v_num=5, train_loss_step=0.00112, val_loss=1.64, val_acc=0.639, train_loss_epoch=0.00626]\n"
     ]
    }
   ],
   "source": [
    "configs['DATASET']['AUGMENTATION'] = 'gaussian'\n",
    "configs['LOSS'] = 'cross_entropy'\n",
    "configs['CHECKPOINT']['SAVE_NAME'] = 'crnn-bmw-gaussian'\n",
    "torch.cuda.empty_cache()\n",
    "do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: gaussian\n",
      "Data augmentation for BMW dataset: none\n",
      "Data augmentation for BMW dataset: none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name        | Type        | Params\n",
      "---------------------------------------------\n",
      "0  | conv1       | Conv2d      | 640   \n",
      "1  | bn1         | BatchNorm2d | 128   \n",
      "2  | dropout1    | Dropout     | 0     \n",
      "3  | conv2       | Conv2d      | 73 K  \n",
      "4  | bn2         | BatchNorm2d | 256   \n",
      "5  | dropout2    | Dropout     | 0     \n",
      "6  | conv3       | Conv2d      | 147 K \n",
      "7  | bn3         | BatchNorm2d | 256   \n",
      "8  | dropout3    | Dropout     | 0     \n",
      "9  | conv4       | Conv2d      | 147 K \n",
      "10 | bn4         | BatchNorm2d | 256   \n",
      "11 | dropout4    | Dropout     | 0     \n",
      "12 | rnn         | GRU         | 21 K  \n",
      "13 | dropout_rnn | Dropout     | 0     \n",
      "14 | linear      | Linear      | 198   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=1.300, v_num=6, train_loss_step=0.779]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=1.275, v_num=6, train_loss_step=1.49, val_loss=1.2, val_acc=0.607]\n",
      "Epoch 1:  85%|████████▍ | 130/153 [00:23<00:04,  5.64it/s, loss=1.307, v_num=6, train_loss_step=1.49, val_loss=1.2, val_acc=0.607, train_loss_epoch=1.33]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 140/153 [00:26<00:02,  5.22it/s, loss=1.361, v_num=6, train_loss_step=2.77, val_loss=1.14, val_acc=0.656, train_loss_epoch=1.33]\n",
      "Epoch 2:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=1.156, v_num=6, train_loss_step=1.02, val_loss=1.14, val_acc=0.656, train_loss_epoch=1.23]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=1.111, v_num=6, train_loss_step=1.55, val_loss=1.41, val_acc=0.459, train_loss_epoch=1.23]\n",
      "Epoch 3:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=1.144, v_num=6, train_loss_step=0.968, val_loss=1.41, val_acc=0.459, train_loss_epoch=1.18]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=1.054, v_num=6, train_loss_step=0.784, val_loss=1.01, val_acc=0.754, train_loss_epoch=1.18]\n",
      "Epoch 4:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=1.036, v_num=6, train_loss_step=0.572, val_loss=1.01, val_acc=0.754, train_loss_epoch=1.09]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=1.135, v_num=6, train_loss_step=0.536, val_loss=1.04, val_acc=0.705, train_loss_epoch=1.09]\n",
      "Epoch 5:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.948, v_num=6, train_loss_step=0.669, val_loss=1.04, val_acc=0.705, train_loss_epoch=1.01]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.908, v_num=6, train_loss_step=0.558, val_loss=1.17, val_acc=0.705, train_loss_epoch=1.01]\n",
      "Epoch 6:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.842, v_num=6, train_loss_step=0.63, val_loss=1.17, val_acc=0.705, train_loss_epoch=0.938] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.776, v_num=6, train_loss_step=0.643, val_loss=0.918, val_acc=0.738, train_loss_epoch=0.938]\n",
      "Epoch 7:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.742, v_num=6, train_loss_step=0.654, val_loss=0.918, val_acc=0.738, train_loss_epoch=0.893]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.805, v_num=6, train_loss_step=1.34, val_loss=0.867, val_acc=0.803, train_loss_epoch=0.893] \n",
      "Epoch 8:  85%|████████▍ | 130/153 [00:22<00:04,  5.74it/s, loss=0.776, v_num=6, train_loss_step=0.87, val_loss=0.867, val_acc=0.803, train_loss_epoch=0.798] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.767, v_num=6, train_loss_step=0.537, val_loss=0.807, val_acc=0.82, train_loss_epoch=0.798]\n",
      "Epoch 9:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.710, v_num=6, train_loss_step=0.505, val_loss=0.807, val_acc=0.82, train_loss_epoch=0.833]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.715, v_num=6, train_loss_step=0.603, val_loss=1.47, val_acc=0.623, train_loss_epoch=0.833]\n",
      "Epoch 10:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.751, v_num=6, train_loss_step=1.49, val_loss=1.47, val_acc=0.623, train_loss_epoch=0.799] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.795, v_num=6, train_loss_step=0.803, val_loss=1.29, val_acc=0.672, train_loss_epoch=0.799]\n",
      "Epoch 11:  85%|████████▍ | 130/153 [00:22<00:04,  5.75it/s, loss=0.818, v_num=6, train_loss_step=1.1, val_loss=1.29, val_acc=0.672, train_loss_epoch=0.748]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.900, v_num=6, train_loss_step=1.56, val_loss=1.17, val_acc=0.656, train_loss_epoch=0.748]\n",
      "Epoch 12:  85%|████████▍ | 130/153 [00:22<00:04,  5.74it/s, loss=0.656, v_num=6, train_loss_step=0.484, val_loss=1.17, val_acc=0.656, train_loss_epoch=0.771]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.740, v_num=6, train_loss_step=1.03, val_loss=0.689, val_acc=0.852, train_loss_epoch=0.771]\n",
      "Epoch 13:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.839, v_num=6, train_loss_step=0.919, val_loss=0.689, val_acc=0.852, train_loss_epoch=0.712]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.952, v_num=6, train_loss_step=0.454, val_loss=1.26, val_acc=0.689, train_loss_epoch=0.712] \n",
      "Epoch 14:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.800, v_num=6, train_loss_step=1.29, val_loss=1.26, val_acc=0.689, train_loss_epoch=0.739] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.732, v_num=6, train_loss_step=0.528, val_loss=0.768, val_acc=0.869, train_loss_epoch=0.739]\n",
      "Epoch 15:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.800, v_num=6, train_loss_step=0.44, val_loss=0.768, val_acc=0.869, train_loss_epoch=0.72]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.923, v_num=6, train_loss_step=0.657, val_loss=0.927, val_acc=0.721, train_loss_epoch=0.72]\n",
      "Epoch 16:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.680, v_num=6, train_loss_step=0.459, val_loss=0.927, val_acc=0.721, train_loss_epoch=0.699]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.660, v_num=6, train_loss_step=0.583, val_loss=1.18, val_acc=0.705, train_loss_epoch=0.699] \n",
      "Epoch 17:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.691, v_num=6, train_loss_step=0.445, val_loss=1.18, val_acc=0.705, train_loss_epoch=0.703]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.591, v_num=6, train_loss_step=0.449, val_loss=1.12, val_acc=0.672, train_loss_epoch=0.703]\n",
      "Epoch 18:  85%|████████▍ | 130/153 [00:23<00:04,  5.64it/s, loss=0.715, v_num=6, train_loss_step=0.436, val_loss=1.12, val_acc=0.672, train_loss_epoch=0.668]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  92%|█████████▏| 140/153 [00:26<00:02,  5.22it/s, loss=0.656, v_num=6, train_loss_step=0.467, val_loss=0.813, val_acc=0.852, train_loss_epoch=0.668]\n",
      "Epoch 19:  85%|████████▍ | 130/153 [00:22<00:03,  5.76it/s, loss=0.669, v_num=6, train_loss_step=1.2, val_loss=0.813, val_acc=0.852, train_loss_epoch=0.65]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  92%|█████████▏| 140/153 [00:26<00:02,  5.32it/s, loss=0.641, v_num=6, train_loss_step=0.446, val_loss=0.809, val_acc=0.82, train_loss_epoch=0.65]\n",
      "Epoch 20:  85%|████████▍ | 130/153 [00:22<00:04,  5.74it/s, loss=0.717, v_num=6, train_loss_step=0.431, val_loss=0.809, val_acc=0.82, train_loss_epoch=0.651]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  92%|█████████▏| 140/153 [00:26<00:02,  5.33it/s, loss=0.707, v_num=6, train_loss_step=0.638, val_loss=0.73, val_acc=0.852, train_loss_epoch=0.651]\n",
      "Epoch 21:  85%|████████▍ | 130/153 [00:22<00:03,  5.76it/s, loss=0.777, v_num=6, train_loss_step=0.457, val_loss=0.73, val_acc=0.852, train_loss_epoch=0.657]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  92%|█████████▏| 140/153 [00:26<00:02,  5.34it/s, loss=0.700, v_num=6, train_loss_step=0.662, val_loss=1.01, val_acc=0.77, train_loss_epoch=0.657] \n",
      "Epoch 22:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.588, v_num=6, train_loss_step=0.464, val_loss=1.01, val_acc=0.77, train_loss_epoch=0.66] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.618, v_num=6, train_loss_step=1.41, val_loss=1.34, val_acc=0.672, train_loss_epoch=0.66]\n",
      "Epoch 23:  85%|████████▍ | 130/153 [00:22<00:03,  5.77it/s, loss=0.660, v_num=6, train_loss_step=0.596, val_loss=1.34, val_acc=0.672, train_loss_epoch=0.664]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  92%|█████████▏| 140/153 [00:26<00:02,  5.33it/s, loss=0.708, v_num=6, train_loss_step=0.48, val_loss=0.808, val_acc=0.787, train_loss_epoch=0.664]\n",
      "Epoch 24:  85%|████████▍ | 130/153 [00:22<00:03,  5.76it/s, loss=0.647, v_num=6, train_loss_step=0.496, val_loss=0.808, val_acc=0.787, train_loss_epoch=0.643]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  92%|█████████▏| 140/153 [00:26<00:02,  5.33it/s, loss=0.705, v_num=6, train_loss_step=0.453, val_loss=0.977, val_acc=0.787, train_loss_epoch=0.643]\n",
      "Epoch 25:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.603, v_num=6, train_loss_step=0.438, val_loss=0.977, val_acc=0.787, train_loss_epoch=0.66] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.673, v_num=6, train_loss_step=0.469, val_loss=0.677, val_acc=0.852, train_loss_epoch=0.66]\n",
      "Epoch 26:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.532, v_num=6, train_loss_step=0.452, val_loss=0.677, val_acc=0.852, train_loss_epoch=0.582]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.468, v_num=6, train_loss_step=0.442, val_loss=0.787, val_acc=0.836, train_loss_epoch=0.582]\n",
      "Epoch 27:  85%|████████▍ | 130/153 [00:22<00:03,  5.77it/s, loss=0.566, v_num=6, train_loss_step=0.483, val_loss=0.787, val_acc=0.836, train_loss_epoch=0.554]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27:  92%|█████████▏| 140/153 [00:26<00:02,  5.33it/s, loss=0.538, v_num=6, train_loss_step=0.451, val_loss=0.58, val_acc=0.918, train_loss_epoch=0.554] \n",
      "Epoch 28:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.576, v_num=6, train_loss_step=1.63, val_loss=0.58, val_acc=0.918, train_loss_epoch=0.54]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28:  92%|█████████▏| 140/153 [00:26<00:02,  5.31it/s, loss=0.594, v_num=6, train_loss_step=0.44, val_loss=0.682, val_acc=0.869, train_loss_epoch=0.54]\n",
      "Epoch 29:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.653, v_num=6, train_loss_step=0.466, val_loss=0.682, val_acc=0.869, train_loss_epoch=0.555]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29:  92%|█████████▏| 140/153 [00:26<00:02,  5.31it/s, loss=0.593, v_num=6, train_loss_step=0.473, val_loss=0.82, val_acc=0.836, train_loss_epoch=0.555] \n",
      "Epoch 30:  85%|████████▍ | 130/153 [00:22<00:03,  5.79it/s, loss=0.618, v_num=6, train_loss_step=0.435, val_loss=0.82, val_acc=0.836, train_loss_epoch=0.558]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30:  92%|█████████▏| 140/153 [00:26<00:02,  5.36it/s, loss=0.570, v_num=6, train_loss_step=0.447, val_loss=0.911, val_acc=0.803, train_loss_epoch=0.558]\n",
      "Epoch 31:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.572, v_num=6, train_loss_step=0.523, val_loss=0.911, val_acc=0.803, train_loss_epoch=0.566]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.596, v_num=6, train_loss_step=0.479, val_loss=0.897, val_acc=0.787, train_loss_epoch=0.566]\n",
      "Epoch 32:  85%|████████▍ | 130/153 [00:23<00:04,  5.61it/s, loss=0.601, v_num=6, train_loss_step=0.451, val_loss=0.897, val_acc=0.787, train_loss_epoch=0.555]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32:  92%|█████████▏| 140/153 [00:26<00:02,  5.20it/s, loss=0.587, v_num=6, train_loss_step=0.469, val_loss=0.679, val_acc=0.869, train_loss_epoch=0.555]\n",
      "Epoch 33:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.593, v_num=6, train_loss_step=0.45, val_loss=0.679, val_acc=0.869, train_loss_epoch=0.591] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.543, v_num=6, train_loss_step=0.434, val_loss=0.823, val_acc=0.836, train_loss_epoch=0.591]\n",
      "Epoch 34:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.592, v_num=6, train_loss_step=0.472, val_loss=0.823, val_acc=0.836, train_loss_epoch=0.543]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.599, v_num=6, train_loss_step=0.861, val_loss=0.69, val_acc=0.885, train_loss_epoch=0.543] \n",
      "Epoch 35:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.528, v_num=6, train_loss_step=0.746, val_loss=0.69, val_acc=0.885, train_loss_epoch=0.586]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.530, v_num=6, train_loss_step=0.543, val_loss=0.744, val_acc=0.836, train_loss_epoch=0.586]\n",
      "Epoch 36:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.484, v_num=6, train_loss_step=0.439, val_loss=0.744, val_acc=0.836, train_loss_epoch=0.543]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.542, v_num=6, train_loss_step=0.438, val_loss=0.833, val_acc=0.82, train_loss_epoch=0.543] \n",
      "Epoch 37:  85%|████████▍ | 130/153 [00:23<00:04,  5.51it/s, loss=0.534, v_num=6, train_loss_step=0.468, val_loss=0.833, val_acc=0.82, train_loss_epoch=0.547]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.567, v_num=6, train_loss_step=0.915, val_loss=0.744, val_acc=0.852, train_loss_epoch=0.547]\n",
      "Epoch 38:  85%|████████▍ | 130/153 [00:23<00:04,  5.64it/s, loss=0.525, v_num=6, train_loss_step=0.598, val_loss=0.744, val_acc=0.852, train_loss_epoch=0.555]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38:  92%|█████████▏| 140/153 [00:26<00:02,  5.19it/s, loss=0.522, v_num=6, train_loss_step=0.428, val_loss=0.878, val_acc=0.836, train_loss_epoch=0.555]\n",
      "Epoch 39:  85%|████████▍ | 130/153 [00:23<00:04,  5.65it/s, loss=0.572, v_num=6, train_loss_step=0.439, val_loss=0.878, val_acc=0.836, train_loss_epoch=0.529]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.552, v_num=6, train_loss_step=0.668, val_loss=0.985, val_acc=0.754, train_loss_epoch=0.529]\n",
      "Epoch 40:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.520, v_num=6, train_loss_step=0.443, val_loss=0.985, val_acc=0.754, train_loss_epoch=0.544]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 40:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.530, v_num=6, train_loss_step=0.431, val_loss=1.17, val_acc=0.623, train_loss_epoch=0.544] \n",
      "Epoch 41:  85%|████████▍ | 130/153 [00:23<00:04,  5.60it/s, loss=0.488, v_num=6, train_loss_step=0.48, val_loss=1.17, val_acc=0.623, train_loss_epoch=0.522] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 41:  92%|█████████▏| 140/153 [00:27<00:02,  5.18it/s, loss=0.486, v_num=6, train_loss_step=0.448, val_loss=0.811, val_acc=0.82, train_loss_epoch=0.522]\n",
      "Epoch 42:  85%|████████▍ | 130/153 [00:23<00:04,  5.64it/s, loss=0.506, v_num=6, train_loss_step=0.455, val_loss=0.811, val_acc=0.82, train_loss_epoch=0.513]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 42:  92%|█████████▏| 140/153 [00:26<00:02,  5.22it/s, loss=0.483, v_num=6, train_loss_step=0.851, val_loss=0.682, val_acc=0.869, train_loss_epoch=0.513]\n",
      "Epoch 43:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.502, v_num=6, train_loss_step=0.475, val_loss=0.682, val_acc=0.869, train_loss_epoch=0.528]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 43:  92%|█████████▏| 140/153 [00:26<00:02,  5.22it/s, loss=0.518, v_num=6, train_loss_step=0.464, val_loss=0.554, val_acc=0.934, train_loss_epoch=0.528]\n",
      "Epoch 44:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.586, v_num=6, train_loss_step=1.12, val_loss=0.554, val_acc=0.934, train_loss_epoch=0.512] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 44:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.557, v_num=6, train_loss_step=0.452, val_loss=0.692, val_acc=0.885, train_loss_epoch=0.512]\n",
      "Epoch 45:  85%|████████▍ | 130/153 [00:22<00:03,  5.75it/s, loss=0.478, v_num=6, train_loss_step=0.452, val_loss=0.692, val_acc=0.885, train_loss_epoch=0.556]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 45:  92%|█████████▏| 140/153 [00:26<00:02,  5.31it/s, loss=0.473, v_num=6, train_loss_step=0.44, val_loss=0.725, val_acc=0.82, train_loss_epoch=0.556]  \n",
      "Epoch 46:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.563, v_num=6, train_loss_step=0.439, val_loss=0.725, val_acc=0.82, train_loss_epoch=0.524]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.511, v_num=6, train_loss_step=0.452, val_loss=0.702, val_acc=0.902, train_loss_epoch=0.524]\n",
      "Epoch 47:  85%|████████▍ | 130/153 [00:22<00:04,  5.74it/s, loss=0.464, v_num=6, train_loss_step=0.472, val_loss=0.702, val_acc=0.902, train_loss_epoch=0.528]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 47:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.457, v_num=6, train_loss_step=0.454, val_loss=0.618, val_acc=0.918, train_loss_epoch=0.528]\n",
      "Epoch 48:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.494, v_num=6, train_loss_step=0.45, val_loss=0.618, val_acc=0.918, train_loss_epoch=0.49]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 48:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.476, v_num=6, train_loss_step=0.459, val_loss=0.566, val_acc=0.918, train_loss_epoch=0.49]\n",
      "Epoch 49:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.480, v_num=6, train_loss_step=0.433, val_loss=0.566, val_acc=0.918, train_loss_epoch=0.49]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 49:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.457, v_num=6, train_loss_step=0.435, val_loss=0.792, val_acc=0.852, train_loss_epoch=0.49]\n",
      "Epoch 50:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.498, v_num=6, train_loss_step=0.442, val_loss=0.792, val_acc=0.852, train_loss_epoch=0.497]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 50:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.501, v_num=6, train_loss_step=0.441, val_loss=0.727, val_acc=0.918, train_loss_epoch=0.497]\n",
      "Epoch 51:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.456, v_num=6, train_loss_step=0.466, val_loss=0.727, val_acc=0.918, train_loss_epoch=0.486]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 51:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.473, v_num=6, train_loss_step=0.434, val_loss=0.587, val_acc=0.902, train_loss_epoch=0.486]\n",
      "Epoch 52:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.474, v_num=6, train_loss_step=0.468, val_loss=0.587, val_acc=0.902, train_loss_epoch=0.48] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 52:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.468, v_num=6, train_loss_step=0.426, val_loss=0.669, val_acc=0.869, train_loss_epoch=0.48]\n",
      "Epoch 53:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.464, v_num=6, train_loss_step=0.439, val_loss=0.669, val_acc=0.869, train_loss_epoch=0.467]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 53:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.491, v_num=6, train_loss_step=0.436, val_loss=0.625, val_acc=0.918, train_loss_epoch=0.467]\n",
      "Epoch 54:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.455, v_num=6, train_loss_step=0.448, val_loss=0.625, val_acc=0.918, train_loss_epoch=0.475]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 54:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.478, v_num=6, train_loss_step=0.443, val_loss=0.645, val_acc=0.902, train_loss_epoch=0.475]\n",
      "Epoch 55:  85%|████████▍ | 130/153 [00:22<00:04,  5.65it/s, loss=0.453, v_num=6, train_loss_step=0.449, val_loss=0.645, val_acc=0.902, train_loss_epoch=0.475]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 55:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.456, v_num=6, train_loss_step=0.426, val_loss=0.752, val_acc=0.82, train_loss_epoch=0.475] \n",
      "Epoch 56:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.478, v_num=6, train_loss_step=0.445, val_loss=0.752, val_acc=0.82, train_loss_epoch=0.473]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 56:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.471, v_num=6, train_loss_step=0.446, val_loss=0.502, val_acc=0.967, train_loss_epoch=0.473]\n",
      "Epoch 57:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.470, v_num=6, train_loss_step=0.458, val_loss=0.502, val_acc=0.967, train_loss_epoch=0.469]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 57:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.478, v_num=6, train_loss_step=0.445, val_loss=0.533, val_acc=0.951, train_loss_epoch=0.469]\n",
      "Epoch 58:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.462, v_num=6, train_loss_step=0.544, val_loss=0.533, val_acc=0.951, train_loss_epoch=0.463]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 58:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.461, v_num=6, train_loss_step=0.441, val_loss=0.654, val_acc=0.885, train_loss_epoch=0.463]\n",
      "Epoch 59:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.445, v_num=6, train_loss_step=0.443, val_loss=0.654, val_acc=0.885, train_loss_epoch=0.461]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 59:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.463, v_num=6, train_loss_step=0.665, val_loss=0.738, val_acc=0.869, train_loss_epoch=0.461]\n",
      "Epoch 60:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.463, v_num=6, train_loss_step=0.433, val_loss=0.738, val_acc=0.869, train_loss_epoch=0.464]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 60:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.456, v_num=6, train_loss_step=0.445, val_loss=0.655, val_acc=0.902, train_loss_epoch=0.464]\n",
      "Epoch 61:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.487, v_num=6, train_loss_step=0.441, val_loss=0.655, val_acc=0.902, train_loss_epoch=0.502]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 61:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.452, v_num=6, train_loss_step=0.446, val_loss=0.615, val_acc=0.918, train_loss_epoch=0.502]\n",
      "Epoch 62:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.468, v_num=6, train_loss_step=0.449, val_loss=0.615, val_acc=0.918, train_loss_epoch=0.468]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 62:  92%|█████████▏| 140/153 [00:26<00:02,  5.30it/s, loss=0.470, v_num=6, train_loss_step=0.471, val_loss=0.843, val_acc=0.869, train_loss_epoch=0.468]\n",
      "Epoch 63:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.465, v_num=6, train_loss_step=0.46, val_loss=0.843, val_acc=0.869, train_loss_epoch=0.492] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 63:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.465, v_num=6, train_loss_step=0.44, val_loss=0.615, val_acc=0.869, train_loss_epoch=0.492]\n",
      "Epoch 64:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.452, v_num=6, train_loss_step=0.438, val_loss=0.615, val_acc=0.869, train_loss_epoch=0.471]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 64:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.454, v_num=6, train_loss_step=0.44, val_loss=0.765, val_acc=0.852, train_loss_epoch=0.471] \n",
      "Epoch 65:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.458, v_num=6, train_loss_step=0.436, val_loss=0.765, val_acc=0.852, train_loss_epoch=0.465]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 65:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.493, v_num=6, train_loss_step=0.841, val_loss=0.622, val_acc=0.918, train_loss_epoch=0.465]\n",
      "Epoch 66:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.470, v_num=6, train_loss_step=0.436, val_loss=0.622, val_acc=0.918, train_loss_epoch=0.458]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 66:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.469, v_num=6, train_loss_step=0.443, val_loss=0.611, val_acc=0.918, train_loss_epoch=0.458]\n",
      "Epoch 67:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.447, v_num=6, train_loss_step=0.432, val_loss=0.611, val_acc=0.918, train_loss_epoch=0.477]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 67:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.455, v_num=6, train_loss_step=0.452, val_loss=0.736, val_acc=0.869, train_loss_epoch=0.477]\n",
      "Epoch 68:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.450, v_num=6, train_loss_step=0.435, val_loss=0.736, val_acc=0.869, train_loss_epoch=0.456]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 68:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.456, v_num=6, train_loss_step=0.481, val_loss=0.735, val_acc=0.885, train_loss_epoch=0.456]\n",
      "Epoch 69:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.450, v_num=6, train_loss_step=0.447, val_loss=0.735, val_acc=0.885, train_loss_epoch=0.457]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.448, v_num=6, train_loss_step=0.437, val_loss=0.728, val_acc=0.869, train_loss_epoch=0.457]\n",
      "Epoch 70:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.455, v_num=6, train_loss_step=0.441, val_loss=0.728, val_acc=0.869, train_loss_epoch=0.456]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 70:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.456, v_num=6, train_loss_step=0.565, val_loss=0.685, val_acc=0.885, train_loss_epoch=0.456]\n",
      "Epoch 71:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.452, v_num=6, train_loss_step=0.445, val_loss=0.685, val_acc=0.885, train_loss_epoch=0.455]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 71:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.510, v_num=6, train_loss_step=0.457, val_loss=0.748, val_acc=0.852, train_loss_epoch=0.455]\n",
      "Epoch 72:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.453, v_num=6, train_loss_step=0.573, val_loss=0.748, val_acc=0.852, train_loss_epoch=0.482]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 72:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.464, v_num=6, train_loss_step=0.43, val_loss=0.597, val_acc=0.902, train_loss_epoch=0.482] \n",
      "Epoch 73:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.448, v_num=6, train_loss_step=0.445, val_loss=0.597, val_acc=0.902, train_loss_epoch=0.485]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 73:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.455, v_num=6, train_loss_step=0.468, val_loss=0.566, val_acc=0.918, train_loss_epoch=0.485]\n",
      "Epoch 74:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.450, v_num=6, train_loss_step=0.457, val_loss=0.566, val_acc=0.918, train_loss_epoch=0.468]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 74:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.449, v_num=6, train_loss_step=0.431, val_loss=0.793, val_acc=0.869, train_loss_epoch=0.468]\n",
      "Epoch 75:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.443, v_num=6, train_loss_step=0.445, val_loss=0.793, val_acc=0.869, train_loss_epoch=0.451]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 75:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.442, v_num=6, train_loss_step=0.446, val_loss=0.704, val_acc=0.885, train_loss_epoch=0.451]\n",
      "Epoch 76:  85%|████████▍ | 130/153 [00:23<00:04,  5.65it/s, loss=0.449, v_num=6, train_loss_step=0.441, val_loss=0.704, val_acc=0.885, train_loss_epoch=0.452]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 76:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.452, v_num=6, train_loss_step=0.473, val_loss=0.687, val_acc=0.885, train_loss_epoch=0.452]\n",
      "Epoch 77:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.458, v_num=6, train_loss_step=0.48, val_loss=0.687, val_acc=0.885, train_loss_epoch=0.45]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 77:  92%|█████████▏| 140/153 [00:26<00:02,  5.22it/s, loss=0.453, v_num=6, train_loss_step=0.428, val_loss=0.675, val_acc=0.869, train_loss_epoch=0.45]\n",
      "Epoch 78:  85%|████████▍ | 130/153 [00:23<00:04,  5.63it/s, loss=0.458, v_num=6, train_loss_step=0.451, val_loss=0.675, val_acc=0.869, train_loss_epoch=0.451]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 78:  92%|█████████▏| 140/153 [00:26<00:02,  5.19it/s, loss=0.453, v_num=6, train_loss_step=0.447, val_loss=0.776, val_acc=0.869, train_loss_epoch=0.451]\n",
      "Epoch 79:  85%|████████▍ | 130/153 [00:23<00:04,  5.60it/s, loss=0.460, v_num=6, train_loss_step=0.435, val_loss=0.776, val_acc=0.869, train_loss_epoch=0.453]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 79:  92%|█████████▏| 140/153 [00:27<00:02,  5.17it/s, loss=0.452, v_num=6, train_loss_step=0.438, val_loss=0.652, val_acc=0.918, train_loss_epoch=0.453]\n",
      "Epoch 80:  85%|████████▍ | 130/153 [00:23<00:04,  5.62it/s, loss=0.444, v_num=6, train_loss_step=0.454, val_loss=0.652, val_acc=0.918, train_loss_epoch=0.451]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 80:  92%|█████████▏| 140/153 [00:27<00:02,  5.18it/s, loss=0.447, v_num=6, train_loss_step=0.436, val_loss=0.612, val_acc=0.918, train_loss_epoch=0.451]\n",
      "Epoch 81:  85%|████████▍ | 130/153 [00:23<00:04,  5.61it/s, loss=0.446, v_num=6, train_loss_step=0.465, val_loss=0.612, val_acc=0.918, train_loss_epoch=0.449]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 81:  92%|█████████▏| 140/153 [00:27<00:02,  5.17it/s, loss=0.446, v_num=6, train_loss_step=0.451, val_loss=0.712, val_acc=0.885, train_loss_epoch=0.449]\n",
      "Epoch 82:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.447, v_num=6, train_loss_step=0.436, val_loss=0.712, val_acc=0.885, train_loss_epoch=0.447]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 82:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.445, v_num=6, train_loss_step=0.437, val_loss=0.684, val_acc=0.885, train_loss_epoch=0.447]\n",
      "Epoch 83:  85%|████████▍ | 130/153 [00:23<00:04,  5.63it/s, loss=0.448, v_num=6, train_loss_step=0.431, val_loss=0.684, val_acc=0.885, train_loss_epoch=0.447]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 83:  92%|█████████▏| 140/153 [00:26<00:02,  5.20it/s, loss=0.481, v_num=6, train_loss_step=1.01, val_loss=0.678, val_acc=0.885, train_loss_epoch=0.447] \n",
      "Epoch 84:  85%|████████▍ | 130/153 [00:23<00:04,  5.63it/s, loss=0.463, v_num=6, train_loss_step=0.439, val_loss=0.678, val_acc=0.885, train_loss_epoch=0.452]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 84:  92%|█████████▏| 140/153 [00:26<00:02,  5.19it/s, loss=0.467, v_num=6, train_loss_step=0.447, val_loss=0.648, val_acc=0.902, train_loss_epoch=0.452]\n",
      "Epoch 85:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.446, v_num=6, train_loss_step=0.456, val_loss=0.648, val_acc=0.902, train_loss_epoch=0.453]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 85:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.448, v_num=6, train_loss_step=0.44, val_loss=0.692, val_acc=0.885, train_loss_epoch=0.453] \n",
      "Epoch 86:  85%|████████▍ | 130/153 [00:23<00:04,  5.64it/s, loss=0.444, v_num=6, train_loss_step=0.45, val_loss=0.692, val_acc=0.885, train_loss_epoch=0.449] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 86:  92%|█████████▏| 140/153 [00:26<00:02,  5.22it/s, loss=0.444, v_num=6, train_loss_step=0.447, val_loss=0.735, val_acc=0.869, train_loss_epoch=0.449]\n",
      "Epoch 87:  85%|████████▍ | 130/153 [00:23<00:04,  5.64it/s, loss=0.448, v_num=6, train_loss_step=0.443, val_loss=0.735, val_acc=0.869, train_loss_epoch=0.447]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 87:  92%|█████████▏| 140/153 [00:26<00:02,  5.21it/s, loss=0.449, v_num=6, train_loss_step=0.44, val_loss=0.687, val_acc=0.885, train_loss_epoch=0.447] \n",
      "Epoch 88:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.443, v_num=6, train_loss_step=0.453, val_loss=0.687, val_acc=0.885, train_loss_epoch=0.446]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 88:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.447, v_num=6, train_loss_step=0.433, val_loss=0.708, val_acc=0.885, train_loss_epoch=0.446]\n",
      "Epoch 89:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.442, v_num=6, train_loss_step=0.437, val_loss=0.708, val_acc=0.885, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 89:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.444, v_num=6, train_loss_step=0.435, val_loss=0.694, val_acc=0.885, train_loss_epoch=0.445]\n",
      "Epoch 90:  85%|████████▍ | 130/153 [00:22<00:04,  5.68it/s, loss=0.444, v_num=6, train_loss_step=0.43, val_loss=0.694, val_acc=0.885, train_loss_epoch=0.446] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 90:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.465, v_num=6, train_loss_step=0.924, val_loss=0.64, val_acc=0.885, train_loss_epoch=0.446]\n",
      "Epoch 91:  85%|████████▍ | 130/153 [00:23<00:04,  5.65it/s, loss=0.447, v_num=6, train_loss_step=0.437, val_loss=0.64, val_acc=0.885, train_loss_epoch=0.449]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 91:  92%|█████████▏| 140/153 [00:26<00:02,  5.21it/s, loss=0.450, v_num=6, train_loss_step=0.444, val_loss=0.662, val_acc=0.918, train_loss_epoch=0.449]\n",
      "Epoch 92:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.443, v_num=6, train_loss_step=0.444, val_loss=0.662, val_acc=0.918, train_loss_epoch=0.449]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.446, v_num=6, train_loss_step=0.432, val_loss=0.779, val_acc=0.918, train_loss_epoch=0.449]\n",
      "Epoch 93:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.446, v_num=6, train_loss_step=0.437, val_loss=0.779, val_acc=0.918, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 93:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.450, v_num=6, train_loss_step=0.434, val_loss=0.674, val_acc=0.885, train_loss_epoch=0.443]\n",
      "Epoch 94:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.445, v_num=6, train_loss_step=0.473, val_loss=0.674, val_acc=0.885, train_loss_epoch=0.448]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 94:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.442, v_num=6, train_loss_step=0.433, val_loss=0.716, val_acc=0.869, train_loss_epoch=0.448]\n",
      "Epoch 95:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.455, v_num=6, train_loss_step=0.434, val_loss=0.716, val_acc=0.869, train_loss_epoch=0.446]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 95:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.442, v_num=6, train_loss_step=0.433, val_loss=0.677, val_acc=0.902, train_loss_epoch=0.446]\n",
      "Epoch 96:  85%|████████▍ | 130/153 [00:23<00:04,  5.65it/s, loss=0.444, v_num=6, train_loss_step=0.458, val_loss=0.677, val_acc=0.902, train_loss_epoch=0.447]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 96:  92%|█████████▏| 140/153 [00:26<00:02,  5.21it/s, loss=0.444, v_num=6, train_loss_step=0.43, val_loss=0.714, val_acc=0.869, train_loss_epoch=0.447] \n",
      "Epoch 97:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.448, v_num=6, train_loss_step=0.433, val_loss=0.714, val_acc=0.869, train_loss_epoch=0.446]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 97:  92%|█████████▏| 140/153 [00:26<00:02,  5.21it/s, loss=0.444, v_num=6, train_loss_step=0.453, val_loss=0.666, val_acc=0.869, train_loss_epoch=0.446]\n",
      "Epoch 98:  85%|████████▍ | 130/153 [00:23<00:04,  5.59it/s, loss=0.458, v_num=6, train_loss_step=0.436, val_loss=0.666, val_acc=0.869, train_loss_epoch=0.448]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 98:  92%|█████████▏| 140/153 [00:27<00:02,  5.16it/s, loss=0.463, v_num=6, train_loss_step=0.5, val_loss=0.677, val_acc=0.885, train_loss_epoch=0.448]  \n",
      "Epoch 99:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.447, v_num=6, train_loss_step=0.44, val_loss=0.677, val_acc=0.885, train_loss_epoch=0.463] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 99:  92%|█████████▏| 140/153 [00:26<00:02,  5.21it/s, loss=0.449, v_num=6, train_loss_step=0.44, val_loss=0.622, val_acc=0.918, train_loss_epoch=0.463]\n",
      "Epoch 100:  85%|████████▍ | 130/153 [00:23<00:04,  5.65it/s, loss=0.444, v_num=6, train_loss_step=0.469, val_loss=0.622, val_acc=0.918, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 100:  92%|█████████▏| 140/153 [00:26<00:02,  5.22it/s, loss=0.444, v_num=6, train_loss_step=0.437, val_loss=0.696, val_acc=0.885, train_loss_epoch=0.445]\n",
      "Epoch 101:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.442, v_num=6, train_loss_step=0.461, val_loss=0.696, val_acc=0.885, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 101:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.444, v_num=6, train_loss_step=0.432, val_loss=0.703, val_acc=0.885, train_loss_epoch=0.445]\n",
      "Epoch 102:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.448, v_num=6, train_loss_step=0.438, val_loss=0.703, val_acc=0.885, train_loss_epoch=0.448]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 102:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.445, v_num=6, train_loss_step=0.432, val_loss=0.674, val_acc=0.885, train_loss_epoch=0.448]\n",
      "Epoch 103:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.443, v_num=6, train_loss_step=0.437, val_loss=0.674, val_acc=0.885, train_loss_epoch=0.444]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 103:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.446, v_num=6, train_loss_step=0.432, val_loss=0.658, val_acc=0.885, train_loss_epoch=0.444]\n",
      "Epoch 104:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.449, v_num=6, train_loss_step=0.445, val_loss=0.658, val_acc=0.885, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 104:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.444, v_num=6, train_loss_step=0.46, val_loss=0.615, val_acc=0.902, train_loss_epoch=0.443] \n",
      "Epoch 105:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.443, v_num=6, train_loss_step=0.447, val_loss=0.615, val_acc=0.902, train_loss_epoch=0.447]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 105:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.444, v_num=6, train_loss_step=0.426, val_loss=0.675, val_acc=0.902, train_loss_epoch=0.447]\n",
      "Epoch 106:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.463, v_num=6, train_loss_step=0.436, val_loss=0.675, val_acc=0.902, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 106:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.448, v_num=6, train_loss_step=0.457, val_loss=0.659, val_acc=0.885, train_loss_epoch=0.443]\n",
      "Epoch 107:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.456, v_num=6, train_loss_step=0.443, val_loss=0.659, val_acc=0.885, train_loss_epoch=0.446]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 107:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.455, v_num=6, train_loss_step=0.448, val_loss=0.562, val_acc=0.934, train_loss_epoch=0.446]\n",
      "Epoch 108:  85%|████████▍ | 130/153 [00:22<00:04,  5.73it/s, loss=0.448, v_num=6, train_loss_step=0.443, val_loss=0.562, val_acc=0.934, train_loss_epoch=0.446]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 108:  92%|█████████▏| 140/153 [00:26<00:02,  5.29it/s, loss=0.440, v_num=6, train_loss_step=0.438, val_loss=0.703, val_acc=0.869, train_loss_epoch=0.446]\n",
      "Epoch 109:  85%|████████▍ | 130/153 [00:22<00:04,  5.65it/s, loss=0.442, v_num=6, train_loss_step=0.439, val_loss=0.703, val_acc=0.869, train_loss_epoch=0.446]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 109:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.441, v_num=6, train_loss_step=0.427, val_loss=0.704, val_acc=0.869, train_loss_epoch=0.446]\n",
      "Epoch 110:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.444, v_num=6, train_loss_step=0.452, val_loss=0.704, val_acc=0.869, train_loss_epoch=0.444]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 110:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.445, v_num=6, train_loss_step=0.47, val_loss=0.731, val_acc=0.885, train_loss_epoch=0.444] \n",
      "Epoch 111:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.448, v_num=6, train_loss_step=0.435, val_loss=0.731, val_acc=0.885, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 111:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.444, v_num=6, train_loss_step=0.447, val_loss=0.748, val_acc=0.869, train_loss_epoch=0.443]\n",
      "Epoch 112:  85%|████████▍ | 130/153 [00:22<00:04,  5.72it/s, loss=0.445, v_num=6, train_loss_step=0.47, val_loss=0.748, val_acc=0.869, train_loss_epoch=0.445] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 112:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.447, v_num=6, train_loss_step=0.445, val_loss=0.729, val_acc=0.869, train_loss_epoch=0.445]\n",
      "Epoch 113:  85%|████████▍ | 130/153 [00:22<00:04,  5.71it/s, loss=0.451, v_num=6, train_loss_step=0.436, val_loss=0.729, val_acc=0.869, train_loss_epoch=0.444]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 113:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.451, v_num=6, train_loss_step=0.439, val_loss=0.705, val_acc=0.869, train_loss_epoch=0.444]\n",
      "Epoch 114:  85%|████████▍ | 130/153 [00:23<00:04,  5.65it/s, loss=0.447, v_num=6, train_loss_step=0.456, val_loss=0.705, val_acc=0.869, train_loss_epoch=0.446]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 114:  92%|█████████▏| 140/153 [00:26<00:02,  5.21it/s, loss=0.445, v_num=6, train_loss_step=0.429, val_loss=0.647, val_acc=0.885, train_loss_epoch=0.446]\n",
      "Epoch 115:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.445, v_num=6, train_loss_step=0.435, val_loss=0.647, val_acc=0.885, train_loss_epoch=0.442]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.447, v_num=6, train_loss_step=0.496, val_loss=0.731, val_acc=0.869, train_loss_epoch=0.442]\n",
      "Epoch 116:  85%|████████▍ | 130/153 [00:22<00:04,  5.67it/s, loss=0.447, v_num=6, train_loss_step=0.432, val_loss=0.731, val_acc=0.869, train_loss_epoch=0.444]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 116:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.445, v_num=6, train_loss_step=0.434, val_loss=0.676, val_acc=0.902, train_loss_epoch=0.444]\n",
      "Epoch 117:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.445, v_num=6, train_loss_step=0.45, val_loss=0.676, val_acc=0.902, train_loss_epoch=0.445] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 117:  92%|█████████▏| 140/153 [00:26<00:02,  5.28it/s, loss=0.448, v_num=6, train_loss_step=0.447, val_loss=0.662, val_acc=0.902, train_loss_epoch=0.445]\n",
      "Epoch 118:  85%|████████▍ | 130/153 [00:22<00:04,  5.70it/s, loss=0.445, v_num=6, train_loss_step=0.441, val_loss=0.662, val_acc=0.902, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 118:  92%|█████████▏| 140/153 [00:26<00:02,  5.27it/s, loss=0.444, v_num=6, train_loss_step=0.446, val_loss=0.624, val_acc=0.902, train_loss_epoch=0.443]\n",
      "Epoch 119:  85%|████████▍ | 130/153 [00:23<00:04,  5.50it/s, loss=0.443, v_num=6, train_loss_step=0.431, val_loss=0.624, val_acc=0.902, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 119:  92%|█████████▏| 140/153 [00:27<00:02,  5.08it/s, loss=0.445, v_num=6, train_loss_step=0.452, val_loss=0.718, val_acc=0.885, train_loss_epoch=0.445]\n",
      "Epoch 120:  85%|████████▍ | 130/153 [00:23<00:04,  5.61it/s, loss=0.446, v_num=6, train_loss_step=0.447, val_loss=0.718, val_acc=0.885, train_loss_epoch=0.443]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 120:  92%|█████████▏| 140/153 [00:26<00:02,  5.20it/s, loss=0.446, v_num=6, train_loss_step=0.434, val_loss=0.611, val_acc=0.934, train_loss_epoch=0.443]\n",
      "Epoch 121:  85%|████████▍ | 130/153 [00:22<00:04,  5.66it/s, loss=0.442, v_num=6, train_loss_step=0.463, val_loss=0.611, val_acc=0.934, train_loss_epoch=0.444]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 121:  92%|█████████▏| 140/153 [00:26<00:02,  5.23it/s, loss=0.445, v_num=6, train_loss_step=0.436, val_loss=0.737, val_acc=0.869, train_loss_epoch=0.444]\n",
      "Epoch 122:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.443, v_num=6, train_loss_step=0.435, val_loss=0.737, val_acc=0.869, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 122:  92%|█████████▏| 140/153 [00:26<00:02,  5.25it/s, loss=0.443, v_num=6, train_loss_step=0.445, val_loss=0.69, val_acc=0.885, train_loss_epoch=0.445] \n",
      "Epoch 123:  85%|████████▍ | 130/153 [00:23<00:04,  5.64it/s, loss=0.443, v_num=6, train_loss_step=0.434, val_loss=0.69, val_acc=0.885, train_loss_epoch=0.445]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 123:  92%|█████████▏| 140/153 [00:26<00:02,  5.22it/s, loss=0.442, v_num=6, train_loss_step=0.437, val_loss=0.69, val_acc=0.869, train_loss_epoch=0.445]\n",
      "Epoch 124:  85%|████████▍ | 130/153 [00:22<00:04,  5.69it/s, loss=0.445, v_num=6, train_loss_step=0.44, val_loss=0.69, val_acc=0.869, train_loss_epoch=0.444] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 124:  92%|█████████▏| 140/153 [00:26<00:02,  5.26it/s, loss=0.442, v_num=6, train_loss_step=0.434, val_loss=0.628, val_acc=0.902, train_loss_epoch=0.444]\n",
      "Epoch 124:  92%|█████████▏| 140/153 [00:26<00:02,  5.24it/s, loss=0.442, v_num=6, train_loss_step=0.434, val_loss=0.628, val_acc=0.902, train_loss_epoch=0.444]\n"
     ]
    }
   ],
   "source": [
    "configs['DATASET']['AUGMENTATION'] = 'gaussian'\n",
    "configs['LOSS'] = 'label_smoothing_cross_entropy'\n",
    "configs['CHECKPOINT']['SAVE_NAME'] = 'crnn-bmw-gaussian-ls0.1'\n",
    "torch.cuda.empty_cache()\n",
    "do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
