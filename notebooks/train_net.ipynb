{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "pkg_path = \"/nfs/homedirs/yuny/project-1/audio_classification\"\n",
    "if pkg_path not in sys.path:\n",
    "    sys.path.append(pkg_path)\n",
    "    \n",
    "import yaml\n",
    "from audio_classification.tools import do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"/nfs/homedirs/yuny/project-1/audio_classification/configs/crnn_bmw.yaml\", \"r\") as config_file:\n",
    "    configs = yaml.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name        | Type        | Params\n",
      "---------------------------------------------\n",
      "0  | conv1       | Conv2d      | 640   \n",
      "1  | bn1         | BatchNorm2d | 128   \n",
      "2  | dropout1    | Dropout     | 0     \n",
      "3  | conv2       | Conv2d      | 73 K  \n",
      "4  | bn2         | BatchNorm2d | 256   \n",
      "5  | dropout2    | Dropout     | 0     \n",
      "6  | conv3       | Conv2d      | 147 K \n",
      "7  | bn3         | BatchNorm2d | 256   \n",
      "8  | dropout3    | Dropout     | 0     \n",
      "9  | conv4       | Conv2d      | 147 K \n",
      "10 | bn4         | BatchNorm2d | 256   \n",
      "11 | dropout4    | Dropout     | 0     \n",
      "12 | rnn         | GRU         | 21 K  \n",
      "13 | dropout_rnn | Dropout     | 0     \n",
      "14 | linear      | Linear      | 198   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  88%|████████▊ | 110/125 [00:11<00:01,  9.18it/s, loss=0.949, v_num=1, train_loss_step=0.748]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 120/125 [00:14<00:00,  8.01it/s, loss=0.977, v_num=1, train_loss_step=1.51, val_loss=1.01, val_acc=0.636]\n",
      "Epoch 1:  88%|████████▊ | 110/125 [00:11<00:01,  9.19it/s, loss=0.910, v_num=1, train_loss_step=0.694, val_loss=1.01, val_acc=0.636, train_loss_epoch=1.24]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 120/125 [00:14<00:00,  8.04it/s, loss=0.906, v_num=1, train_loss_step=0.441, val_loss=1.03, val_acc=0.626, train_loss_epoch=1.24]\n",
      "Epoch 2:  88%|████████▊ | 110/125 [00:11<00:01,  9.30it/s, loss=0.815, v_num=1, train_loss_step=1.31, val_loss=1.03, val_acc=0.626, train_loss_epoch=1.01] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 120/125 [00:14<00:00,  8.12it/s, loss=0.736, v_num=1, train_loss_step=0.244, val_loss=1.5, val_acc=0.556, train_loss_epoch=1.01]\n",
      "Epoch 3:  88%|████████▊ | 110/125 [00:11<00:01,  9.28it/s, loss=0.567, v_num=1, train_loss_step=0.861, val_loss=1.5, val_acc=0.556, train_loss_epoch=0.811]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 120/125 [00:14<00:00,  8.08it/s, loss=0.571, v_num=1, train_loss_step=0.561, val_loss=0.664, val_acc=0.747, train_loss_epoch=0.811]\n",
      "Epoch 4:  88%|████████▊ | 110/125 [00:11<00:01,  9.27it/s, loss=0.698, v_num=1, train_loss_step=0.954, val_loss=0.664, val_acc=0.747, train_loss_epoch=0.702]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 120/125 [00:14<00:00,  8.08it/s, loss=0.671, v_num=1, train_loss_step=0.56, val_loss=0.576, val_acc=0.798, train_loss_epoch=0.702] \n",
      "Epoch 5:  88%|████████▊ | 110/125 [00:11<00:01,  9.27it/s, loss=0.435, v_num=1, train_loss_step=0.284, val_loss=0.576, val_acc=0.798, train_loss_epoch=0.631]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 120/125 [00:14<00:00,  8.07it/s, loss=0.433, v_num=1, train_loss_step=0.33, val_loss=0.491, val_acc=0.808, train_loss_epoch=0.631] \n",
      "Epoch 6:  88%|████████▊ | 110/125 [00:11<00:01,  9.27it/s, loss=0.429, v_num=1, train_loss_step=0.44, val_loss=0.491, val_acc=0.808, train_loss_epoch=0.563] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 120/125 [00:14<00:00,  8.12it/s, loss=0.448, v_num=1, train_loss_step=1.01, val_loss=0.518, val_acc=0.788, train_loss_epoch=0.563]\n",
      "Epoch 7:  88%|████████▊ | 110/125 [00:11<00:01,  9.22it/s, loss=0.452, v_num=1, train_loss_step=0.965, val_loss=0.518, val_acc=0.788, train_loss_epoch=0.508]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 120/125 [00:14<00:00,  8.05it/s, loss=0.437, v_num=1, train_loss_step=0.388, val_loss=0.39, val_acc=0.869, train_loss_epoch=0.508] \n",
      "Epoch 8:  88%|████████▊ | 110/125 [00:11<00:01,  9.22it/s, loss=0.397, v_num=1, train_loss_step=0.0375, val_loss=0.39, val_acc=0.869, train_loss_epoch=0.45]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 120/125 [00:14<00:00,  8.04it/s, loss=0.438, v_num=1, train_loss_step=0.165, val_loss=0.319, val_acc=0.879, train_loss_epoch=0.45]\n",
      "Epoch 9:  88%|████████▊ | 110/125 [00:11<00:01,  9.26it/s, loss=0.477, v_num=1, train_loss_step=1.02, val_loss=0.319, val_acc=0.879, train_loss_epoch=0.481] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  96%|█████████▌| 120/125 [00:14<00:00,  8.10it/s, loss=0.467, v_num=1, train_loss_step=0.0487, val_loss=0.395, val_acc=0.869, train_loss_epoch=0.481]\n",
      "Epoch 10:  88%|████████▊ | 110/125 [00:11<00:01,  9.31it/s, loss=0.514, v_num=1, train_loss_step=0.257, val_loss=0.395, val_acc=0.869, train_loss_epoch=0.398]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  96%|█████████▌| 120/125 [00:14<00:00,  8.13it/s, loss=0.514, v_num=1, train_loss_step=0.372, val_loss=0.409, val_acc=0.848, train_loss_epoch=0.398]\n",
      "Epoch 11:  88%|████████▊ | 110/125 [00:11<00:01,  9.27it/s, loss=0.380, v_num=1, train_loss_step=0.0433, val_loss=0.409, val_acc=0.848, train_loss_epoch=0.386]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  96%|█████████▌| 120/125 [00:14<00:00,  8.10it/s, loss=0.391, v_num=1, train_loss_step=0.31, val_loss=0.522, val_acc=0.828, train_loss_epoch=0.386]  \n",
      "Epoch 12:  88%|████████▊ | 110/125 [00:11<00:01,  9.19it/s, loss=0.237, v_num=1, train_loss_step=0.652, val_loss=0.522, val_acc=0.828, train_loss_epoch=0.323] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  96%|█████████▌| 120/125 [00:14<00:00,  8.05it/s, loss=0.286, v_num=1, train_loss_step=0.941, val_loss=0.599, val_acc=0.798, train_loss_epoch=0.323]\n",
      "Epoch 13:  88%|████████▊ | 110/125 [00:11<00:01,  9.20it/s, loss=0.384, v_num=1, train_loss_step=0.409, val_loss=0.599, val_acc=0.798, train_loss_epoch=0.28] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  96%|█████████▌| 120/125 [00:14<00:00,  8.06it/s, loss=0.414, v_num=1, train_loss_step=0.36, val_loss=0.435, val_acc=0.879, train_loss_epoch=0.28] \n",
      "Epoch 14:  88%|████████▊ | 110/125 [00:11<00:01,  9.26it/s, loss=0.298, v_num=1, train_loss_step=0.175, val_loss=0.435, val_acc=0.879, train_loss_epoch=0.292]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  96%|█████████▌| 120/125 [00:14<00:00,  8.09it/s, loss=0.273, v_num=1, train_loss_step=0.0533, val_loss=0.243, val_acc=0.909, train_loss_epoch=0.292]\n",
      "Epoch 15:  88%|████████▊ | 110/125 [00:11<00:01,  9.19it/s, loss=0.233, v_num=1, train_loss_step=0.723, val_loss=0.243, val_acc=0.909, train_loss_epoch=0.345] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 15:  96%|█████████▌| 120/125 [00:14<00:00,  8.05it/s, loss=0.216, v_num=1, train_loss_step=0.0683, val_loss=0.255, val_acc=0.899, train_loss_epoch=0.345]\n",
      "Epoch 16:  88%|████████▊ | 110/125 [00:11<00:01,  9.24it/s, loss=0.170, v_num=1, train_loss_step=0.182, val_loss=0.255, val_acc=0.899, train_loss_epoch=0.245] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  96%|█████████▌| 120/125 [00:14<00:00,  8.08it/s, loss=0.169, v_num=1, train_loss_step=0.24, val_loss=0.273, val_acc=0.899, train_loss_epoch=0.245] \n",
      "Epoch 17:  88%|████████▊ | 110/125 [00:11<00:01,  9.28it/s, loss=0.278, v_num=1, train_loss_step=0.279, val_loss=0.273, val_acc=0.899, train_loss_epoch=0.23]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  96%|█████████▌| 120/125 [00:14<00:00,  8.09it/s, loss=0.319, v_num=1, train_loss_step=1.06, val_loss=0.328, val_acc=0.889, train_loss_epoch=0.23] \n",
      "Epoch 18:  88%|████████▊ | 110/125 [00:11<00:01,  9.28it/s, loss=0.174, v_num=1, train_loss_step=0.11, val_loss=0.328, val_acc=0.889, train_loss_epoch=0.276]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  96%|█████████▌| 120/125 [00:14<00:00,  8.09it/s, loss=0.182, v_num=1, train_loss_step=0.0708, val_loss=0.338, val_acc=0.869, train_loss_epoch=0.276]\n",
      "Epoch 19:  88%|████████▊ | 110/125 [00:11<00:01,  9.20it/s, loss=0.254, v_num=1, train_loss_step=0.0756, val_loss=0.338, val_acc=0.869, train_loss_epoch=0.213]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  96%|█████████▌| 120/125 [00:14<00:00,  8.01it/s, loss=0.253, v_num=1, train_loss_step=0.515, val_loss=0.243, val_acc=0.929, train_loss_epoch=0.213] \n",
      "Epoch 20:  88%|████████▊ | 110/125 [00:11<00:01,  9.28it/s, loss=0.149, v_num=1, train_loss_step=0.254, val_loss=0.243, val_acc=0.929, train_loss_epoch=0.232] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 20:  96%|█████████▌| 120/125 [00:14<00:00,  8.09it/s, loss=0.139, v_num=1, train_loss_step=0.102, val_loss=0.155, val_acc=0.949, train_loss_epoch=0.232]\n",
      "Epoch 21:  88%|████████▊ | 110/125 [00:11<00:01,  9.36it/s, loss=0.170, v_num=1, train_loss_step=0.0205, val_loss=0.155, val_acc=0.949, train_loss_epoch=0.169]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  96%|█████████▌| 120/125 [00:14<00:00,  8.16it/s, loss=0.182, v_num=1, train_loss_step=0.0229, val_loss=0.168, val_acc=0.939, train_loss_epoch=0.169]\n",
      "Epoch 22:  88%|████████▊ | 110/125 [00:11<00:01,  9.27it/s, loss=0.127, v_num=1, train_loss_step=0.0924, val_loss=0.168, val_acc=0.939, train_loss_epoch=0.151]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  96%|█████████▌| 120/125 [00:14<00:00,  8.10it/s, loss=0.122, v_num=1, train_loss_step=0.24, val_loss=0.239, val_acc=0.929, train_loss_epoch=0.151]  \n",
      "Epoch 23:  88%|████████▊ | 110/125 [00:11<00:01,  9.27it/s, loss=0.147, v_num=1, train_loss_step=0.0362, val_loss=0.239, val_acc=0.929, train_loss_epoch=0.16]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  96%|█████████▌| 120/125 [00:14<00:00,  8.08it/s, loss=0.147, v_num=1, train_loss_step=0.026, val_loss=0.156, val_acc=0.96, train_loss_epoch=0.16]  \n",
      "Epoch 24:  88%|████████▊ | 110/125 [00:11<00:01,  9.28it/s, loss=0.088, v_num=1, train_loss_step=0.0418, val_loss=0.156, val_acc=0.96, train_loss_epoch=0.143]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  96%|█████████▌| 120/125 [00:14<00:00,  8.10it/s, loss=0.105, v_num=1, train_loss_step=0.377, val_loss=0.134, val_acc=0.96, train_loss_epoch=0.143] \n",
      "Epoch 25:  88%|████████▊ | 110/125 [00:11<00:01,  9.29it/s, loss=0.191, v_num=1, train_loss_step=0.23, val_loss=0.134, val_acc=0.96, train_loss_epoch=0.129]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25:  96%|█████████▌| 120/125 [00:14<00:00,  8.12it/s, loss=0.200, v_num=1, train_loss_step=0.388, val_loss=0.234, val_acc=0.929, train_loss_epoch=0.129]\n",
      "Epoch 26:  88%|████████▊ | 110/125 [00:11<00:01,  9.20it/s, loss=0.137, v_num=1, train_loss_step=0.00639, val_loss=0.234, val_acc=0.929, train_loss_epoch=0.141]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26:  96%|█████████▌| 120/125 [00:14<00:00,  8.05it/s, loss=0.128, v_num=1, train_loss_step=0.0679, val_loss=0.276, val_acc=0.929, train_loss_epoch=0.141] \n",
      "Epoch 27:  88%|████████▊ | 110/125 [00:11<00:01,  9.21it/s, loss=0.223, v_num=1, train_loss_step=0.122, val_loss=0.276, val_acc=0.929, train_loss_epoch=0.139] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27:  96%|█████████▌| 120/125 [00:14<00:00,  8.05it/s, loss=0.174, v_num=1, train_loss_step=0.00478, val_loss=0.171, val_acc=0.96, train_loss_epoch=0.139]\n",
      "Epoch 28:  88%|████████▊ | 110/125 [00:11<00:01,  9.26it/s, loss=0.092, v_num=1, train_loss_step=0.0428, val_loss=0.171, val_acc=0.96, train_loss_epoch=0.124] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28:  96%|█████████▌| 120/125 [00:14<00:00,  8.09it/s, loss=0.078, v_num=1, train_loss_step=0.0124, val_loss=0.213, val_acc=0.939, train_loss_epoch=0.124]\n",
      "Epoch 29:  88%|████████▊ | 110/125 [00:11<00:01,  9.25it/s, loss=0.103, v_num=1, train_loss_step=0.0112, val_loss=0.213, val_acc=0.939, train_loss_epoch=0.115] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29:  96%|█████████▌| 120/125 [00:14<00:00,  8.09it/s, loss=0.102, v_num=1, train_loss_step=0.029, val_loss=0.153, val_acc=0.949, train_loss_epoch=0.115] \n",
      "Epoch 30:  88%|████████▊ | 110/125 [00:11<00:01,  9.25it/s, loss=0.170, v_num=1, train_loss_step=0.0286, val_loss=0.153, val_acc=0.949, train_loss_epoch=0.0957]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30:  96%|█████████▌| 120/125 [00:14<00:00,  8.08it/s, loss=0.143, v_num=1, train_loss_step=0.00414, val_loss=0.171, val_acc=0.96, train_loss_epoch=0.0957]\n",
      "Epoch 31:  88%|████████▊ | 110/125 [00:11<00:01,  9.25it/s, loss=0.123, v_num=1, train_loss_step=0.0274, val_loss=0.171, val_acc=0.96, train_loss_epoch=0.116]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31:  96%|█████████▌| 120/125 [00:14<00:00,  8.10it/s, loss=0.123, v_num=1, train_loss_step=0.024, val_loss=0.18, val_acc=0.949, train_loss_epoch=0.116] \n",
      "Epoch 32:  88%|████████▊ | 110/125 [00:11<00:01,  9.23it/s, loss=0.068, v_num=1, train_loss_step=0.208, val_loss=0.18, val_acc=0.949, train_loss_epoch=0.0975]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32:  96%|█████████▌| 120/125 [00:14<00:00,  8.07it/s, loss=0.070, v_num=1, train_loss_step=0.191, val_loss=0.199, val_acc=0.96, train_loss_epoch=0.0975]\n",
      "Epoch 33:  88%|████████▊ | 110/125 [00:11<00:01,  9.26it/s, loss=0.159, v_num=1, train_loss_step=0.0432, val_loss=0.199, val_acc=0.96, train_loss_epoch=0.0899] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33:  96%|█████████▌| 120/125 [00:14<00:00,  8.09it/s, loss=0.155, v_num=1, train_loss_step=0.0205, val_loss=0.234, val_acc=0.919, train_loss_epoch=0.0899]\n",
      "Epoch 34:  88%|████████▊ | 110/125 [00:11<00:01,  9.25it/s, loss=0.216, v_num=1, train_loss_step=0.664, val_loss=0.234, val_acc=0.919, train_loss_epoch=0.104]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 34:  96%|█████████▌| 120/125 [00:14<00:00,  8.07it/s, loss=0.225, v_num=1, train_loss_step=0.217, val_loss=0.261, val_acc=0.909, train_loss_epoch=0.104]\n",
      "Epoch 35:  88%|████████▊ | 110/125 [00:11<00:01,  9.24it/s, loss=0.141, v_num=1, train_loss_step=0.00693, val_loss=0.261, val_acc=0.909, train_loss_epoch=0.179]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 35:  96%|█████████▌| 120/125 [00:14<00:00,  8.08it/s, loss=0.167, v_num=1, train_loss_step=0.877, val_loss=0.39, val_acc=0.909, train_loss_epoch=0.179]   \n",
      "Epoch 36:  88%|████████▊ | 110/125 [00:11<00:01,  9.28it/s, loss=0.090, v_num=1, train_loss_step=0.0885, val_loss=0.39, val_acc=0.909, train_loss_epoch=0.144] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 36:  96%|█████████▌| 120/125 [00:14<00:00,  8.10it/s, loss=0.090, v_num=1, train_loss_step=0.0329, val_loss=0.216, val_acc=0.96, train_loss_epoch=0.144]\n",
      "Epoch 37:  88%|████████▊ | 110/125 [00:11<00:01,  9.26it/s, loss=0.129, v_num=1, train_loss_step=0.0334, val_loss=0.216, val_acc=0.96, train_loss_epoch=0.123]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 37:  96%|█████████▌| 120/125 [00:14<00:00,  8.10it/s, loss=0.107, v_num=1, train_loss_step=0.0367, val_loss=0.323, val_acc=0.929, train_loss_epoch=0.123]\n",
      "Epoch 38:  88%|████████▊ | 110/125 [00:11<00:01,  9.25it/s, loss=0.115, v_num=1, train_loss_step=0.0559, val_loss=0.323, val_acc=0.929, train_loss_epoch=0.0804] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38:  96%|█████████▌| 120/125 [00:14<00:00,  8.07it/s, loss=0.092, v_num=1, train_loss_step=0.0196, val_loss=0.193, val_acc=0.939, train_loss_epoch=0.0804]\n",
      "Epoch 39:  88%|████████▊ | 110/125 [00:11<00:01,  9.19it/s, loss=0.100, v_num=1, train_loss_step=0.0344, val_loss=0.193, val_acc=0.939, train_loss_epoch=0.0752]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39:  96%|█████████▌| 120/125 [00:14<00:00,  8.06it/s, loss=0.087, v_num=1, train_loss_step=0.406, val_loss=0.342, val_acc=0.919, train_loss_epoch=0.0752] \n",
      "Epoch 40:  88%|████████▊ | 110/125 [00:11<00:01,  9.22it/s, loss=0.048, v_num=1, train_loss_step=0.0398, val_loss=0.342, val_acc=0.919, train_loss_epoch=0.0823]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 40:  96%|█████████▌| 120/125 [00:14<00:00,  8.08it/s, loss=0.042, v_num=1, train_loss_step=0.00706, val_loss=0.183, val_acc=0.939, train_loss_epoch=0.0823]\n",
      "Epoch 41:  88%|████████▊ | 110/125 [00:11<00:01,  9.29it/s, loss=0.072, v_num=1, train_loss_step=0.0232, val_loss=0.183, val_acc=0.939, train_loss_epoch=0.0615] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 41:  96%|█████████▌| 120/125 [00:14<00:00,  8.11it/s, loss=0.062, v_num=1, train_loss_step=0.00861, val_loss=0.26, val_acc=0.919, train_loss_epoch=0.0615]\n",
      "Epoch 42:  88%|████████▊ | 110/125 [00:11<00:01,  9.30it/s, loss=0.028, v_num=1, train_loss_step=0.00656, val_loss=0.26, val_acc=0.919, train_loss_epoch=0.0661]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 42:  96%|█████████▌| 120/125 [00:14<00:00,  8.12it/s, loss=0.014, v_num=1, train_loss_step=0.0189, val_loss=0.188, val_acc=0.96, train_loss_epoch=0.0661] \n",
      "Epoch 43:  88%|████████▊ | 110/125 [00:11<00:01,  9.24it/s, loss=0.058, v_num=1, train_loss_step=0.534, val_loss=0.188, val_acc=0.96, train_loss_epoch=0.0529] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 43:  96%|█████████▌| 120/125 [00:14<00:00,  8.09it/s, loss=0.048, v_num=1, train_loss_step=0.00734, val_loss=0.174, val_acc=0.96, train_loss_epoch=0.0529]\n",
      "Epoch 44:  88%|████████▊ | 110/125 [00:11<00:01,  9.25it/s, loss=0.059, v_num=1, train_loss_step=0.0123, val_loss=0.174, val_acc=0.96, train_loss_epoch=0.0422] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 44:  96%|█████████▌| 120/125 [00:14<00:00,  8.08it/s, loss=0.059, v_num=1, train_loss_step=0.00969, val_loss=0.209, val_acc=0.949, train_loss_epoch=0.0422]\n",
      "Epoch 45:  88%|████████▊ | 110/125 [00:11<00:01,  9.27it/s, loss=0.027, v_num=1, train_loss_step=0.00452, val_loss=0.209, val_acc=0.949, train_loss_epoch=0.0409]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 45:  96%|█████████▌| 120/125 [00:14<00:00,  8.10it/s, loss=0.025, v_num=1, train_loss_step=0.0112, val_loss=0.277, val_acc=0.939, train_loss_epoch=0.0409] \n",
      "Epoch 46:  88%|████████▊ | 110/125 [00:11<00:01,  9.20it/s, loss=0.028, v_num=1, train_loss_step=0.015, val_loss=0.277, val_acc=0.939, train_loss_epoch=0.0446] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46:  96%|█████████▌| 120/125 [00:14<00:00,  8.04it/s, loss=0.029, v_num=1, train_loss_step=0.0347, val_loss=0.219, val_acc=0.949, train_loss_epoch=0.0446]\n",
      "Epoch 47:  88%|████████▊ | 110/125 [00:11<00:01,  9.30it/s, loss=0.074, v_num=1, train_loss_step=0.00749, val_loss=0.219, val_acc=0.949, train_loss_epoch=0.0441]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 47:  96%|█████████▌| 120/125 [00:14<00:00,  8.12it/s, loss=0.075, v_num=1, train_loss_step=0.0203, val_loss=0.229, val_acc=0.949, train_loss_epoch=0.0441] \n",
      "Epoch 48:  88%|████████▊ | 110/125 [00:11<00:01,  9.29it/s, loss=0.072, v_num=1, train_loss_step=0.00415, val_loss=0.229, val_acc=0.949, train_loss_epoch=0.0407]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 48:  96%|█████████▌| 120/125 [00:14<00:00,  8.10it/s, loss=0.041, v_num=1, train_loss_step=0.0191, val_loss=0.176, val_acc=0.96, train_loss_epoch=0.0407]  \n",
      "Epoch 49:  88%|████████▊ | 110/125 [00:11<00:01,  9.22it/s, loss=0.030, v_num=1, train_loss_step=0.183, val_loss=0.176, val_acc=0.96, train_loss_epoch=0.0708] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 49:  96%|█████████▌| 120/125 [00:14<00:00,  8.07it/s, loss=0.031, v_num=1, train_loss_step=0.00535, val_loss=0.167, val_acc=0.949, train_loss_epoch=0.0708]\n",
      "Epoch 49:  96%|█████████▌| 120/125 [00:14<00:00,  8.05it/s, loss=0.031, v_num=1, train_loss_step=0.00535, val_loss=0.167, val_acc=0.949, train_loss_epoch=0.0708]\n"
     ]
    }
   ],
   "source": [
    "test_loader = do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Temporary testing procedure, will move to do_train in the future\n",
    "\"\"\"\n",
    "from audio_classification.model import lit_m18\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "map_location = 'cuda'\n",
    "model = lit_m18.load_from_checkpoint(\n",
    "    checkpoint_path='/nfs/students/winter-term-2020/project-1/project-1/weights/m18-epoch=19-val_acc=0.803.ckpt',\n",
    "    cfg=configs,\n",
    "    map_location=map_location\n",
    ")\n",
    "trainer = pl.Trainer()\n",
    "\n",
    "trainer.test(model, test_dataloaders=test_loader)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
