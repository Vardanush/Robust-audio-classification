{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "pkg_path = \"/nfs/homedirs/yuny/project-1/audio_classification\"\n",
    "if pkg_path not in sys.path:\n",
    "    sys.path.append(pkg_path)\n",
    "    \n",
    "import yaml\n",
    "import torch\n",
    "from audio_classification.tools import do_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/nfs/homedirs/yuny/project-1/audio_classification/configs/crnn_bmw.yaml\", \"r\") as config_file:\n",
    "    configs = yaml.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "   | Name        | Type        | Params\n",
      "---------------------------------------------\n",
      "0  | conv1       | Conv2d      | 640   \n",
      "1  | bn1         | BatchNorm2d | 128   \n",
      "2  | dropout1    | Dropout     | 0     \n",
      "3  | conv2       | Conv2d      | 73 K  \n",
      "4  | bn2         | BatchNorm2d | 256   \n",
      "5  | dropout2    | Dropout     | 0     \n",
      "6  | conv3       | Conv2d      | 147 K \n",
      "7  | bn3         | BatchNorm2d | 256   \n",
      "8  | dropout3    | Dropout     | 0     \n",
      "9  | conv4       | Conv2d      | 147 K \n",
      "10 | bn4         | BatchNorm2d | 256   \n",
      "11 | dropout4    | Dropout     | 0     \n",
      "12 | rnn         | GRU         | 21 K  \n",
      "13 | dropout_rnn | Dropout     | 0     \n",
      "14 | linear      | Linear      | 198   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  78%|███████▊  | 60/77 [00:14<00:04,  4.18it/s, loss=1.280, v_num=5, train_loss_step=0.858]\n",
      "Epoch 0:  78%|███████▊  | 60/77 [00:17<00:05,  3.39it/s, loss=1.220, v_num=5, train_loss_step=0.795, val_loss=1.16, val_acc=0.656]\n",
      "Epoch 1:  78%|███████▊  | 60/77 [00:13<00:03,  4.30it/s, loss=1.204, v_num=5, train_loss_step=1.4, val_loss=1.16, val_acc=0.656, train_loss_epoch=1.32]  \n",
      "Epoch 1:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=1.237, v_num=5, train_loss_step=1.59, val_loss=1.08, val_acc=0.656, train_loss_epoch=1.32]\n",
      "Epoch 2:  78%|███████▊  | 60/77 [00:14<00:04,  4.23it/s, loss=1.106, v_num=5, train_loss_step=0.973, val_loss=1.08, val_acc=0.656, train_loss_epoch=1.17]\n",
      "Epoch 2:  78%|███████▊  | 60/77 [00:17<00:05,  3.39it/s, loss=1.145, v_num=5, train_loss_step=1.77, val_loss=1.03, val_acc=0.689, train_loss_epoch=1.17] \n",
      "Epoch 3:  78%|███████▊  | 60/77 [00:13<00:03,  4.30it/s, loss=1.015, v_num=5, train_loss_step=1.03, val_loss=1.03, val_acc=0.689, train_loss_epoch=1.1] \n",
      "Epoch 3:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=1.089, v_num=5, train_loss_step=1.83, val_loss=1, val_acc=0.738, train_loss_epoch=1.1]   \n",
      "Epoch 4:  78%|███████▊  | 60/77 [00:14<00:03,  4.28it/s, loss=0.876, v_num=5, train_loss_step=0.548, val_loss=1, val_acc=0.738, train_loss_epoch=1.08]\n",
      "Epoch 4:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.854, v_num=5, train_loss_step=0.62, val_loss=0.927, val_acc=0.754, train_loss_epoch=1.08]\n",
      "Epoch 5:  78%|███████▊  | 60/77 [00:13<00:03,  4.34it/s, loss=0.920, v_num=5, train_loss_step=0.497, val_loss=0.927, val_acc=0.754, train_loss_epoch=0.985]\n",
      "Epoch 5:  78%|███████▊  | 60/77 [00:17<00:04,  3.46it/s, loss=0.928, v_num=5, train_loss_step=1.68, val_loss=0.876, val_acc=0.803, train_loss_epoch=0.985] \n",
      "Epoch 6:  78%|███████▊  | 60/77 [00:13<00:03,  4.36it/s, loss=0.791, v_num=5, train_loss_step=0.761, val_loss=0.876, val_acc=0.803, train_loss_epoch=0.929]\n",
      "Epoch 6:  78%|███████▊  | 60/77 [00:17<00:04,  3.47it/s, loss=0.855, v_num=5, train_loss_step=0.541, val_loss=1.05, val_acc=0.705, train_loss_epoch=0.929] \n",
      "Epoch 7:  78%|███████▊  | 60/77 [00:13<00:03,  4.29it/s, loss=0.859, v_num=5, train_loss_step=0.755, val_loss=1.05, val_acc=0.705, train_loss_epoch=0.844]\n",
      "Epoch 7:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.925, v_num=5, train_loss_step=0.569, val_loss=0.879, val_acc=0.77, train_loss_epoch=0.844]\n",
      "Epoch 8:  78%|███████▊  | 60/77 [00:14<00:03,  4.26it/s, loss=0.794, v_num=5, train_loss_step=0.513, val_loss=0.879, val_acc=0.77, train_loss_epoch=0.846]\n",
      "Epoch 8:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.736, v_num=5, train_loss_step=0.58, val_loss=0.821, val_acc=0.787, train_loss_epoch=0.846]\n",
      "Epoch 9:  78%|███████▊  | 60/77 [00:14<00:03,  4.26it/s, loss=0.879, v_num=5, train_loss_step=1.18, val_loss=0.821, val_acc=0.787, train_loss_epoch=0.788] \n",
      "Epoch 9:  78%|███████▊  | 60/77 [00:17<00:05,  3.40it/s, loss=0.786, v_num=5, train_loss_step=0.445, val_loss=0.773, val_acc=0.852, train_loss_epoch=0.788]\n",
      "Epoch 10:  78%|███████▊  | 60/77 [00:13<00:03,  4.32it/s, loss=0.739, v_num=5, train_loss_step=0.636, val_loss=0.773, val_acc=0.852, train_loss_epoch=0.844]\n",
      "Epoch 10:  78%|███████▊  | 60/77 [00:17<00:04,  3.47it/s, loss=0.704, v_num=5, train_loss_step=0.562, val_loss=0.737, val_acc=0.852, train_loss_epoch=0.844]\n",
      "Epoch 11:  78%|███████▊  | 60/77 [00:14<00:04,  4.17it/s, loss=0.704, v_num=5, train_loss_step=0.698, val_loss=0.737, val_acc=0.852, train_loss_epoch=0.753]\n",
      "Epoch 11:  78%|███████▊  | 60/77 [00:17<00:05,  3.37it/s, loss=0.734, v_num=5, train_loss_step=1.49, val_loss=0.768, val_acc=0.82, train_loss_epoch=0.753]  \n",
      "Epoch 12:  78%|███████▊  | 60/77 [00:13<00:03,  4.31it/s, loss=0.805, v_num=5, train_loss_step=0.792, val_loss=0.768, val_acc=0.82, train_loss_epoch=0.777]\n",
      "Epoch 12:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.742, v_num=5, train_loss_step=0.824, val_loss=0.725, val_acc=0.869, train_loss_epoch=0.777]\n",
      "Epoch 13:  78%|███████▊  | 60/77 [00:13<00:03,  4.30it/s, loss=0.689, v_num=5, train_loss_step=0.515, val_loss=0.725, val_acc=0.869, train_loss_epoch=0.76] \n",
      "Epoch 13:  78%|███████▊  | 60/77 [00:17<00:04,  3.40it/s, loss=0.674, v_num=5, train_loss_step=0.438, val_loss=0.746, val_acc=0.836, train_loss_epoch=0.76]\n",
      "Epoch 14:  78%|███████▊  | 60/77 [00:13<00:03,  4.30it/s, loss=0.720, v_num=5, train_loss_step=0.521, val_loss=0.746, val_acc=0.836, train_loss_epoch=0.677]\n",
      "Epoch 14:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.690, v_num=5, train_loss_step=0.444, val_loss=0.783, val_acc=0.836, train_loss_epoch=0.677]\n",
      "Epoch 15:  78%|███████▊  | 60/77 [00:13<00:03,  4.37it/s, loss=0.656, v_num=5, train_loss_step=0.578, val_loss=0.783, val_acc=0.836, train_loss_epoch=0.686]\n",
      "Epoch 15:  78%|███████▊  | 60/77 [00:17<00:04,  3.47it/s, loss=0.688, v_num=5, train_loss_step=0.557, val_loss=0.851, val_acc=0.803, train_loss_epoch=0.686]\n",
      "Epoch 16:  78%|███████▊  | 60/77 [00:14<00:04,  4.21it/s, loss=0.659, v_num=5, train_loss_step=0.608, val_loss=0.851, val_acc=0.803, train_loss_epoch=0.692]\n",
      "Epoch 16:  78%|███████▊  | 60/77 [00:17<00:05,  3.39it/s, loss=0.706, v_num=5, train_loss_step=0.972, val_loss=0.681, val_acc=0.918, train_loss_epoch=0.692]\n",
      "Epoch 17:  78%|███████▊  | 60/77 [00:13<00:03,  4.38it/s, loss=0.732, v_num=5, train_loss_step=0.472, val_loss=0.681, val_acc=0.918, train_loss_epoch=0.702]\n",
      "Epoch 17:  78%|███████▊  | 60/77 [00:17<00:04,  3.47it/s, loss=0.664, v_num=5, train_loss_step=0.501, val_loss=0.703, val_acc=0.852, train_loss_epoch=0.702]\n",
      "Epoch 18:  78%|███████▊  | 60/77 [00:13<00:03,  4.30it/s, loss=0.643, v_num=5, train_loss_step=0.563, val_loss=0.703, val_acc=0.852, train_loss_epoch=0.733]\n",
      "Epoch 18:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.623, v_num=5, train_loss_step=0.452, val_loss=0.683, val_acc=0.902, train_loss_epoch=0.733]\n",
      "Epoch 19:  78%|███████▊  | 60/77 [00:13<00:03,  4.40it/s, loss=0.607, v_num=5, train_loss_step=0.524, val_loss=0.683, val_acc=0.902, train_loss_epoch=0.631]\n",
      "Epoch 19:  78%|███████▊  | 60/77 [00:17<00:04,  3.47it/s, loss=0.673, v_num=5, train_loss_step=0.462, val_loss=0.577, val_acc=0.918, train_loss_epoch=0.631]\n",
      "Epoch 20:  78%|███████▊  | 60/77 [00:14<00:03,  4.28it/s, loss=0.612, v_num=5, train_loss_step=0.48, val_loss=0.577, val_acc=0.918, train_loss_epoch=0.616] \n",
      "Epoch 20:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.647, v_num=5, train_loss_step=0.674, val_loss=0.665, val_acc=0.852, train_loss_epoch=0.616]\n",
      "Epoch 21:  78%|███████▊  | 60/77 [00:13<00:03,  4.38it/s, loss=0.615, v_num=5, train_loss_step=1.07, val_loss=0.665, val_acc=0.852, train_loss_epoch=0.633] \n",
      "Epoch 21:  78%|███████▊  | 60/77 [00:17<00:04,  3.46it/s, loss=0.629, v_num=5, train_loss_step=0.579, val_loss=0.652, val_acc=0.885, train_loss_epoch=0.633]\n",
      "Epoch 22:  78%|███████▊  | 60/77 [00:13<00:03,  4.38it/s, loss=0.665, v_num=5, train_loss_step=1.03, val_loss=0.652, val_acc=0.885, train_loss_epoch=0.633] \n",
      "Epoch 22:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.692, v_num=5, train_loss_step=1.18, val_loss=0.659, val_acc=0.918, train_loss_epoch=0.633]\n",
      "Epoch 23:  78%|███████▊  | 60/77 [00:13<00:03,  4.29it/s, loss=0.559, v_num=5, train_loss_step=0.509, val_loss=0.659, val_acc=0.918, train_loss_epoch=0.625]\n",
      "Epoch 23:  78%|███████▊  | 60/77 [00:17<00:04,  3.45it/s, loss=0.575, v_num=5, train_loss_step=0.475, val_loss=0.686, val_acc=0.885, train_loss_epoch=0.625]\n",
      "Epoch 24:  78%|███████▊  | 60/77 [00:13<00:03,  4.33it/s, loss=0.625, v_num=5, train_loss_step=0.485, val_loss=0.686, val_acc=0.885, train_loss_epoch=0.606]\n",
      "Epoch 24:  78%|███████▊  | 60/77 [00:17<00:04,  3.47it/s, loss=0.543, v_num=5, train_loss_step=0.674, val_loss=0.593, val_acc=0.918, train_loss_epoch=0.606]\n",
      "Epoch 25:  78%|███████▊  | 60/77 [00:14<00:03,  4.27it/s, loss=0.563, v_num=5, train_loss_step=0.567, val_loss=0.593, val_acc=0.918, train_loss_epoch=0.602]\n",
      "Epoch 25:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.584, v_num=5, train_loss_step=1.09, val_loss=0.613, val_acc=0.902, train_loss_epoch=0.602] \n",
      "Epoch 26:  78%|███████▊  | 60/77 [00:14<00:04,  4.24it/s, loss=0.518, v_num=5, train_loss_step=0.452, val_loss=0.613, val_acc=0.902, train_loss_epoch=0.575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.520, v_num=5, train_loss_step=0.435, val_loss=0.644, val_acc=0.869, train_loss_epoch=0.575]\n",
      "Epoch 27:  78%|███████▊  | 60/77 [00:14<00:03,  4.26it/s, loss=0.544, v_num=5, train_loss_step=0.588, val_loss=0.644, val_acc=0.869, train_loss_epoch=0.544]\n",
      "Epoch 27:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.546, v_num=5, train_loss_step=0.508, val_loss=0.539, val_acc=0.934, train_loss_epoch=0.544]\n",
      "Epoch 28:  78%|███████▊  | 60/77 [00:13<00:03,  4.38it/s, loss=0.530, v_num=5, train_loss_step=0.843, val_loss=0.539, val_acc=0.934, train_loss_epoch=0.539]\n",
      "Epoch 28:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.572, v_num=5, train_loss_step=0.857, val_loss=0.529, val_acc=0.967, train_loss_epoch=0.539]\n",
      "Epoch 29:  78%|███████▊  | 60/77 [00:13<00:03,  4.34it/s, loss=0.579, v_num=5, train_loss_step=0.692, val_loss=0.529, val_acc=0.967, train_loss_epoch=0.531]\n",
      "Epoch 29:  78%|███████▊  | 60/77 [00:17<00:04,  3.45it/s, loss=0.652, v_num=5, train_loss_step=2.32, val_loss=0.552, val_acc=0.951, train_loss_epoch=0.531] \n",
      "Epoch 30:  78%|███████▊  | 60/77 [00:13<00:03,  4.39it/s, loss=0.543, v_num=5, train_loss_step=0.466, val_loss=0.552, val_acc=0.951, train_loss_epoch=0.571]\n",
      "Epoch 30:  78%|███████▊  | 60/77 [00:17<00:04,  3.46it/s, loss=0.499, v_num=5, train_loss_step=0.517, val_loss=0.549, val_acc=0.934, train_loss_epoch=0.571]\n",
      "Epoch 31:  78%|███████▊  | 60/77 [00:13<00:03,  4.36it/s, loss=0.517, v_num=5, train_loss_step=0.78, val_loss=0.549, val_acc=0.934, train_loss_epoch=0.553] \n",
      "Epoch 31:  78%|███████▊  | 60/77 [00:17<00:04,  3.49it/s, loss=0.528, v_num=5, train_loss_step=0.428, val_loss=0.577, val_acc=0.951, train_loss_epoch=0.553]\n",
      "Epoch 32:  78%|███████▊  | 60/77 [00:14<00:04,  4.19it/s, loss=0.487, v_num=5, train_loss_step=0.581, val_loss=0.577, val_acc=0.951, train_loss_epoch=0.532]\n",
      "Epoch 32:  78%|███████▊  | 60/77 [00:17<00:05,  3.37it/s, loss=0.493, v_num=5, train_loss_step=0.435, val_loss=0.571, val_acc=0.951, train_loss_epoch=0.532]\n",
      "Epoch 33:  78%|███████▊  | 60/77 [00:14<00:03,  4.27it/s, loss=0.550, v_num=5, train_loss_step=0.449, val_loss=0.571, val_acc=0.951, train_loss_epoch=0.521]\n",
      "Epoch 33:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.525, v_num=5, train_loss_step=0.481, val_loss=0.577, val_acc=0.934, train_loss_epoch=0.521]\n",
      "Epoch 34:  78%|███████▊  | 60/77 [00:14<00:03,  4.28it/s, loss=0.552, v_num=5, train_loss_step=0.454, val_loss=0.577, val_acc=0.934, train_loss_epoch=0.535]\n",
      "Epoch 34:  78%|███████▊  | 60/77 [00:17<00:04,  3.40it/s, loss=0.518, v_num=5, train_loss_step=0.571, val_loss=0.513, val_acc=0.984, train_loss_epoch=0.535]\n",
      "Epoch 35:  78%|███████▊  | 60/77 [00:13<00:03,  4.31it/s, loss=0.530, v_num=5, train_loss_step=0.526, val_loss=0.513, val_acc=0.984, train_loss_epoch=0.524]\n",
      "Epoch 35:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.543, v_num=5, train_loss_step=0.488, val_loss=0.541, val_acc=0.934, train_loss_epoch=0.524]\n",
      "Epoch 36:  78%|███████▊  | 60/77 [00:13<00:03,  4.32it/s, loss=0.499, v_num=5, train_loss_step=0.515, val_loss=0.541, val_acc=0.934, train_loss_epoch=0.514]\n",
      "Epoch 36:  78%|███████▊  | 60/77 [00:17<00:04,  3.45it/s, loss=0.471, v_num=5, train_loss_step=0.452, val_loss=0.492, val_acc=0.967, train_loss_epoch=0.514]\n",
      "Epoch 37:  78%|███████▊  | 60/77 [00:14<00:03,  4.27it/s, loss=0.511, v_num=5, train_loss_step=0.451, val_loss=0.492, val_acc=0.967, train_loss_epoch=0.508]\n",
      "Epoch 37:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.517, v_num=5, train_loss_step=0.44, val_loss=0.545, val_acc=0.934, train_loss_epoch=0.508] \n",
      "Epoch 38:  78%|███████▊  | 60/77 [00:13<00:03,  4.38it/s, loss=0.475, v_num=5, train_loss_step=0.456, val_loss=0.545, val_acc=0.934, train_loss_epoch=0.501]\n",
      "Epoch 38:  78%|███████▊  | 60/77 [00:17<00:04,  3.46it/s, loss=0.464, v_num=5, train_loss_step=0.435, val_loss=0.534, val_acc=0.951, train_loss_epoch=0.501]\n",
      "Epoch 39:  78%|███████▊  | 60/77 [00:14<00:03,  4.28it/s, loss=0.543, v_num=5, train_loss_step=0.874, val_loss=0.534, val_acc=0.951, train_loss_epoch=0.494]\n",
      "Epoch 39:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.557, v_num=5, train_loss_step=0.606, val_loss=0.753, val_acc=0.836, train_loss_epoch=0.494]\n",
      "Epoch 40:  78%|███████▊  | 60/77 [00:14<00:03,  4.29it/s, loss=0.543, v_num=5, train_loss_step=0.461, val_loss=0.753, val_acc=0.836, train_loss_epoch=0.521]\n",
      "Epoch 40:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.537, v_num=5, train_loss_step=0.484, val_loss=0.609, val_acc=0.918, train_loss_epoch=0.521]\n",
      "Epoch 41:  78%|███████▊  | 60/77 [00:14<00:03,  4.25it/s, loss=0.500, v_num=5, train_loss_step=0.642, val_loss=0.609, val_acc=0.918, train_loss_epoch=0.577]\n",
      "Epoch 41:  78%|███████▊  | 60/77 [00:17<00:05,  3.39it/s, loss=0.506, v_num=5, train_loss_step=0.464, val_loss=0.523, val_acc=0.967, train_loss_epoch=0.577]\n",
      "Epoch 42:  78%|███████▊  | 60/77 [00:14<00:04,  4.22it/s, loss=0.481, v_num=5, train_loss_step=0.469, val_loss=0.523, val_acc=0.967, train_loss_epoch=0.508]\n",
      "Epoch 42:  78%|███████▊  | 60/77 [00:17<00:05,  3.36it/s, loss=0.499, v_num=5, train_loss_step=0.5, val_loss=0.522, val_acc=0.967, train_loss_epoch=0.508]  \n",
      "Epoch 43:  78%|███████▊  | 60/77 [00:13<00:03,  4.32it/s, loss=0.494, v_num=5, train_loss_step=0.443, val_loss=0.522, val_acc=0.967, train_loss_epoch=0.5]\n",
      "Epoch 43:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.513, v_num=5, train_loss_step=0.51, val_loss=0.533, val_acc=0.967, train_loss_epoch=0.5] \n",
      "Epoch 44:  78%|███████▊  | 60/77 [00:14<00:03,  4.25it/s, loss=0.501, v_num=5, train_loss_step=0.447, val_loss=0.533, val_acc=0.967, train_loss_epoch=0.518]\n",
      "Epoch 44:  78%|███████▊  | 60/77 [00:17<00:04,  3.40it/s, loss=0.537, v_num=5, train_loss_step=0.577, val_loss=0.568, val_acc=0.951, train_loss_epoch=0.518]\n",
      "Epoch 45:  78%|███████▊  | 60/77 [00:13<00:03,  4.30it/s, loss=0.575, v_num=5, train_loss_step=0.468, val_loss=0.568, val_acc=0.951, train_loss_epoch=0.509]\n",
      "Epoch 45:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.521, v_num=5, train_loss_step=0.434, val_loss=0.525, val_acc=0.967, train_loss_epoch=0.509]\n",
      "Epoch 46:  78%|███████▊  | 60/77 [00:14<00:04,  4.23it/s, loss=0.518, v_num=5, train_loss_step=0.443, val_loss=0.525, val_acc=0.967, train_loss_epoch=0.546]\n",
      "Epoch 46:  78%|███████▊  | 60/77 [00:17<00:04,  3.40it/s, loss=0.539, v_num=5, train_loss_step=0.917, val_loss=0.584, val_acc=0.934, train_loss_epoch=0.546]\n",
      "Epoch 47:  78%|███████▊  | 60/77 [00:13<00:03,  4.30it/s, loss=0.522, v_num=5, train_loss_step=0.45, val_loss=0.584, val_acc=0.934, train_loss_epoch=0.538] \n",
      "Epoch 47:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.534, v_num=5, train_loss_step=0.441, val_loss=0.534, val_acc=0.967, train_loss_epoch=0.538]\n",
      "Epoch 48:  78%|███████▊  | 60/77 [00:13<00:03,  4.31it/s, loss=0.490, v_num=5, train_loss_step=0.492, val_loss=0.534, val_acc=0.967, train_loss_epoch=0.557]\n",
      "Epoch 48:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.590, v_num=5, train_loss_step=2.15, val_loss=0.502, val_acc=0.967, train_loss_epoch=0.557] \n",
      "Epoch 49:  78%|███████▊  | 60/77 [00:14<00:03,  4.26it/s, loss=0.480, v_num=5, train_loss_step=0.439, val_loss=0.502, val_acc=0.967, train_loss_epoch=0.535]\n",
      "Epoch 49:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.484, v_num=5, train_loss_step=0.452, val_loss=0.529, val_acc=0.951, train_loss_epoch=0.535]\n",
      "Epoch 50:  78%|███████▊  | 60/77 [00:14<00:03,  4.26it/s, loss=0.477, v_num=5, train_loss_step=0.456, val_loss=0.529, val_acc=0.951, train_loss_epoch=0.497]\n",
      "Epoch 50:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.479, v_num=5, train_loss_step=0.437, val_loss=0.514, val_acc=0.951, train_loss_epoch=0.497]\n",
      "Epoch 51:  78%|███████▊  | 60/77 [00:13<00:03,  4.34it/s, loss=0.502, v_num=5, train_loss_step=0.585, val_loss=0.514, val_acc=0.951, train_loss_epoch=0.481]\n",
      "Epoch 51:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.485, v_num=5, train_loss_step=0.435, val_loss=0.511, val_acc=0.967, train_loss_epoch=0.481]\n",
      "Epoch 52:  78%|███████▊  | 60/77 [00:14<00:03,  4.26it/s, loss=0.469, v_num=5, train_loss_step=0.473, val_loss=0.511, val_acc=0.967, train_loss_epoch=0.493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52:  78%|███████▊  | 60/77 [00:17<00:04,  3.40it/s, loss=0.474, v_num=5, train_loss_step=0.454, val_loss=0.512, val_acc=0.967, train_loss_epoch=0.493]\n",
      "Epoch 53:  78%|███████▊  | 60/77 [00:13<00:03,  4.30it/s, loss=0.476, v_num=5, train_loss_step=0.444, val_loss=0.512, val_acc=0.967, train_loss_epoch=0.47] \n",
      "Epoch 53:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.505, v_num=5, train_loss_step=0.811, val_loss=0.513, val_acc=0.967, train_loss_epoch=0.47]\n",
      "Epoch 54:  78%|███████▊  | 60/77 [00:13<00:03,  4.32it/s, loss=0.468, v_num=5, train_loss_step=0.453, val_loss=0.513, val_acc=0.967, train_loss_epoch=0.478]\n",
      "Epoch 54:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.459, v_num=5, train_loss_step=0.508, val_loss=0.499, val_acc=0.967, train_loss_epoch=0.478]\n",
      "Epoch 55:  78%|███████▊  | 60/77 [00:13<00:03,  4.37it/s, loss=0.457, v_num=5, train_loss_step=0.458, val_loss=0.499, val_acc=0.967, train_loss_epoch=0.474]\n",
      "Epoch 55:  78%|███████▊  | 60/77 [00:17<00:04,  3.47it/s, loss=0.463, v_num=5, train_loss_step=0.431, val_loss=0.484, val_acc=0.967, train_loss_epoch=0.474]\n",
      "Epoch 56:  78%|███████▊  | 60/77 [00:14<00:04,  4.24it/s, loss=0.454, v_num=5, train_loss_step=0.491, val_loss=0.484, val_acc=0.967, train_loss_epoch=0.46] \n",
      "Epoch 56:  78%|███████▊  | 60/77 [00:17<00:04,  3.40it/s, loss=0.454, v_num=5, train_loss_step=0.535, val_loss=0.503, val_acc=0.967, train_loss_epoch=0.46]\n",
      "Epoch 57:  78%|███████▊  | 60/77 [00:13<00:03,  4.32it/s, loss=0.463, v_num=5, train_loss_step=0.436, val_loss=0.503, val_acc=0.967, train_loss_epoch=0.463]\n",
      "Epoch 57:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.458, v_num=5, train_loss_step=0.433, val_loss=0.52, val_acc=0.951, train_loss_epoch=0.463] \n",
      "Epoch 58:  78%|███████▊  | 60/77 [00:14<00:04,  4.23it/s, loss=0.463, v_num=5, train_loss_step=0.437, val_loss=0.52, val_acc=0.951, train_loss_epoch=0.462]\n",
      "Epoch 58:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.463, v_num=5, train_loss_step=0.468, val_loss=0.531, val_acc=0.934, train_loss_epoch=0.462]\n",
      "Epoch 59:  78%|███████▊  | 60/77 [00:14<00:03,  4.28it/s, loss=0.451, v_num=5, train_loss_step=0.444, val_loss=0.531, val_acc=0.934, train_loss_epoch=0.465]\n",
      "Epoch 59:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.457, v_num=5, train_loss_step=0.504, val_loss=0.51, val_acc=0.967, train_loss_epoch=0.465] \n",
      "Epoch 60:  78%|███████▊  | 60/77 [00:14<00:04,  4.22it/s, loss=0.462, v_num=5, train_loss_step=0.437, val_loss=0.51, val_acc=0.967, train_loss_epoch=0.461]\n",
      "Epoch 60:  78%|███████▊  | 60/77 [00:17<00:05,  3.40it/s, loss=0.486, v_num=5, train_loss_step=0.534, val_loss=0.526, val_acc=0.967, train_loss_epoch=0.461]\n",
      "Epoch 61:  78%|███████▊  | 60/77 [00:13<00:03,  4.32it/s, loss=0.465, v_num=5, train_loss_step=0.456, val_loss=0.526, val_acc=0.967, train_loss_epoch=0.473]\n",
      "Epoch 61:  78%|███████▊  | 60/77 [00:17<00:04,  3.46it/s, loss=0.467, v_num=5, train_loss_step=0.429, val_loss=0.501, val_acc=0.967, train_loss_epoch=0.473]\n",
      "Epoch 62:  78%|███████▊  | 60/77 [00:13<00:03,  4.32it/s, loss=0.448, v_num=5, train_loss_step=0.445, val_loss=0.501, val_acc=0.967, train_loss_epoch=0.469]\n",
      "Epoch 62:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.454, v_num=5, train_loss_step=0.438, val_loss=0.503, val_acc=0.967, train_loss_epoch=0.469]\n",
      "Epoch 63:  78%|███████▊  | 60/77 [00:14<00:03,  4.28it/s, loss=0.462, v_num=5, train_loss_step=0.439, val_loss=0.503, val_acc=0.967, train_loss_epoch=0.456]\n",
      "Epoch 63:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.462, v_num=5, train_loss_step=0.436, val_loss=0.525, val_acc=0.967, train_loss_epoch=0.456]\n",
      "Epoch 64:  78%|███████▊  | 60/77 [00:13<00:03,  4.32it/s, loss=0.447, v_num=5, train_loss_step=0.448, val_loss=0.525, val_acc=0.967, train_loss_epoch=0.461]\n",
      "Epoch 64:  78%|███████▊  | 60/77 [00:17<00:04,  3.48it/s, loss=0.455, v_num=5, train_loss_step=0.585, val_loss=0.493, val_acc=0.967, train_loss_epoch=0.461]\n",
      "Epoch 65:  78%|███████▊  | 60/77 [00:13<00:03,  4.38it/s, loss=0.461, v_num=5, train_loss_step=0.496, val_loss=0.493, val_acc=0.967, train_loss_epoch=0.46] \n",
      "Epoch 65:  78%|███████▊  | 60/77 [00:17<00:04,  3.48it/s, loss=0.476, v_num=5, train_loss_step=0.443, val_loss=0.526, val_acc=0.951, train_loss_epoch=0.46]\n",
      "Epoch 66:  78%|███████▊  | 60/77 [00:13<00:03,  4.29it/s, loss=0.461, v_num=5, train_loss_step=0.657, val_loss=0.526, val_acc=0.951, train_loss_epoch=0.468]\n",
      "Epoch 66:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.469, v_num=5, train_loss_step=0.455, val_loss=0.516, val_acc=0.967, train_loss_epoch=0.468]\n",
      "Epoch 67:  78%|███████▊  | 60/77 [00:14<00:04,  4.19it/s, loss=0.461, v_num=5, train_loss_step=0.448, val_loss=0.516, val_acc=0.967, train_loss_epoch=0.471]\n",
      "Epoch 67:  78%|███████▊  | 60/77 [00:17<00:05,  3.34it/s, loss=0.452, v_num=5, train_loss_step=0.5, val_loss=0.492, val_acc=0.967, train_loss_epoch=0.471]  \n",
      "Epoch 68:  78%|███████▊  | 60/77 [00:13<00:03,  4.32it/s, loss=0.489, v_num=5, train_loss_step=0.446, val_loss=0.492, val_acc=0.967, train_loss_epoch=0.456]\n",
      "Epoch 68:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.490, v_num=5, train_loss_step=0.438, val_loss=0.497, val_acc=0.951, train_loss_epoch=0.456]\n",
      "Epoch 69:  78%|███████▊  | 60/77 [00:13<00:03,  4.43it/s, loss=0.487, v_num=5, train_loss_step=0.437, val_loss=0.497, val_acc=0.951, train_loss_epoch=0.482]\n",
      "Epoch 69:  78%|███████▊  | 60/77 [00:17<00:04,  3.48it/s, loss=0.472, v_num=5, train_loss_step=0.43, val_loss=0.502, val_acc=0.951, train_loss_epoch=0.482] \n",
      "Epoch 70:  78%|███████▊  | 60/77 [00:14<00:04,  4.25it/s, loss=0.456, v_num=5, train_loss_step=0.45, val_loss=0.502, val_acc=0.951, train_loss_epoch=0.488] \n",
      "Epoch 70:  78%|███████▊  | 60/77 [00:17<00:05,  3.38it/s, loss=0.451, v_num=5, train_loss_step=0.508, val_loss=0.508, val_acc=0.951, train_loss_epoch=0.488]\n",
      "Epoch 71:  78%|███████▊  | 60/77 [00:13<00:03,  4.32it/s, loss=0.477, v_num=5, train_loss_step=0.705, val_loss=0.508, val_acc=0.951, train_loss_epoch=0.456]\n",
      "Epoch 71:  78%|███████▊  | 60/77 [00:17<00:04,  3.45it/s, loss=0.476, v_num=5, train_loss_step=0.601, val_loss=0.525, val_acc=0.967, train_loss_epoch=0.456]\n",
      "Epoch 72:  78%|███████▊  | 60/77 [00:13<00:03,  4.29it/s, loss=0.456, v_num=5, train_loss_step=0.512, val_loss=0.525, val_acc=0.967, train_loss_epoch=0.465]\n",
      "Epoch 72:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.463, v_num=5, train_loss_step=0.471, val_loss=0.509, val_acc=0.967, train_loss_epoch=0.465]\n",
      "Epoch 73:  78%|███████▊  | 60/77 [00:13<00:03,  4.31it/s, loss=0.464, v_num=5, train_loss_step=0.474, val_loss=0.509, val_acc=0.967, train_loss_epoch=0.461]\n",
      "Epoch 73:  78%|███████▊  | 60/77 [00:17<00:04,  3.45it/s, loss=0.453, v_num=5, train_loss_step=0.454, val_loss=0.516, val_acc=0.951, train_loss_epoch=0.461]\n",
      "Epoch 74:  78%|███████▊  | 60/77 [00:14<00:03,  4.26it/s, loss=0.453, v_num=5, train_loss_step=0.438, val_loss=0.516, val_acc=0.951, train_loss_epoch=0.457]\n",
      "Epoch 74:  78%|███████▊  | 60/77 [00:17<00:04,  3.40it/s, loss=0.455, v_num=5, train_loss_step=0.429, val_loss=0.526, val_acc=0.951, train_loss_epoch=0.457]\n",
      "Epoch 75:  78%|███████▊  | 60/77 [00:14<00:04,  4.25it/s, loss=0.452, v_num=5, train_loss_step=0.444, val_loss=0.526, val_acc=0.951, train_loss_epoch=0.45] \n",
      "Epoch 75:  78%|███████▊  | 60/77 [00:17<00:05,  3.40it/s, loss=0.456, v_num=5, train_loss_step=0.536, val_loss=0.523, val_acc=0.967, train_loss_epoch=0.45]\n",
      "Epoch 76:  78%|███████▊  | 60/77 [00:13<00:03,  4.31it/s, loss=0.446, v_num=5, train_loss_step=0.446, val_loss=0.523, val_acc=0.967, train_loss_epoch=0.453]\n",
      "Epoch 76:  78%|███████▊  | 60/77 [00:17<00:05,  3.40it/s, loss=0.446, v_num=5, train_loss_step=0.464, val_loss=0.524, val_acc=0.951, train_loss_epoch=0.453]\n",
      "Epoch 77:  78%|███████▊  | 60/77 [00:13<00:03,  4.34it/s, loss=0.447, v_num=5, train_loss_step=0.444, val_loss=0.524, val_acc=0.951, train_loss_epoch=0.449]\n",
      "Epoch 77:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.451, v_num=5, train_loss_step=0.442, val_loss=0.514, val_acc=0.967, train_loss_epoch=0.449]\n",
      "Epoch 78:  78%|███████▊  | 60/77 [00:13<00:03,  4.42it/s, loss=0.457, v_num=5, train_loss_step=0.439, val_loss=0.514, val_acc=0.967, train_loss_epoch=0.45] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78:  78%|███████▊  | 60/77 [00:17<00:04,  3.50it/s, loss=0.446, v_num=5, train_loss_step=0.444, val_loss=0.54, val_acc=0.951, train_loss_epoch=0.45] \n",
      "Epoch 79:  78%|███████▊  | 60/77 [00:14<00:03,  4.27it/s, loss=0.446, v_num=5, train_loss_step=0.443, val_loss=0.54, val_acc=0.951, train_loss_epoch=0.452]\n",
      "Epoch 79:  78%|███████▊  | 60/77 [00:17<00:05,  3.40it/s, loss=0.442, v_num=5, train_loss_step=0.44, val_loss=0.533, val_acc=0.951, train_loss_epoch=0.452]\n",
      "Epoch 80:  78%|███████▊  | 60/77 [00:13<00:03,  4.29it/s, loss=0.450, v_num=5, train_loss_step=0.437, val_loss=0.533, val_acc=0.951, train_loss_epoch=0.446]\n",
      "Epoch 80:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.448, v_num=5, train_loss_step=0.456, val_loss=0.542, val_acc=0.951, train_loss_epoch=0.446]\n",
      "Epoch 81:  78%|███████▊  | 60/77 [00:14<00:04,  4.22it/s, loss=0.447, v_num=5, train_loss_step=0.438, val_loss=0.542, val_acc=0.951, train_loss_epoch=0.448]\n",
      "Epoch 81:  78%|███████▊  | 60/77 [00:17<00:05,  3.40it/s, loss=0.456, v_num=5, train_loss_step=0.558, val_loss=0.522, val_acc=0.967, train_loss_epoch=0.448]\n",
      "Epoch 82:  78%|███████▊  | 60/77 [00:14<00:04,  4.23it/s, loss=0.444, v_num=5, train_loss_step=0.443, val_loss=0.522, val_acc=0.967, train_loss_epoch=0.448]\n",
      "Epoch 82:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.453, v_num=5, train_loss_step=0.542, val_loss=0.524, val_acc=0.951, train_loss_epoch=0.448]\n",
      "Epoch 83:  78%|███████▊  | 60/77 [00:14<00:03,  4.26it/s, loss=0.448, v_num=5, train_loss_step=0.435, val_loss=0.524, val_acc=0.951, train_loss_epoch=0.448]\n",
      "Epoch 83:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.447, v_num=5, train_loss_step=0.44, val_loss=0.53, val_acc=0.951, train_loss_epoch=0.448]  \n",
      "Epoch 84:  78%|███████▊  | 60/77 [00:13<00:03,  4.29it/s, loss=0.450, v_num=5, train_loss_step=0.454, val_loss=0.53, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 84:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.447, v_num=5, train_loss_step=0.443, val_loss=0.559, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 85:  78%|███████▊  | 60/77 [00:13<00:03,  4.42it/s, loss=0.450, v_num=5, train_loss_step=0.46, val_loss=0.559, val_acc=0.951, train_loss_epoch=0.447] \n",
      "Epoch 85:  78%|███████▊  | 60/77 [00:17<00:04,  3.47it/s, loss=0.452, v_num=5, train_loss_step=0.479, val_loss=0.519, val_acc=0.967, train_loss_epoch=0.447]\n",
      "Epoch 86:  78%|███████▊  | 60/77 [00:13<00:03,  4.35it/s, loss=0.445, v_num=5, train_loss_step=0.444, val_loss=0.519, val_acc=0.967, train_loss_epoch=0.447]\n",
      "Epoch 86:  78%|███████▊  | 60/77 [00:17<00:05,  3.39it/s, loss=0.452, v_num=5, train_loss_step=0.448, val_loss=0.532, val_acc=0.951, train_loss_epoch=0.447]\n",
      "Epoch 87:  78%|███████▊  | 60/77 [00:14<00:04,  4.22it/s, loss=0.448, v_num=5, train_loss_step=0.446, val_loss=0.532, val_acc=0.951, train_loss_epoch=0.449]\n",
      "Epoch 87:  78%|███████▊  | 60/77 [00:17<00:04,  3.40it/s, loss=0.449, v_num=5, train_loss_step=0.461, val_loss=0.534, val_acc=0.951, train_loss_epoch=0.449]\n",
      "Epoch 88:  78%|███████▊  | 60/77 [00:14<00:04,  4.22it/s, loss=0.447, v_num=5, train_loss_step=0.449, val_loss=0.534, val_acc=0.951, train_loss_epoch=0.446]\n",
      "Epoch 88:  78%|███████▊  | 60/77 [00:17<00:05,  3.38it/s, loss=0.446, v_num=5, train_loss_step=0.438, val_loss=0.526, val_acc=0.951, train_loss_epoch=0.446]\n",
      "Epoch 89:  78%|███████▊  | 60/77 [00:14<00:03,  4.25it/s, loss=0.445, v_num=5, train_loss_step=0.453, val_loss=0.526, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 89:  78%|███████▊  | 60/77 [00:17<00:05,  3.40it/s, loss=0.442, v_num=5, train_loss_step=0.426, val_loss=0.542, val_acc=0.934, train_loss_epoch=0.445]\n",
      "Epoch 90:  78%|███████▊  | 60/77 [00:14<00:03,  4.27it/s, loss=0.443, v_num=5, train_loss_step=0.434, val_loss=0.542, val_acc=0.934, train_loss_epoch=0.446]\n",
      "Epoch 90:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.459, v_num=5, train_loss_step=0.74, val_loss=0.531, val_acc=0.951, train_loss_epoch=0.446] \n",
      "Epoch 91:  78%|███████▊  | 60/77 [00:13<00:03,  4.30it/s, loss=0.456, v_num=5, train_loss_step=0.444, val_loss=0.531, val_acc=0.951, train_loss_epoch=0.448]\n",
      "Epoch 91:  78%|███████▊  | 60/77 [00:17<00:05,  3.38it/s, loss=0.459, v_num=5, train_loss_step=0.46, val_loss=0.55, val_acc=0.951, train_loss_epoch=0.448]  \n",
      "Epoch 92:  78%|███████▊  | 60/77 [00:14<00:04,  4.25it/s, loss=0.447, v_num=5, train_loss_step=0.432, val_loss=0.55, val_acc=0.951, train_loss_epoch=0.454]\n",
      "Epoch 92:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.443, v_num=5, train_loss_step=0.434, val_loss=0.542, val_acc=0.951, train_loss_epoch=0.454]\n",
      "Epoch 93:  78%|███████▊  | 60/77 [00:14<00:03,  4.28it/s, loss=0.449, v_num=5, train_loss_step=0.452, val_loss=0.542, val_acc=0.951, train_loss_epoch=0.449]\n",
      "Epoch 93:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.452, v_num=5, train_loss_step=0.513, val_loss=0.537, val_acc=0.951, train_loss_epoch=0.449]\n",
      "Epoch 94:  78%|███████▊  | 60/77 [00:13<00:03,  4.29it/s, loss=0.450, v_num=5, train_loss_step=0.441, val_loss=0.537, val_acc=0.951, train_loss_epoch=0.448]\n",
      "Epoch 94:  78%|███████▊  | 60/77 [00:17<00:05,  3.39it/s, loss=0.448, v_num=5, train_loss_step=0.434, val_loss=0.546, val_acc=0.951, train_loss_epoch=0.448]\n",
      "Epoch 95:  78%|███████▊  | 60/77 [00:14<00:03,  4.25it/s, loss=0.441, v_num=5, train_loss_step=0.44, val_loss=0.546, val_acc=0.951, train_loss_epoch=0.445] \n",
      "Epoch 95:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.441, v_num=5, train_loss_step=0.434, val_loss=0.552, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 96:  78%|███████▊  | 60/77 [00:13<00:03,  4.30it/s, loss=0.445, v_num=5, train_loss_step=0.447, val_loss=0.552, val_acc=0.951, train_loss_epoch=0.443]\n",
      "Epoch 96:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.446, v_num=5, train_loss_step=0.463, val_loss=0.538, val_acc=0.951, train_loss_epoch=0.443]\n",
      "Epoch 97:  78%|███████▊  | 60/77 [00:13<00:03,  4.34it/s, loss=0.443, v_num=5, train_loss_step=0.437, val_loss=0.538, val_acc=0.951, train_loss_epoch=0.446]\n",
      "Epoch 97:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.442, v_num=5, train_loss_step=0.436, val_loss=0.55, val_acc=0.951, train_loss_epoch=0.446] \n",
      "Epoch 98:  78%|███████▊  | 60/77 [00:14<00:03,  4.26it/s, loss=0.449, v_num=5, train_loss_step=0.441, val_loss=0.55, val_acc=0.951, train_loss_epoch=0.446]\n",
      "Epoch 98:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.446, v_num=5, train_loss_step=0.433, val_loss=0.536, val_acc=0.951, train_loss_epoch=0.446]\n",
      "Epoch 99:  78%|███████▊  | 60/77 [00:14<00:04,  4.19it/s, loss=0.444, v_num=5, train_loss_step=0.446, val_loss=0.536, val_acc=0.951, train_loss_epoch=0.446]\n",
      "Epoch 99:  78%|███████▊  | 60/77 [00:17<00:05,  3.37it/s, loss=0.445, v_num=5, train_loss_step=0.452, val_loss=0.535, val_acc=0.951, train_loss_epoch=0.446]\n",
      "Epoch 100:  78%|███████▊  | 60/77 [00:13<00:03,  4.41it/s, loss=0.444, v_num=5, train_loss_step=0.438, val_loss=0.535, val_acc=0.951, train_loss_epoch=0.45] \n",
      "Epoch 100:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.445, v_num=5, train_loss_step=0.434, val_loss=0.539, val_acc=0.951, train_loss_epoch=0.45]\n",
      "Epoch 101:  78%|███████▊  | 60/77 [00:13<00:03,  4.34it/s, loss=0.445, v_num=5, train_loss_step=0.446, val_loss=0.539, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 101:  78%|███████▊  | 60/77 [00:17<00:04,  3.48it/s, loss=0.444, v_num=5, train_loss_step=0.432, val_loss=0.541, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 102:  78%|███████▊  | 60/77 [00:13<00:03,  4.34it/s, loss=0.448, v_num=5, train_loss_step=0.44, val_loss=0.541, val_acc=0.951, train_loss_epoch=0.444] \n",
      "Epoch 102:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.446, v_num=5, train_loss_step=0.435, val_loss=0.541, val_acc=0.951, train_loss_epoch=0.444]\n",
      "Epoch 103:  78%|███████▊  | 60/77 [00:13<00:03,  4.31it/s, loss=0.445, v_num=5, train_loss_step=0.463, val_loss=0.541, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 103:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.447, v_num=5, train_loss_step=0.494, val_loss=0.536, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 104:  78%|███████▊  | 60/77 [00:14<00:04,  4.25it/s, loss=0.445, v_num=5, train_loss_step=0.462, val_loss=0.536, val_acc=0.951, train_loss_epoch=0.444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104:  78%|███████▊  | 60/77 [00:17<00:05,  3.40it/s, loss=0.443, v_num=5, train_loss_step=0.424, val_loss=0.533, val_acc=0.951, train_loss_epoch=0.444]\n",
      "Epoch 105:  78%|███████▊  | 60/77 [00:14<00:04,  4.23it/s, loss=0.444, v_num=5, train_loss_step=0.434, val_loss=0.533, val_acc=0.951, train_loss_epoch=0.446]\n",
      "Epoch 105:  78%|███████▊  | 60/77 [00:17<00:05,  3.38it/s, loss=0.448, v_num=5, train_loss_step=0.461, val_loss=0.532, val_acc=0.951, train_loss_epoch=0.446]\n",
      "Epoch 106:  78%|███████▊  | 60/77 [00:14<00:03,  4.25it/s, loss=0.444, v_num=5, train_loss_step=0.447, val_loss=0.532, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 106:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.442, v_num=5, train_loss_step=0.446, val_loss=0.542, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 107:  78%|███████▊  | 60/77 [00:14<00:04,  4.24it/s, loss=0.444, v_num=5, train_loss_step=0.431, val_loss=0.542, val_acc=0.951, train_loss_epoch=0.443]\n",
      "Epoch 107:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.439, v_num=5, train_loss_step=0.433, val_loss=0.547, val_acc=0.951, train_loss_epoch=0.443]\n",
      "Epoch 108:  78%|███████▊  | 60/77 [00:14<00:03,  4.26it/s, loss=0.442, v_num=5, train_loss_step=0.437, val_loss=0.547, val_acc=0.951, train_loss_epoch=0.443]\n",
      "Epoch 108:  78%|███████▊  | 60/77 [00:17<00:04,  3.40it/s, loss=0.441, v_num=5, train_loss_step=0.431, val_loss=0.54, val_acc=0.951, train_loss_epoch=0.443] \n",
      "Epoch 109:  78%|███████▊  | 60/77 [00:13<00:03,  4.34it/s, loss=0.443, v_num=5, train_loss_step=0.44, val_loss=0.54, val_acc=0.951, train_loss_epoch=0.442] \n",
      "Epoch 109:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.441, v_num=5, train_loss_step=0.445, val_loss=0.548, val_acc=0.951, train_loss_epoch=0.442]\n",
      "Epoch 110:  78%|███████▊  | 60/77 [00:14<00:04,  4.21it/s, loss=0.440, v_num=5, train_loss_step=0.434, val_loss=0.548, val_acc=0.951, train_loss_epoch=0.443]\n",
      "Epoch 110:  78%|███████▊  | 60/77 [00:17<00:05,  3.37it/s, loss=0.441, v_num=5, train_loss_step=0.44, val_loss=0.525, val_acc=0.967, train_loss_epoch=0.443] \n",
      "Epoch 111:  78%|███████▊  | 60/77 [00:14<00:03,  4.28it/s, loss=0.444, v_num=5, train_loss_step=0.442, val_loss=0.525, val_acc=0.967, train_loss_epoch=0.444]\n",
      "Epoch 111:  78%|███████▊  | 60/77 [00:17<00:04,  3.40it/s, loss=0.443, v_num=5, train_loss_step=0.443, val_loss=0.52, val_acc=0.967, train_loss_epoch=0.444] \n",
      "Epoch 112:  78%|███████▊  | 60/77 [00:13<00:03,  4.30it/s, loss=0.438, v_num=5, train_loss_step=0.438, val_loss=0.52, val_acc=0.967, train_loss_epoch=0.445]\n",
      "Epoch 112:  78%|███████▊  | 60/77 [00:17<00:05,  3.40it/s, loss=0.441, v_num=5, train_loss_step=0.484, val_loss=0.533, val_acc=0.951, train_loss_epoch=0.445]\n",
      "Epoch 113:  78%|███████▊  | 60/77 [00:14<00:03,  4.26it/s, loss=0.441, v_num=5, train_loss_step=0.453, val_loss=0.533, val_acc=0.951, train_loss_epoch=0.442]\n",
      "Epoch 113:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.441, v_num=5, train_loss_step=0.427, val_loss=0.541, val_acc=0.951, train_loss_epoch=0.442]\n",
      "Epoch 114:  78%|███████▊  | 60/77 [00:14<00:03,  4.26it/s, loss=0.445, v_num=5, train_loss_step=0.444, val_loss=0.541, val_acc=0.951, train_loss_epoch=0.441]\n",
      "Epoch 114:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.442, v_num=5, train_loss_step=0.456, val_loss=0.533, val_acc=0.951, train_loss_epoch=0.441]\n",
      "Epoch 115:  78%|███████▊  | 60/77 [00:13<00:03,  4.35it/s, loss=0.462, v_num=5, train_loss_step=0.436, val_loss=0.533, val_acc=0.951, train_loss_epoch=0.446]\n",
      "Epoch 115:  78%|███████▊  | 60/77 [00:17<00:04,  3.45it/s, loss=0.448, v_num=5, train_loss_step=0.425, val_loss=0.536, val_acc=0.951, train_loss_epoch=0.446]\n",
      "Epoch 116:  78%|███████▊  | 60/77 [00:13<00:03,  4.37it/s, loss=0.443, v_num=5, train_loss_step=0.438, val_loss=0.536, val_acc=0.951, train_loss_epoch=0.45] \n",
      "Epoch 116:  78%|███████▊  | 60/77 [00:17<00:04,  3.45it/s, loss=0.445, v_num=5, train_loss_step=0.454, val_loss=0.52, val_acc=0.967, train_loss_epoch=0.45] \n",
      "Epoch 117:  78%|███████▊  | 60/77 [00:13<00:03,  4.35it/s, loss=0.442, v_num=5, train_loss_step=0.452, val_loss=0.52, val_acc=0.967, train_loss_epoch=0.442]\n",
      "Epoch 117:  78%|███████▊  | 60/77 [00:17<00:04,  3.44it/s, loss=0.443, v_num=5, train_loss_step=0.45, val_loss=0.518, val_acc=0.967, train_loss_epoch=0.442]\n",
      "Epoch 118:  78%|███████▊  | 60/77 [00:13<00:03,  4.33it/s, loss=0.442, v_num=5, train_loss_step=0.44, val_loss=0.518, val_acc=0.967, train_loss_epoch=0.443] \n",
      "Epoch 118:  78%|███████▊  | 60/77 [00:17<00:04,  3.46it/s, loss=0.443, v_num=5, train_loss_step=0.438, val_loss=0.518, val_acc=0.967, train_loss_epoch=0.443]\n",
      "Epoch 119:  78%|███████▊  | 60/77 [00:13<00:03,  4.31it/s, loss=0.444, v_num=5, train_loss_step=0.441, val_loss=0.518, val_acc=0.967, train_loss_epoch=0.443]\n",
      "Epoch 119:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.448, v_num=5, train_loss_step=0.472, val_loss=0.499, val_acc=0.951, train_loss_epoch=0.443]\n",
      "Epoch 120:  78%|███████▊  | 60/77 [00:14<00:03,  4.27it/s, loss=0.445, v_num=5, train_loss_step=0.45, val_loss=0.499, val_acc=0.951, train_loss_epoch=0.444] \n",
      "Epoch 120:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.444, v_num=5, train_loss_step=0.463, val_loss=0.521, val_acc=0.951, train_loss_epoch=0.444]\n",
      "Epoch 121:  78%|███████▊  | 60/77 [00:14<00:04,  4.23it/s, loss=0.446, v_num=5, train_loss_step=0.437, val_loss=0.521, val_acc=0.951, train_loss_epoch=0.442]\n",
      "Epoch 121:  78%|███████▊  | 60/77 [00:17<00:04,  3.40it/s, loss=0.444, v_num=5, train_loss_step=0.426, val_loss=0.522, val_acc=0.951, train_loss_epoch=0.442]\n",
      "Epoch 122:  78%|███████▊  | 60/77 [00:13<00:03,  4.36it/s, loss=0.447, v_num=5, train_loss_step=0.431, val_loss=0.522, val_acc=0.951, train_loss_epoch=0.443]\n",
      "Epoch 122:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.443, v_num=5, train_loss_step=0.451, val_loss=0.532, val_acc=0.951, train_loss_epoch=0.443]\n",
      "Epoch 123:  78%|███████▊  | 60/77 [00:14<00:03,  4.28it/s, loss=0.445, v_num=5, train_loss_step=0.465, val_loss=0.532, val_acc=0.951, train_loss_epoch=0.444]\n",
      "Epoch 123:  78%|███████▊  | 60/77 [00:17<00:04,  3.41it/s, loss=0.445, v_num=5, train_loss_step=0.436, val_loss=0.518, val_acc=0.951, train_loss_epoch=0.444]\n",
      "Epoch 124:  78%|███████▊  | 60/77 [00:14<00:03,  4.27it/s, loss=0.444, v_num=5, train_loss_step=0.45, val_loss=0.518, val_acc=0.951, train_loss_epoch=0.443] \n",
      "Epoch 124:  78%|███████▊  | 60/77 [00:17<00:04,  3.43it/s, loss=0.443, v_num=5, train_loss_step=0.46, val_loss=0.517, val_acc=0.951, train_loss_epoch=0.443]\n",
      "Epoch 124:  78%|███████▊  | 60/77 [00:17<00:04,  3.42it/s, loss=0.443, v_num=5, train_loss_step=0.46, val_loss=0.517, val_acc=0.951, train_loss_epoch=0.443]\n"
     ]
    }
   ],
   "source": [
    "# configs['DATASET']['AUGMENTATION'] = 'random'\n",
    "# configs['LOSS'] = 'cross_entropy'\n",
    "torch.cuda.empty_cache()\n",
    "do_train(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs['DATASET']['AUGMENTATION'] = 'random'\n",
    "# configs['LOSS'] = 'label_smoothing_cross_entropy'\n",
    "# torch.cuda.empty_cache()\n",
    "# do_train(configs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
