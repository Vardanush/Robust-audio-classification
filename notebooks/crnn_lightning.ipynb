{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "from project.data import UrbanSoundDataset\n",
    "from project.model import LitCRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Training on device {device}\")\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger('../logs/')\n",
    "\n",
    "csv_path = '../datasets/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
    "file_path = '../datasets/UrbanSound8K/audio/'\n",
    "\n",
    "# transform to log_amplitude mel-spectrogram\n",
    "# using original sampling_rate, n_fft, hop_length, n_mels from the paper\n",
    "transform = nn.Sequential(\n",
    "    T.MelSpectrogram(sample_rate=12000, n_fft=512, hop_length=256, n_mels=96),\n",
    "    T.AmplitudeToDB()\n",
    ")\n",
    "\n",
    "# device train_folds and val_folds\n",
    "folds = list(range(1,11))\n",
    "val_folds = [10] # CHANGE HERE FOR A DIFFERENT VALIDATION FOLD!\n",
    "train_folds = [fold for fold in folds if fold not in val_folds]\n",
    "\n",
    "# create train and test sets using chosen transform\n",
    "train_set = UrbanSoundDataset(csv_path, file_path, train_folds, transform=transform)\n",
    "val_set = UrbanSoundDataset(csv_path, file_path, val_folds, transform=transform)\n",
    "print(\"Train set size: \" + str(len(train_set)))\n",
    "print(\"val set size: \" + str(len(val_set)))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = 12, shuffle = True, num_workers=20, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size = 12, num_workers=20, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_acc',\n",
    "   min_delta=0.00,\n",
    "   patience=5,\n",
    "   verbose=True,\n",
    "   mode='max'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='../weights',\n",
    "    filename='fold-10-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "model = LitCRNN()\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=20, progress_bar_refresh_rate=20,\n",
    "                    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "                    logger=tb_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "detectron2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
